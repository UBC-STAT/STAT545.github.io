[
  {
    "objectID": "webpages/lectures_ii/lec8a_functions.html",
    "href": "webpages/lectures_ii/lec8a_functions.html",
    "title": "Lecture 8: Functions",
    "section": "",
    "text": "From this lecture, students are expected to be able to:\nWe will require the following packages for this lecture:\nlibrary(roxygen2)\nlibrary(testthat)",
    "crumbs": [
      "Lecture 8: Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec8a_functions.html#self-made-r-functions",
    "href": "webpages/lectures_ii/lec8a_functions.html#self-made-r-functions",
    "title": "Lecture 8: Functions",
    "section": "Self-made R Functions",
    "text": "Self-made R Functions\nAt this point in the course, we‚Äôve used lots of functions, like mean(), mutate(), and pivot_longer(). But it can be really useful to write your own function. For example, the ability to writing your own functions can supercharge your group_by() %&gt;% summarize() workflow: you can write your own function to use inside summarize(), instead of relying solely on functions built into R or available in packages!\nSo why write functions? In short, it avoids repeatedly duplicating code. This is helpful because:\n\nIt shortens your code ‚Äì crucially, without losing interpretability ‚Äì making it easier and faster to read through and process its overall intent.\nIf your needs change, then you only need to change your code in one place (the function definition) rather than a bunch of places.\nBullet points 1 and 2 mean that using functions typically leads to fewer bugs and fewer headaches.\n\nA good rule of thumb is whenever you find yourself repeating code more than a few times, consider writing a function.\nHere‚Äôs a simple example of a function I wrote to simulate rolling a user-inputted number of D10s (a 10-sided die used for tabletop gaming) and returning the sum of the dice.\n\nroll_d10 &lt;- function(num_dice) { \n    sum(sample(1:10, num_dice, replace=TRUE))\n}\n\nroll_d10(2)\n\n[1] 17\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis is not reproducible code, as the output will change each time I run this function as I am randomly sampling. If I wanted to make this reproducible, then I would set the seed to (say) 123 before running my function with set.seed(123).\n\n\n\nDocumentation\nYou should have also noticed by now that other people‚Äôs functions in packages are documented - there‚Äôs information about:\n\nwhat the function does, at a high level\nthe objects it expects you to input\nthe object that the function outputs\n\nAt an absolute minimum, functions should have some comments indicating what the function does and what the inputs are. However, to make the function more user-friendly, commenting each line can be extremely helpful to let the user know exactly what‚Äôs happening under the hood. For example, we could comment the above function to make it more clear:\n\nroll_d10 &lt;- function(num_dice) { \n  # this function simulates rolling `num_dice` number of 10-sided dice and outputs the sum\n  # note: no seed is used so the function will return a dice combination each time it is run\n  #\n  # inputs:\n  # - num_dice: number of dice you wish to roll\n  \n    sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers with replacement between 1 and 10, return sum\n}\n\n# test function\nroll_d10(2)\n\n[1] 9\n\n\nWe can do even better than this wutg roxygen2 tags to document the function! These tags are placed immediately above the function definition. Although roxygen2 tags are designed for use when creating R packages, they provide a standardized way to document a function ‚Äì and make it easy for you to migrate your function to an R package if need be! Roxygen comment lines always start with #' , the usual # for a comment, followed immediately by a single quote ':\n#' Description of function goes here\n#' \n#' @param x description of the parameter input x goes here\n#' @param y description of the parameter input x goes here\n#' @returns description of the what function returns goes here\n\nname_of_function &lt;- function(x, y) {\n  your function goes here!\n}\nFor the dice example, we could write:\n\n#' @details\n#' Simulates rolling `num_dice` number of dice for a 10 sided dice and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @return the sum of the dice rolled\n  \nroll_d10 &lt;- function(num_dice) { \n    sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers from one to 10 with replacement, return sum\n}\n\nroll_d10(2)\n\n[1] 19\n\n\n\n\nTesting\nWhen you‚Äôre using other people‚Äôs functions ‚Äì like those in packages ‚Äì they often work. However, as you have probably discovered by this point, it is very easy to inadvertently write code ‚Äì and therefore functions ‚Äì that do not work. Because of this, it‚Äôs important to test the functions we write to make sure they work. It is useful to ensure that\nIt‚Äôs useful to think of a few cases to test, along with edge cases (conditions that fall outside the typical or expected parameters) and see if the function performs\nLet‚Äôs try rolling 4 dice:\n\nroll_d10(4)\n\n[1] 23\n\n\nNow, let‚Äôs try rolling no dice. The expected output should be 0.\n\nroll_d10(0)\n\n[1] 0\n\n\nInstead of manually coding test cases over and over, we can use functions from the testthat package in R. For example, when rolling no dice, we would expect the output to be 0. We can use the expect_equal() function to confirm this. The function won‚Äôt output anything if the output is as expected:\n\nexpect_equal(roll_d10(0), 0)\n\nor will throw an error if not:\nexpect_equal(roll_d10(0), 2)\nError: roll_d10(0) not equal to 2.\n1/1 mismatches\n[1] 0 - 2 == -2\nThe test_that() function makes these tests even more readable:\n\ntest_that(\"Rolling no dice equals 0\", {\n  expect_equal(roll_d10(0), 0)\n})\n\nTest passed üéä\n\n\nMore examples for the test_that() can be found on on this Video Lecture.\n\n\nError Handling\nLet‚Äôs try inputting a nonsense input, like 2.5 dice. This input doesn‚Äôt make sense, so let‚Äôs see what happens:\n\nroll_d10(2.5)\n\n[1] 8\n\n\nInteresting! This is something we should consider controlling for when creating our function.\nWithin a function call, we can force errors to appear using the stop() function and conditional statements. For example, we may only want to allow whole numbers (positive numbers of dice) to be inputs. We can do this by seeing if the num_dice %% 1function returns 0. %% is the ‚Äúmodular division‚Äù function which returns the remainder after division. Whole numbers will not have any remainder when divided by 1. Let‚Äôs update our function:\n\n#' @details\n#' Simulates rolling `num_dice` number of dice and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @return the sum of the dice rolled\n  \nroll_d10 &lt;- function(num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers from one to 10 with replacement, return sum\n}\n\nSo rolling 2 dice shouldn‚Äôt throw an error:\n\nroll_d10(2)\n\n[1] 14\n\n\nBut rolling 2.5 dice should:\nroll_d10(2.5)\nError in roll_d10(2.5) : num_dice must be an integer\nOur function is working as expected for this edge case!\n\n\nReturns\nBy default, your function will return the last thing computed in your function. However, we can return other items, like lists and vectors and dataframes using return().\nWhile perhaps redundant as the last line of code here is what we want to output, we could explictly tell R what to output by:\n\n#' @details\n#' Simulates rolling `num_dice` number of dice with `n_sides` sides and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @return the sum of the dice rolled\n  \nroll_d10 &lt;- function(num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum_dice &lt;- sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers from one to 10 with replacement, save as sum_dice\n    \n    #output\n    return(sum_dice)\n}\n\nWe could also return a vector of the the number of dice, and the number of faces of each dice, and the sum.\n\n#' @details\n#' Simulates rolling `num_dice` number of dice with `n_sides` sides and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @param n_sides integer representing the number of sides of each dice.\n#' @return the sum of the dice rolled\n  \nroll_d10 &lt;- function(n_sides, num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum_dice &lt;- sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers from one to 10 with replacement, return sum\n    \n    out &lt;- c(num_dice, sum_dice) #create a vector of what we want to return\n    \n    return(out)\n    \n}\n\nroll_d10(num_dice = 5)\n\n[1]  5 23\n\n\nLooks like we rolled 5 dice and the sum was 23.",
    "crumbs": [
      "Lecture 8: Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec8a_functions.html#worksheet-b1",
    "href": "webpages/lectures_ii/lec8a_functions.html#worksheet-b1",
    "title": "Lecture 8: Functions",
    "section": "Worksheet B1",
    "text": "Worksheet B1\nNow it‚Äôs your turn to explore functions. Working through Worksheet B1 is a great place to go from here to learn the basics of how to define your own functions and how to test it.",
    "crumbs": [
      "Lecture 8: Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec8a_functions.html#resources",
    "href": "webpages/lectures_ii/lec8a_functions.html#resources",
    "title": "Lecture 8: Functions",
    "section": "Resources",
    "text": "Resources\nVideo lecture:\n\nR Functions for Data Analysis\n\nWritten resources:\n\nBasic function syntax in R: https://swcarpentry.github.io/r-novice-inflammation/02-func-R/\nWhen to use functions in your data analysis:\n\nstat545.com Functions, Parts 1-3\nR4DS functions chapter\n\n\n\nAttribution\nContent created by Grace Tompkins based off of previous instructional teams and Vincenzo Coia.",
    "crumbs": [
      "Lecture 8: Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1a_installation.html",
    "href": "webpages/lectures_i/lec1a_installation.html",
    "title": "Lecture 1A: Installation",
    "section": "",
    "text": "The goal of this lecture is to learn how to install and setup key software for use in the course.\nTAs are available in class on Imagine Day from 9am-10:30am on Tuesday September 2nd to aid with installation. I highly recommend you join if you haven‚Äôt used RStudio, Jupyter, or GitHub before.\n\n\nYou may encounter some material that implicitly assumes that you are using a Mac. For example, they might point you to a Terminal app, or ask you to use Unix commands like which or ls. Here is a cheatsheet that helps you convert between Windows command line (‚ÄúDOS‚Äù) and Mac command line (‚ÄúUNIX‚Äù). One thing that‚Äôs missing is the equivalent to Unix‚Äôs which; the closest equivalent in DOS is where.\n\n\n\nR and RStudio The main programming language used in the class is R and our main IDE (a text editor with helpful features for writing and running code) is RStudio. The following instructions are adapted from Chapter 5 of Jenny Bryan‚Äôs ‚Äúhappy git‚Äù book.\n\nInstall (or update to) the latest release R on your computer (4.5.1 currently):\n\nWindows: https://cran.r-project.org/bin/windows/base/\nMac: https://cran.r-project.org/bin/macosx/\n\nInstall RStudio\n\nhttps://posit.co/download/rstudio-desktop/\n\n\nEven if you already have R/RStudio, please update them to the most recent version!\n\n\n\nYou will need another IDE for R (Jupyter Notebook) and an R kernel called ‚ÄòIR Kernel‚Äô (needed to run R code within Jupyter) to work on the autograded worksheets. This is because the autograder we use plays well with Jupyter.\nThe following instructions are adapted from Rich Pauloo.\nPC Installation:\n\nInstall Anaconda from https://www.anaconda.com/download\n\nProvide your email and an installation link will be sent to you\nInstall the full version of Anaconda (not miniconda)\n\nInstall and setup the IR Kernel\n\nFind the location of R.exe on your computer (the location probably looks like C:\\Program Files\\R\\R-4.5.1\\bin). If you can‚Äôt find it, launch Command Prompt (CMD) and execute where R. The output should be the path to the file R.exe.\nOpen the Anaconda Prompt application. Enter the following command into Anaconda Prompt: cd file_path_here where file_path_here is replaced with the location of the R.exe that you found.\nRun R from within Anaconda Prompt by entering in R.exe. This opens an R session inside Anaconda Prompt. From here, enter the following commands in this order:\n\ninstall.packages(\"IRkernel\")\nIR:kernel::installspec()\n\nIf prompted to select a IR kernel mirror, select 12 (CANADA - MB).\n\nTo verify that everything is working, open Anaconda Prompt and type jupyter lab. Jupyter Lab should launch and display both a Python and R kernel.\n\nHaving trouble? Check the instructions here: https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/.\nMac OS Installation:\n\nInstall Anaconda from https://www.anaconda.com/download\n\nProvide your email and an installation link will be sent to you\nInstall the full version of Anaconda (not miniconda)\n\nInstall and setup the IR Kernel\n\nOpen R and navigate to the Console (see below).\n\n\n\nYour console may have a different appearance! Mine‚Äôs in dark mode.\n\n\nInstall the necessary packages by entering\ninstall.packages(c(\"repr\", \"IRdisplay\", \"evaluate\", \"crayon\", \"pbdZMQ\", \"devtools\", \"uuid\", \"digest\"))\ndevtools::install_github(\"IRkernel/IRkernel\")\nExit RStudio.\n\nConfigure the IRkernel from within R\n\nIt‚Äôs important that these next commands are done from within the version of R that you want to link to Jupyter Lab (R version 5.4.1, for example)\nLaunch R (NOT RSTUDIO! This is typically found in /usr/bin/R. If you can‚Äôt find it, open the Terminal application and type in which R. This will provide you with the path to R. Then, open a Finder window and at the top of your screen hit Go -&gt; go to folder and paste everything in the path except R (i.e., /usr/bin/). Scroll through and find R and open it.\nIn the R application, run IRkernel::installspec()\nIf prompted to choose a IRkernel mirror, select 12 (Canada - MB).\n\nLaunch Anaconda, and open a Jupyter Lab and you should see an R kernel available.\n\nHaving trouble? Check out https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/.\n\n\n\nGit is a version control software. Github is a cloud-based platform (built on Git) for sharing code.\n\nRegister a Github account at github.com (if you don‚Äôt already have one).\n\nCreate a username that uses your actual name. Shorter is better! For example, mine is grcetmpk. See this for more information.\nYou don‚Äôt need to download any apps.\n\nInstall Git (more info here)\n\nSee if Git is already installed. For Mac OS, on the Terminal (Mac) type which git. For Windows, go to Command Prompt and type where git. If you get an error of git: command not found, you do not have git installed yet.\nWindows:\n\nInstall Git for Windows (https://gitforwindows.org/)\nWhen asked about ‚ÄúAdjusting your PATH environment‚Äù, make sure to select ‚ÄúGit from the command line and also from 3rd-party software‚Äù. Otherwise, keep the defaults.\n\nMac OS:\n\nInstall XCode Command Line Tools by opening Terminal and typing xcode-select --install (more info here)\nIn Terminal, enter git config. Click install.\n\n\nConfigure Git: In RStudio, navigate to the Terminal or Shell (see below).\n\n\n\nIf using Windows, you will have a Shell, not a Terminal.\n\n\nwithin the Terminal (Mac) or Shell (Windows) (Tools &gt; Terminal/Shell) do:\ngit config --global user.name \"your_github_username\"\ngit config --global user.email \"your_email_you_used_for_github@example.com\"\ngit config --global --list\n\nIf you are having issues, you could use the usethis package in R. See here.\n\nGet your Personal Access Token (PAT)\n\nOption 1: Go to to https://github.com/settings/tokens and click ‚ÄúGenerate token‚Äù. Describe the token‚Äôs purpose in the Note field, e.g.¬†‚Äúpersonal-macbook‚Äù or ‚ÄúStat545Installation‚Äù. Select ‚Äúrepo‚Äù, ‚Äúuser‚Äù, and ‚Äúworkflow‚Äù for scopes. Save this token somewhere so you can use it again later, such as a password manager.\nOption 2: From R, execute usethis::create_github_token() (you may have to install the usethis package first by first running install.packages(\"usethis\")). Describe the token‚Äôs purpose in the Note field, e.g.¬†‚Äúpersonal-macbook‚Äù or ‚Äústat545installation‚Äù.\n\nFrom R (in the console), run install.packages(\"gitcreds\") if you haven‚Äôt already.\nExecute gitcreds::gitcreds_set() and enter the PAT that you just made when prompted.\n\n\n\n\nDirections written by Vincenzo Coia, Jenny Bryan, and Grace Tompkins",
    "crumbs": [
      "Lecture 1A: Installation"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1a_installation.html#software-and-troubleshooting",
    "href": "webpages/lectures_i/lec1a_installation.html#software-and-troubleshooting",
    "title": "Lecture 1A: Installation",
    "section": "",
    "text": "The goal of this lecture is to learn how to install and setup key software for use in the course.\nTAs are available in class on Imagine Day from 9am-10:30am on Tuesday September 2nd to aid with installation. I highly recommend you join if you haven‚Äôt used RStudio, Jupyter, or GitHub before.\n\n\nYou may encounter some material that implicitly assumes that you are using a Mac. For example, they might point you to a Terminal app, or ask you to use Unix commands like which or ls. Here is a cheatsheet that helps you convert between Windows command line (‚ÄúDOS‚Äù) and Mac command line (‚ÄúUNIX‚Äù). One thing that‚Äôs missing is the equivalent to Unix‚Äôs which; the closest equivalent in DOS is where.\n\n\n\nR and RStudio The main programming language used in the class is R and our main IDE (a text editor with helpful features for writing and running code) is RStudio. The following instructions are adapted from Chapter 5 of Jenny Bryan‚Äôs ‚Äúhappy git‚Äù book.\n\nInstall (or update to) the latest release R on your computer (4.5.1 currently):\n\nWindows: https://cran.r-project.org/bin/windows/base/\nMac: https://cran.r-project.org/bin/macosx/\n\nInstall RStudio\n\nhttps://posit.co/download/rstudio-desktop/\n\n\nEven if you already have R/RStudio, please update them to the most recent version!\n\n\n\nYou will need another IDE for R (Jupyter Notebook) and an R kernel called ‚ÄòIR Kernel‚Äô (needed to run R code within Jupyter) to work on the autograded worksheets. This is because the autograder we use plays well with Jupyter.\nThe following instructions are adapted from Rich Pauloo.\nPC Installation:\n\nInstall Anaconda from https://www.anaconda.com/download\n\nProvide your email and an installation link will be sent to you\nInstall the full version of Anaconda (not miniconda)\n\nInstall and setup the IR Kernel\n\nFind the location of R.exe on your computer (the location probably looks like C:\\Program Files\\R\\R-4.5.1\\bin). If you can‚Äôt find it, launch Command Prompt (CMD) and execute where R. The output should be the path to the file R.exe.\nOpen the Anaconda Prompt application. Enter the following command into Anaconda Prompt: cd file_path_here where file_path_here is replaced with the location of the R.exe that you found.\nRun R from within Anaconda Prompt by entering in R.exe. This opens an R session inside Anaconda Prompt. From here, enter the following commands in this order:\n\ninstall.packages(\"IRkernel\")\nIR:kernel::installspec()\n\nIf prompted to select a IR kernel mirror, select 12 (CANADA - MB).\n\nTo verify that everything is working, open Anaconda Prompt and type jupyter lab. Jupyter Lab should launch and display both a Python and R kernel.\n\nHaving trouble? Check the instructions here: https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/.\nMac OS Installation:\n\nInstall Anaconda from https://www.anaconda.com/download\n\nProvide your email and an installation link will be sent to you\nInstall the full version of Anaconda (not miniconda)\n\nInstall and setup the IR Kernel\n\nOpen R and navigate to the Console (see below).\n\n\n\nYour console may have a different appearance! Mine‚Äôs in dark mode.\n\n\nInstall the necessary packages by entering\ninstall.packages(c(\"repr\", \"IRdisplay\", \"evaluate\", \"crayon\", \"pbdZMQ\", \"devtools\", \"uuid\", \"digest\"))\ndevtools::install_github(\"IRkernel/IRkernel\")\nExit RStudio.\n\nConfigure the IRkernel from within R\n\nIt‚Äôs important that these next commands are done from within the version of R that you want to link to Jupyter Lab (R version 5.4.1, for example)\nLaunch R (NOT RSTUDIO! This is typically found in /usr/bin/R. If you can‚Äôt find it, open the Terminal application and type in which R. This will provide you with the path to R. Then, open a Finder window and at the top of your screen hit Go -&gt; go to folder and paste everything in the path except R (i.e., /usr/bin/). Scroll through and find R and open it.\nIn the R application, run IRkernel::installspec()\nIf prompted to choose a IRkernel mirror, select 12 (Canada - MB).\n\nLaunch Anaconda, and open a Jupyter Lab and you should see an R kernel available.\n\nHaving trouble? Check out https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/.\n\n\n\nGit is a version control software. Github is a cloud-based platform (built on Git) for sharing code.\n\nRegister a Github account at github.com (if you don‚Äôt already have one).\n\nCreate a username that uses your actual name. Shorter is better! For example, mine is grcetmpk. See this for more information.\nYou don‚Äôt need to download any apps.\n\nInstall Git (more info here)\n\nSee if Git is already installed. For Mac OS, on the Terminal (Mac) type which git. For Windows, go to Command Prompt and type where git. If you get an error of git: command not found, you do not have git installed yet.\nWindows:\n\nInstall Git for Windows (https://gitforwindows.org/)\nWhen asked about ‚ÄúAdjusting your PATH environment‚Äù, make sure to select ‚ÄúGit from the command line and also from 3rd-party software‚Äù. Otherwise, keep the defaults.\n\nMac OS:\n\nInstall XCode Command Line Tools by opening Terminal and typing xcode-select --install (more info here)\nIn Terminal, enter git config. Click install.\n\n\nConfigure Git: In RStudio, navigate to the Terminal or Shell (see below).\n\n\n\nIf using Windows, you will have a Shell, not a Terminal.\n\n\nwithin the Terminal (Mac) or Shell (Windows) (Tools &gt; Terminal/Shell) do:\ngit config --global user.name \"your_github_username\"\ngit config --global user.email \"your_email_you_used_for_github@example.com\"\ngit config --global --list\n\nIf you are having issues, you could use the usethis package in R. See here.\n\nGet your Personal Access Token (PAT)\n\nOption 1: Go to to https://github.com/settings/tokens and click ‚ÄúGenerate token‚Äù. Describe the token‚Äôs purpose in the Note field, e.g.¬†‚Äúpersonal-macbook‚Äù or ‚ÄúStat545Installation‚Äù. Select ‚Äúrepo‚Äù, ‚Äúuser‚Äù, and ‚Äúworkflow‚Äù for scopes. Save this token somewhere so you can use it again later, such as a password manager.\nOption 2: From R, execute usethis::create_github_token() (you may have to install the usethis package first by first running install.packages(\"usethis\")). Describe the token‚Äôs purpose in the Note field, e.g.¬†‚Äúpersonal-macbook‚Äù or ‚Äústat545installation‚Äù.\n\nFrom R (in the console), run install.packages(\"gitcreds\") if you haven‚Äôt already.\nExecute gitcreds::gitcreds_set() and enter the PAT that you just made when prompted.\n\n\n\n\nDirections written by Vincenzo Coia, Jenny Bryan, and Grace Tompkins",
    "crumbs": [
      "Lecture 1A: Installation"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html",
    "href": "webpages/lectures_i/lec1b_introR.html",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "",
    "text": "For today‚Äôs lecture, we are going to go through the some important information related to the course and jump right into some coding in R using an interactive worksheet and Jupyter Notebooks.\n\n\nWe will be using various technologies throughout this course which you should familiarize yourself with. The main platforms we‚Äôll be using are;\n\nThe course website (this one!),\nCanvas (for submitting assignments),\nSlack (for communications),\nRStudio (for writing R code),\nGitHub (for version control and collaboration), and\nJupyter notebooks (for interactive worksheets).\n\nIf you‚Äôve never used some of these before, that‚Äôs absolutely OK. This course is made to guide you through the basics of many of these platforms.\n\n\n\nAll of the important information is in the syllabus, which you can navigate to at the top of this page. There are a few items I‚Äôd like to emphasize:\n\nSTAT 545 A has frequent worksheets. These are graded based on completion. For example, if you complete all 15 questions, you will score 100% for that worksheet. Complete 14/15? You‚Äôll get a 93%. They are relatively straight forward and will guide you through the topics we talked about that week.\nEveryone gets one ‚Äúpass‚Äù for a late worksheet. After the first occurrence, a 0 will be awarded for any late worksheet.\nSTAT 545 A has a mini data analysis and collaborative project worth most of your marks. These are not graded on the basis of how sophisticated your statistical analysis is, but on the quality of your code and workflow. A grading rubric will be posted for each.\nThere is a zero tolerance policy for late projects and analyses.\nStay home if you‚Äôre sick. Fill out an Academic Concession Self Declaration form (linked on Canvas) if you miss an assessment due to illness. Accommodations will be given on a case-by-case basis.\nBring a charged laptop to class!\nAll communications are to be done on Slack - do not email me questions unless they are of a sensitive nature (i.e., an academic concession form).\nDon‚Äôt plagiarize code or assessments.\n\nBut please - read the syllabus :)\n\n\n\nLectures for STAT545 are designed to be more interactive than a traditional statistics lecture. The class will begin with a short summary of the previous class, followed by an introduction to that day‚Äôs topic. For most of the lectures, we will be going through the interactive worksheets (yes, the ones that you receive marks for and yes, prior to the deadline). This will give provide you with dedicated time to work on the assessments in class with access to the instructor and the TAs.\nLectures build on top of each other and it is crucial to stay on track as we progress through this course.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html#welcome-to-stat545",
    "href": "webpages/lectures_i/lec1b_introR.html#welcome-to-stat545",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "",
    "text": "For today‚Äôs lecture, we are going to go through the some important information related to the course and jump right into some coding in R using an interactive worksheet and Jupyter Notebooks.\n\n\nWe will be using various technologies throughout this course which you should familiarize yourself with. The main platforms we‚Äôll be using are;\n\nThe course website (this one!),\nCanvas (for submitting assignments),\nSlack (for communications),\nRStudio (for writing R code),\nGitHub (for version control and collaboration), and\nJupyter notebooks (for interactive worksheets).\n\nIf you‚Äôve never used some of these before, that‚Äôs absolutely OK. This course is made to guide you through the basics of many of these platforms.\n\n\n\nAll of the important information is in the syllabus, which you can navigate to at the top of this page. There are a few items I‚Äôd like to emphasize:\n\nSTAT 545 A has frequent worksheets. These are graded based on completion. For example, if you complete all 15 questions, you will score 100% for that worksheet. Complete 14/15? You‚Äôll get a 93%. They are relatively straight forward and will guide you through the topics we talked about that week.\nEveryone gets one ‚Äúpass‚Äù for a late worksheet. After the first occurrence, a 0 will be awarded for any late worksheet.\nSTAT 545 A has a mini data analysis and collaborative project worth most of your marks. These are not graded on the basis of how sophisticated your statistical analysis is, but on the quality of your code and workflow. A grading rubric will be posted for each.\nThere is a zero tolerance policy for late projects and analyses.\nStay home if you‚Äôre sick. Fill out an Academic Concession Self Declaration form (linked on Canvas) if you miss an assessment due to illness. Accommodations will be given on a case-by-case basis.\nBring a charged laptop to class!\nAll communications are to be done on Slack - do not email me questions unless they are of a sensitive nature (i.e., an academic concession form).\nDon‚Äôt plagiarize code or assessments.\n\nBut please - read the syllabus :)\n\n\n\nLectures for STAT545 are designed to be more interactive than a traditional statistics lecture. The class will begin with a short summary of the previous class, followed by an introduction to that day‚Äôs topic. For most of the lectures, we will be going through the interactive worksheets (yes, the ones that you receive marks for and yes, prior to the deadline). This will give provide you with dedicated time to work on the assessments in class with access to the instructor and the TAs.\nLectures build on top of each other and it is crucial to stay on track as we progress through this course.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html#coding-in-r-the-basics",
    "href": "webpages/lectures_i/lec1b_introR.html#coding-in-r-the-basics",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "Coding in R: The Basics",
    "text": "Coding in R: The Basics\nLet‚Äôs get started! By this point, I‚Äôm assuming you‚Äôve successfully installed R, RStudio, Github, and Jupyter notebooks. If you haven‚Äôt, check out the previous lecture for a guide to setting up this software.\nBefore diving into the worksheet, let‚Äôs talk about R. R is an open source programming language designed for statistical computing and data analysis. It is a commonly used programming language alongside Python and SAS, which we will not be covering in this course.\n\nCalculations\nIn its simplest form, R is a calculator. For example, we can type 1 + 2 in the console of R (we will be using RStudio) will spit out the answer of 3.\n\n1 + 2\n\n[1] 3\n\n\nThe [1] in the answer can be ignored for now.\nR can also be used to do more complex expressions, such as \\((450 - 15)^2/(5 + 7\\times4)\\), which we would write in R with:\n\n(450-15)^2/(5+7*4)\n\n[1] 5734.091\n\n\n\n\nVariables\nR can also be used to store values as a variable. To assign a value to a variable in R, we use the &lt;- symbol (the less than symbol followed by the minus sign). For example, if I wanted to store the number of apartments I‚Äôve lived in since moving out for university, I could assign this to a variable called apartments_lived_in by:\n\napartments_lived_in &lt;- 4\n\nThen, if I later wanted to use this value, I could simply execute\n\napartments_lived_in\n\n[1] 4\n\n\nwhich you can see stores the value of 4! I can also do math on this variable, for example multiplying it by 2:\n\napartments_lived_in*2\n\n[1] 8\n\n\nVariables can also store the results of expressions, which we will dive into in Worksheet 1.\n\n\nData Structures\nR isn‚Äôt just a calculator. R can handle different data structures (which are just objects that contain data) including strings, vectors, and data frames (just to name a few). We will go over the basics of these structures in this section.\n\nStrings\nA string is a R (often called character data) is a string of characters enclosed in quotations. For example, I could store my name in a variable called name:\n\nname &lt;- \"Grace\"\n\nand access it later by typing name\n\nname\n\n[1] \"Grace\"\n\n\nStrings can also have write space, such as\n\nmanifestation &lt;- \"I'm a great R coder!\"\nmanifestation\n\n[1] \"I'm a great R coder!\"\n\n\nYou can use single ' or double \" quotation marks to wrap around the string - just be consistent!\n\n\n\n\n\n\nTip\n\n\n\nIn some worksheets, questions are multiple choice. Ensure that you type your answer as a string, i.e., my_answer &lt;- \"A\".\n\n\n\n\nNumeric Vectors\nA vector is an ordered list of items of the same type. A numeric vector is an ordered list of numbers.\nVectors are created in R using the c() function, with elements separated by commas. For example, suppose someone wanted to store the number of roommates they lived with in their four apartments. They had 4 roommates in their first apartment, then 2 in their next, followed by 3, and finally lived alone with 0 roommates. We can save this information in a vector named roommates using the following code:\n\nroommates &lt;- c(4, 2, 3, 0)\n\nTo see the contents of a vector, simply type its name in the console and run the code\n\nroommates\n\n[1] 4 2 3 0\n\n\nWe can access each element of the vector by indexing it with []. In R, unlike some other programming languages, the index starts at 1. So if you‚Äôd like to access the first element of the vector, you can use [1]. For example, to see the number of roommates in my first apartment, I could use\n\nroommates[1]\n\n[1] 4\n\n\nOr view the number of roommates in my third apartment using:\n\nroommates[3]\n\n[1] 3\n\n\nWe can also perform functions on vectors! Suppose we wanted to calculate the total number of occupants in each apartment (including myself). I need to add one person to each apartment! To do so, I can make a new variable called totaloccupants which is equal to roommates plus one:\n\ntotaloccupants &lt;- roommates + 1\ntotaloccupants\n\n[1] 5 3 4 1\n\n\nWe will dive more into functions on vectors in Worksheet 1.\n\n\nLogical Vectors\nA logical vector is a vector where the elements are a logical statement containing TRUE or FALSE. Let‚Äôs see how we can create a vector indicating whether or not there were more than two roommates in a given apartment. We can store this as a variable, named more_than_two_roommates using\n\nmore_than_two_roommates &lt;- roommates &gt; 2\nmore_than_two_roommates\n\n[1]  TRUE FALSE  TRUE FALSE\n\n\nFrom the output, you can see that this statement is true for apartments 1 and 3, indicating there were more than two roommates for these apartments.\n\n\nOther useful functions on vectors\nR has a number of built in functions that are useful for exploring vectors. We can check the length (number of elements) of a vector using the length() function:\n\nlength(roommates)\n\n[1] 4\n\n\nThis answer makes sense as we had data for four apartments. We can also look at the types of data stored in vectors using the typeof function\n\ntypeof(roommates)\n\n[1] \"double\"\n\ntypeof(totaloccupants)\n\n[1] \"double\"\n\ntypeof(more_than_two_roommates)\n\n[1] \"logical\"\n\n\ndouble is a type of numeric data. logical is the type of data that stores TRUE/FALSE.\n\n\nDataframes\nDataframes are a powerful tool for storing multidimensional data. For example, we could have data on housing for multiple people, including the rent paid, number of roommates, city, etc. Dataframes are a convenient way to store such information. Suppose we have data on three individuals stored in the dataframe housingdata. To access it, type housingdata in the R Console.\n\nhousingdata\n\n   Name NumRooms NumOccupants Rent      City\n1 Grace        2            2 2700 Vancouver\n2   Mei        3            4 5000   Toronto\n3   Sam        1            1 1900   Halifax\n\n\nWe see that Grace rents a 2 bedroom apartment, with two total occupants, and the total rent is $2700 per month in Vancouver. Mei lives in Toronto and has a 3 bedroom apartment shared between 4 people, and the total rent is $5000. Sam lives alone in a one bedroom apartment in Halifax, and pays $1900.\nWe will focus more on dataframes in a coming lecture, but I wanted to mention them here.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html#worksheet-a1",
    "href": "webpages/lectures_i/lec1b_introR.html#worksheet-a1",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "Worksheet A1",
    "text": "Worksheet A1\nNow it‚Äôs your turn to use R! Work through Worksheet A1 on your own and reach out on Slack if you have any issues. Refer to the previous lecture if you need guidance on how to access Worksheets on Jupyter Notebooks.\n\n\n\n\n\n\nNote\n\n\n\nWorksheet A1 is NOT going to be graded. However, I highly recommend going through it to practice using Jupyter Notebooks and to get a handle on R. Future worksheets will be graded.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html#what-to-do-when-youre-stuck",
    "href": "webpages/lectures_i/lec1b_introR.html#what-to-do-when-youre-stuck",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "What to do when you‚Äôre stuck",
    "text": "What to do when you‚Äôre stuck\nWorking with technology can be hard. Coding can be especially hard. Getting stuck is very common in both cases.\nBefore running to Slack, try searching for the answer yourself. This is an extremely important real-world skill! When you‚Äôre conducting your own analyses down the road, you may not have anyone to directly ask for help.\nTry:\n\nGoogling your error codes (removing highly specific information like variable names)\nGoogling the problem (i.e., R dataframe can‚Äôt rename columns)\nSearch stackoverflow and include the [r] tag. Or the [ggplot2] tag. Or the [plyr] tag. You get the idea.\n\n\n\n\n\n\n\nCaution\n\n\n\nBeware of AI tools: sometimes they‚Äôre helpful, and sometimes they‚Äôre not.\n\n\nWhile I encourage you to search for answers on your own, don‚Äôt fret if you‚Äôre stuck. We‚Äôre here to help on Slack! Review the posting guidelines on the Syllabus so your questions go to the appropriate channel.\n\nAttribution\nExample created by Grace Tompkins. Notes originally created by Vincenzo Coia.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html",
    "href": "webpages/lectures_i/lec2A_reproducibility.html",
    "title": "Lecture 2A: Reproducibility",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nUse basic markdown features.\nWrite documents in markdown.\nChoose whether html or pdf is an appropriate output.\nStyle an .Rmd document by editing the YAML header.\nCustomize code chunk output using Rmd code chunk.\nRender your finalized document to HTML & PDF.",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html#learning-objectives",
    "href": "webpages/lectures_i/lec2A_reproducibility.html#learning-objectives",
    "title": "Lecture 2A: Reproducibility",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nUse basic markdown features.\nWrite documents in markdown.\nChoose whether html or pdf is an appropriate output.\nStyle an .Rmd document by editing the YAML header.\nCustomize code chunk output using Rmd code chunk.\nRender your finalized document to HTML & PDF.",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html#reproducibility",
    "href": "webpages/lectures_i/lec2A_reproducibility.html#reproducibility",
    "title": "Lecture 2A: Reproducibility",
    "section": "Reproducibility",
    "text": "Reproducibility\nReproducibility is the ability of an independent researcher to repeat an experiment using the same data and workflow to obtain the same results [1]. One way to ensure reproducible research is sharing clear details on the analysis and providing the code used to produce the results. Reproducibility is often confused with replication. However, replication is a separate concept where the results of a study should be validated on an independent study using new data. A ‚Äúgood‚Äù study is both replicable and reproducible.\nThere are also ethical benefits to reproducible research [1]. Performing open research can reduce the chance of data fabrication or other ethical issues such as p-hacking, where a researcher tests a number of hypotheses until they find one that is statistically significant. Open, transparent research poses a sense of accountability on the researcher(s). Of course, you can‚Äôt always share data (for example, health data containing personal identifying information), but you should share as much as is possible. Always check with your ethics board or principal investigator before sharing data online.\nReproducible studies can also advance research by providing the code used for analysis. Not only can we reproduce the study to make the findings more trustworthy, but we can learn more about how the analysis was performed and possibly apply it to other studies.\nReproducible research can also force you to have better, more automated workflows. The first analysis I ever did in R, I was manually changing things in excel documents, and then saving them in a certain place, and then using R to fit a model, and then exporting the data, and then changing the worksheet format, and so on. I had a sticky note of instructions on how to produce the results on my desk. This was neither reproducible nor productive for my time. While automating some steps and using tools like GitHub for version control can be more work upfront, it can save you a lot of headaches down the road. It is something I personally wish I learned to use earlier in my career.",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html#r-markdown",
    "href": "webpages/lectures_i/lec2A_reproducibility.html#r-markdown",
    "title": "Lecture 2A: Reproducibility",
    "section": "R Markdown",
    "text": "R Markdown\nUsing an editor like MS Word is like painting: you decorate the page with text, graphs, and tables, making sure things are positioned, sized, and coloured appropriately.\nThis is great for a letter to a friend, but is less great for scientific work, because it hampers reproducibility and shareability.\nR Markdown lets you write a single ‚Äúblueprint‚Äù for your analysis that includes everything - positioning/sizing/colouring/formatting, analysis/graph/table code and results, and text ‚Äì and then ‚Äúknit‚Äù all of those components together into a complete report with a single button press.\nThere is a large community of R Markdown users, making it easy to find tutorials and blog posts about a ton of different types of documents. We‚Äôre going to start simple and dive right into R Markdown.\n\nGetting Started with Markdown\nIn lecture, we are going to work through this online Markdown tutorial together in small groups. Challenge yourself to meet someone new in the class!\nAfter completing the tutorial, try making your own R Markdown document!\n\nIn RStudio, go to ‚ÄúFile‚Äù -&gt; ‚ÄúNew File‚Äù -&gt; ‚ÄúMarkdown File‚Äù\nWrite a Markdown document all about you that includes:\n\nA header\nA link to your GitHub profile\nA list of courses you‚Äôre taking this semester\n\nClick the ‚ÄúPreview‚Äù button to generate an output .html file from the source .md file.\n\n\n\nInstall RMarkdown\n\nOpen a new .Rmd file in RStudio (‚ÄúFile‚Äù &gt; ‚ÄúNew File‚Äù &gt; ‚ÄúRMarkdown‚Ä¶‚Äù). Add ‚ÄúSTAT545_Lecture_2‚Äù as your title and save the other default options.\nTo get started with using R Markdown, you‚Äôll need to install the rmarkdown R package. You might automatically be prompted to do this; accept, if so. If not, you will have to manually install the package.\ninstall.packages('rmarkdown')\nAfter installation, install the DT package:\ninstall.packages('DT')\nClick ‚Äúknit‚Äù.\n\nThings to notice:\n\nThe YAML header is contained between two ‚Äî at the top of the .Rmd source, and contains metadata on the document. This is where you specify the output type to be HTML.\nText is formatted using Markdown. There are three chunks of R code, and knitting executes the R code and displays the output in the output file.\n\nHow does it all work?\nThe key drivers under the hood are knitrand Pandoc! When you press ‚ÄúKnit‚Äù, R Markdown passes the .Rmdfile to knitr, which executes all of the code and creates a new .md file including the code and output. Then, that .md file is processed into the final output format (e.g.¬†.html) by pandoc.\n\n\n\n\n\n\nExercise: Edit Your YAML in Small Groups:\n\n\n\nRun ?html_document from your R console and/or check out Yihui Xie‚Äôs RMarkdown book to:\n\nAdd a floating table of contents\nAdd a theme.\n\nIf this was easy, then try to figure out how to knit to a pdf document!\n\n\n\n\n\n\n\n\nInstructor demo: mtcars Report\n\n\n\nTo follow along, download the demonstration.Rmd file from the STAT545 GitHub and open it in RStudio.\n\n\n\nExploring Code Chunks\n\nAdd a code chunk below the first paragraph in the ‚ÄúMotor Trend Car Road Tests data‚Äù section of the .Rmd file. Either select ‚ÄúCode‚Äù -&gt; ‚ÄúInsert Chunk‚Äù, or use a keyboard shortcut: cmd + option + I(MAC) / ctrl + alt + i(WINDOWS).\nIn this code chunk, print out the mtcars data frame to explore the output. (Yes, this object comes shipped with R.)\nRun that chunk interactively using the green ‚Äòplay‚Äô button.\nNow try out the DT::datatable() function on mtcars in this new chunk, and knit the file (to html, ideally).\nAdd an in-line code chunk specifying the number of rows of the mtcars dataset in place of the hardcoded number ‚Äú32 automobiles‚Äù. Hint: nrow().\nFill in the document with markdown commentary for each of the code chunks! A few notes go a long way towards improving the readability of the report.\n\n\n\nCode Chunk Options\n\n\n\n\n\n\nTip\n\n\n\nGot lost in the demonstration? No problem, just open a new .Rmd file in RStudio via ‚ÄúFile‚Äù -&gt; ‚ÄúNew File‚Äù -&gt; ‚ÄúR Markdown‚Ä¶‚Äù, and just press ‚ÄúOK‚Äù, and resume!)\n\n\nJust like YAML is metadata for the Rmd document, code chunk options are metadata for the code chunk. Specify them within the {r} at the top of a code chunk, separated by commas. For a list of chunk options, check out Yihui Xie‚Äôs knitr book. Let‚Äôs try some:\n\nHide the code from the output with echo = FALSE.\nChange the figure width and height with fig.width = 5 and fig.height = 3.\nKnit the results. Can you spot the differences?\n\n\n\n\n\n\n\nExercise 2\n\n\n\nIn the instructor demo, we prettied up a nice report about mtcars together. But suddenly, you receive an email from your collaborator who collected the mtcars data, who says that the data on Mazda RX4, the Valiant, and the Volvo 142E were transcribed wrong from the magazine! They‚Äôre going to work on correcting them, but in the mean time, they‚Äôd like to re-run the analysis with those three cars excluded.\nIn small groups, prepare an updated report by updating your .Rmd appropriately, then re-knitting it. Then discuss: in this case, how did using the RMarkdown workflow rather than copying and pasting R output to MS Word help prevent the creation of non-reproducible results?",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html#resources",
    "href": "webpages/lectures_i/lec2A_reproducibility.html#resources",
    "title": "Lecture 2A: Reproducibility",
    "section": "Resources",
    "text": "Resources\nHere are a number of resources that may help supplement you with today‚Äôs lesson:\n\nSTAT 545 Episode 3-A: Reproducible Reports with R Markdown Some additional resources that you might find useful:\nThe Official R Markdown Tutorial from the ‚ÄúIntroduction‚Äù up to and including the ‚ÄúInline Code‚Äù section.\nR Markdown cheat sheet\n\n\n\n\n\n\n\nTip\n\n\n\nMany cheat sheets can be found from RStudio: go to ‚ÄúHelp‚Äù -&gt; ‚ÄúCheatsheets‚Äù.\n\n\n\nAttribution\nThis section was written by Grace Tompkins. Demonstration by Ic√≠ar Fern√°ndez Boyano. Inspiration for activity ideas drawn from Nicholas Tierney‚Äôs R Markdown for Scientists book, the R Markdown for Medicine workshop materials, and the UBC MDS program.",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html",
    "title": "Lecture 2B: Version Control",
    "section": "",
    "text": "From today‚Äôs topic, students are anticipated to be able to:\n\nuse git on their own computer (locally).\nconnect between a local git repository and that repository on GitHub, using RStudio.\nmake commits in git using RStudio.\nmake a branch in git using RStudio or GitHub.\nuse collaborative GitHub features such as Issues and pull requests.\n\nAfter this class, you should be able to start working on your Collaborative Project.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#learning-objectives",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#learning-objectives",
    "title": "Lecture 2B: Version Control",
    "section": "",
    "text": "From today‚Äôs topic, students are anticipated to be able to:\n\nuse git on their own computer (locally).\nconnect between a local git repository and that repository on GitHub, using RStudio.\nmake commits in git using RStudio.\nmake a branch in git using RStudio or GitHub.\nuse collaborative GitHub features such as Issues and pull requests.\n\nAfter this class, you should be able to start working on your Collaborative Project.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#get-acquainted-with-github",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#get-acquainted-with-github",
    "title": "Lecture 2B: Version Control",
    "section": "Get Acquainted with GitHub",
    "text": "Get Acquainted with GitHub\n\nRepositories, Organizations, and Personal Accounts\nA repository stores files and the history of the files; the usual convention is to use a single repository to organize a single project.\nGitHub is a place where repositories can live online. Being online provides us a way to share and collaborate on projects. It also serves as a backup for your project.\nExample 1: Grace‚Äôs GitHub page\nExample 1: The STAT 545 webpage\nThe first repository lives under Grace‚Äôs personal Github account. The second repository lives under the UBC-STAT organization. Organizations are useful if you have lots of different projects with a common theme which lots of people are collaborating on.\n\n\n\n\n\n\nInstructor Demo: GitHub\n\n\n\nWe will spend some time exploring some GitHub basics, with some real examples of repositories.\n\n\n\n\nUseful Github tips for the course\n\nAll of your projects in this class will live in the STAT 545 @ UBC Organization.\nWhen you watch a Github repo, you get notifications when things happen in them. So if you ‚ÄúWatch‚Äù the STAT 545 webpage repo, then you will get email notifications when I update the site!\nThe Issues page on a Github repo is a forum where Github users can bring up issues related to the repository. Our commmunication guidelines suggest that you post an Issue on your homework repo if you have concerns about your grade.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#create-your-own-repository",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#create-your-own-repository",
    "title": "Lecture 2B: Version Control",
    "section": "Create Your Own Repository",
    "text": "Create Your Own Repository\n\n\n\n\n\n\nExercise\n\n\n\nTry making your own Github repository and editing it on Github! (This exercise is slightly adapted from Data Carpentries.)\n\nGo to your GitHub profile. Eg. Mine is https://github.com/katieburak.\nCreate a new GitHub repository by clicking the + symbol in the top bar and using the dropdown menu to create a new repository.\nName your repository stat-545-demo-YOUR-NAME. In the description write ‚ÄúSTAT 545 Demo‚Äù. Check the box for initializing the repository for adding a README file.\nYou are now redirected to the repository main page. The repository page tells you you have 1 commit. Click on it to get to the history page. This tells you all the changes that have been tracked for the files in the repository so far.\nGo back to your repository main page. Click on README.md, then click ‚Äúedit this file‚Äù. Add the following information into the README.md file:\n\nYour name\nWhat kind of scientist do you tell people you are at dinner parties?\n\nCommit your changes: click the commit changes button, and briefly summarize the changes you‚Äôve made in the Commit message.\nCheck out the Github commit history again. Has anything changed?\n\n\n\n##Working Locally, and Synchronizing with Github\nWe will go through the Data Carpentries tutorial for this together. This demonstrates how to keep and work on the project files in a local repository on your machine, and how to keep it in sync with a remote Github repository.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#merging-conflicts",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#merging-conflicts",
    "title": "Lecture 2B: Version Control",
    "section": "Merging Conflicts",
    "text": "Merging Conflicts\nMerge conflicts happen when we‚Äôve created multiple versions of files that can‚Äôt be obviously combined into one definitive version.\nHere is an example of something that would not cause a merge conflict:\n\nAt 9am, my TA pulls from the STAT 545 repository, makes a local change to the course dashboard, and commits and pushes her changes.\nAt 10am, I forget to pull from the STAT 545 repository, and start working on the Day 1 notes locally.\nWhen I commit and push, Git is a bit confused, because I wasn‚Äôt working off of the ‚Äúfreshest‚Äù version of the STAT 545 repository - but since my TA and I were working on different lines of code, it will fairly seamlessly figure out that the right thing to do is to add my changes to the Day 1 notes to the current version of the STAT 545 repository online.\n\nHere is an example of something that WOULD cause a merge conflict:\n\nAt 9am, my TA and I both pull from the STAT 545 repository.\nAt 10am, my TA changes the front page to say ‚ÄúSTAT 555 @ UBC‚Äù, and commits/pushes those changes.\nAt 11am, I change the front page (without pulling!!!) to say ‚ÄúSTAT 777 @ UBC‚Äù.\nWhen I commit and push, Git doesn‚Äôt know what to do. Should it make the version that says ‚ÄúSTAT 555 @ UBC‚Äù or ‚ÄúSTAT 777 @ UBC‚Äù the definitive version? The push will fail, and Git will tell us we need to fix the conflict and then commit the result.\n\nHow do we fix this?\n\nPull.\nOpen the file that caused the merge conflict. You should see something like this:\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nSTAT 555 @ UBC\n=======\nSTAT 777 @ UBC\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; 526363991d21ed20e7e0c57b5e99d944ac5ce5aa\n\nThe stuff below the &lt;&lt;&lt;&lt;&lt;&lt;&lt; and above the ======= is what was in your local version; the stuff above the &gt;&gt;&gt;&gt;&gt;&gt;&gt; and below the ======= is what was in the remote conflicting version. Decide what you want to have on the offending line (e.g.¬†‚ÄúSTAT 555 @ UBC‚Äù), and replace the whole block of text above with that.\nSave and commit the file. (An informative message here might be ‚ÄúFixing a merge conflict.‚Äù) You should now be able to successfully push!\n\n\n\n\n\n\n\nExercise\n\n\n\nFind a partner. In this exercise, we will learn how to have different team members save their work separately on branches, and how to merge those changes to the main project branch.\n\nTeammate A adds Teammate B to their stat545-demo repository as a collaborator. (Go to Settings from the main repo page, then Access =&gt; Collaborators). This should send Teammate B an email with a collaboration invitation; accept that invitation.\nTeammate B clones Teammate A‚Äôs stat545-demo repository.\nOn their own computer, Teammate B will make a new branch in Teammate A‚Äôs stat545-demo repository. You can do this either on Github by clicking on ‚Äú1 branch‚Äù on the repo homepage then the green ‚ÄúNew branch‚Äù button, or on your own computer in R Studio with the ‚ÄúNew Branch‚Äù button.\nOn their own computer, Teammate B will create a new file in the newly created branch, then commit and push it.\nTeammate B will start a pull request (basically a request to merge content onto the main branch) on GitHub, by going to ‚ÄúPull Requests‚Äù -&gt; ‚ÄúNew Pull Request‚Äù, and selecting the branch you intend to merge to the main branch. In this pull request, include a comment and title indicating (at a high level) what the change made is about.\nTeammate A will follow the instructions here to merge the pull request.\n\nToo easy? Then either switch roles, or try creating a pull request that causes a merge conflict and resolving it!",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#resources",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#resources",
    "title": "Lecture 2B: Version Control",
    "section": "Resources",
    "text": "Resources\nToday‚Äôs class is a digest of the following resources:\n\nVideo lecture STAT 545 Episode 2-A: Git and GitHub for an Organized Project\nOnline tutorials:\n\nThe basic version control workflow (without branching): Happy git w R: Chapter 20.\nStarting with GitHub: Chapter 15: New project, GitHub first\nStarting with files on your computer, and didn‚Äôt set up git: Chapter 16: Existing project, GitHub first\nStarting with files on your computer, and did set up git: Chapter 17: Existing project, GitHub Last\n\n\nSome additional resources that you might find useful:\n\nRead the Understanding the GitHub flow to get a sense of branching.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html",
    "href": "webpages/lectures_i/lec3_dplyr.html",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nUse the five core dplyr verbs for data wrangling: select(), filter(), arrange(), mutate(), summarise().\nUse piping when implementing function chains.\nUse group_by() to operate within groups (of rows) with mutate() and summarise().\nUse across() to operate on multiple columns with summarise() and mutate().\n\nWe will spend two classes on this topic.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#learning-objectives",
    "href": "webpages/lectures_i/lec3_dplyr.html#learning-objectives",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nUse the five core dplyr verbs for data wrangling: select(), filter(), arrange(), mutate(), summarise().\nUse piping when implementing function chains.\nUse group_by() to operate within groups (of rows) with mutate() and summarise().\nUse across() to operate on multiple columns with summarise() and mutate().\n\nWe will spend two classes on this topic.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#why-data-manipulation",
    "href": "webpages/lectures_i/lec3_dplyr.html#why-data-manipulation",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Why Data Manipulation?",
    "text": "Why Data Manipulation?\nYou have a shiny new data set - great! You might be tempted to dive right in and start making pretty graphs and fitting cool models to your data. Not so fast! In practice, it‚Äôs very rare that you have the data in the exact right form to make the graph you want, or fit the model you want. You will need to start by manipulating your data into the right form: creating new variables, subsetting rows, renaming columns, etc.\nPlus, an important piece of data analysis output is tables that summarize the data in some way. For example, it is extremely standard practice in biomedical and public health studies to have the first table of any journal article summarize basic characteristics of the study population, possibly stratified by exposure. While these tables are less pretty than graphs, they can nevertheless be very insightful!\nAn even less exciting but perhaps even more important part of data analysis is simply checking the data for things like:\n\nPossible inconsistencies with your understanding of what the data set should contain\nPossible errors\nBasic info gathering: number of rows, number of columns, amount of missing data, etc.\n\nAll of these require data manipulation. We choose to use the dplyr (pronounced d-plier) package for this.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#tibbles",
    "href": "webpages/lectures_i/lec3_dplyr.html#tibbles",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Tibbles",
    "text": "Tibbles\nAs mentioned in Lecture 1A, data frames are useful tools for storing data. You can think of it as a spreadsheet of information, but in R. A tibble is a modern version of a basic data frame. To use tibbles, we first install the tibble package (if we haven‚Äôt already) and load it into R by:\n\n# install.packages(\"tibble\") # remove comment if not already installed\nlibrary(tibble)\n\nTibbles typically said to be more user friendly than standard R dataframes, and are easily used with tidyverse functions. More on that in a bit!\nWe can either load in pre-existing data frames (like from a .csv file or an R package), or create a tibble manually using the tibble() function. For example, we could use\n\ntibble(x = letters)\n\n# A tibble: 26 √ó 1\n   x    \n   &lt;chr&gt;\n 1 a    \n 2 b    \n 3 c    \n 4 d    \n 5 e    \n 6 f    \n 7 g    \n 8 h    \n 9 i    \n10 j    \n# ‚Ñπ 16 more rows\n\n\nto have a single column tibble of letters of the alphabet, or\n\nhousingdata &lt;- tibble(name = c(\"Grace\", \"Mei\", \"Steven\", \"Phuong\", \"Omar\", \"Richa\", \"Bruce\", \"David\"), \n                      numrooms = c(2, 3, 1, 4, 2, 1, 3, 2), \n                      rent_2024 = c(2665, 4900, 2900, 4950, 2400, 1000, 2800, 2350),\n                      rent_2025 = c(2700, 5000, 2900, 5000, 2500, 1000, 2800, 2400),\n                      city = c(\"Vancouver\", \"Toronto\", \"Halifax\", \"Vancouver\", \"Montreal\", \"Victoria\", \"Halifax\", \"Vancouver\"))\nhousingdata\n\n# A tibble: 8 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Mei           3      4900      5000 Toronto  \n3 Steven        1      2900      2900 Halifax  \n4 Phuong        4      4950      5000 Vancouver\n5 Omar          2      2400      2500 Montreal \n6 Richa         1      1000      1000 Victoria \n7 Bruce         3      2800      2800 Halifax  \n8 David         2      2350      2400 Vancouver\n\n\nWe can see that the tibble can store different data types (here we have both numeric data (‚Äúdbl‚Äù is short for double) and character data (‚Äúchr‚Äù is short for character).\nWe can also change an R data frame to a dibble. For example, the mtcars data set is available in the datasets package in R as a dataframe. We can load it as a tibble using:\n\nlibrary(datasets)\ntibble(mtcars)\n\n# A tibble: 32 √ó 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ‚Ñπ 22 more rows",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#dplyr-functions",
    "href": "webpages/lectures_i/lec3_dplyr.html#dplyr-functions",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "dplyr Functions",
    "text": "dplyr Functions\nTo use the dplyr functions, we need to install (if necessary) and load the dplyr package:\n\n# install.packages(\"dplyr\") #remove comment if not installed yet\nlibrary(dplyr)\n\nOnce loaded, we will have a number of new tools at our disposal. Here are a few functions we are going to review in this lecture:\n\nselect(): keep or remove certain columns\n\n\nSubsetting with select()\nselect() allows you to keep or remove columns. For example, in the housingdata dataset, say we only want the columns name and city. We use the select function where the first argument is the name of the tibble, and the other arguments are the names of the columns we wish to keep:\n\nselect(housingdata, name, city)\n\n# A tibble: 8 √ó 2\n  name   city     \n  &lt;chr&gt;  &lt;chr&gt;    \n1 Grace  Vancouver\n2 Mei    Toronto  \n3 Steven Halifax  \n4 Phuong Vancouver\n5 Omar   Montreal \n6 Richa  Victoria \n7 Bruce  Halifax  \n8 David  Vancouver\n\n\nNow, this didn‚Äôt alter the original data frame! If we wanted to save this reduced dataframe, we can name it to a new variable, such as\n\nhousingdata2 &lt;- select(housingdata, name, city)\nhousingdata2\n\n# A tibble: 8 √ó 2\n  name   city     \n  &lt;chr&gt;  &lt;chr&gt;    \n1 Grace  Vancouver\n2 Mei    Toronto  \n3 Steven Halifax  \n4 Phuong Vancouver\n5 Omar   Montreal \n6 Richa  Victoria \n7 Bruce  Halifax  \n8 David  Vancouver\n\n\nNow, housingdata2 contains only the rows we were interested in keeping, without overriding the original housingdata tibble. We can see that housingdata still contains all of the information from the original data set.\n\nhousingdata\n\n# A tibble: 8 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Mei           3      4900      5000 Toronto  \n3 Steven        1      2900      2900 Halifax  \n4 Phuong        4      4950      5000 Vancouver\n5 Omar          2      2400      2500 Montreal \n6 Richa         1      1000      1000 Victoria \n7 Bruce         3      2800      2800 Halifax  \n8 David         2      2350      2400 Vancouver\n\n\nWe can also use select() to indicate which columns to remove. For example, if I wanted all variables except name in my data set, I could do:\n\nselect(housingdata, -name)\n\n# A tibble: 8 √ó 4\n  numrooms rent_2024 rent_2025 city     \n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1        2      2665      2700 Vancouver\n2        3      4900      5000 Toronto  \n3        1      2900      2900 Halifax  \n4        4      4950      5000 Vancouver\n5        2      2400      2500 Montreal \n6        1      1000      1000 Victoria \n7        3      2800      2800 Halifax  \n8        2      2350      2400 Vancouver\n\n\n\n\nSubsetting with filter()\nThe filter() function allows you to specify which rows to keep in the tibble. The filter() function takes conditional statements and allows us to remove or keep rows based on these conditions.\nFor example, let‚Äôs say we wanted to keep only data where the rent in 2025 (rent_2025) is strictly larger than 2500. Then, we could use:\n\nfilter(housingdata, rent_2025 &gt; 2500)\n\n# A tibble: 5 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Mei           3      4900      5000 Toronto  \n3 Steven        1      2900      2900 Halifax  \n4 Phuong        4      4950      5000 Vancouver\n5 Bruce         3      2800      2800 Halifax  \n\n\nNow, only rows with rent_2025 &gt; 2500 are kept in the data frame.\nWe can also use the == sign to indicate that something is equivalent. For example, we may only be interested in observations in Vancouver. To do so, we can use:\n\nfilter(housingdata, city == \"Vancouver\")\n\n# A tibble: 3 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Phuong        4      4950      5000 Vancouver\n3 David         2      2350      2400 Vancouver\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe double == in the statement to indicate ‚Äúis equal to‚Äù! Further, as the variable of interest is a string (or character type), we need to use quotations around the city name ‚ÄúVancouver‚Äù.\n\n\nWe can also filter on multiple variables at the same time, even if they are different types. for example:\n\nfilter(housingdata, rent_2025 &gt; 2500, city == \"Vancouver\")\n\n# A tibble: 2 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Phuong        4      4950      5000 Vancouver\n\n\n\n\nLeveling Up with tidyselect()\nSometimes we will want to select columns that have something in common with their name. This is particularly useful when the number of columns is large (for example, think if we had historical rent data for many years). To do so, we can use helper functions in the tidyverse library. First, install (if necessary) and load in the tidyverse library\n\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nLet‚Äôs use the starts_with() function to select all columns that relate to rents. We can do this by:\n\nselect(housingdata, starts_with(\"rent\"))\n\n# A tibble: 8 √ó 2\n  rent_2024 rent_2025\n      &lt;dbl&gt;     &lt;dbl&gt;\n1      2665      2700\n2      4900      5000\n3      2900      2900\n4      4950      5000\n5      2400      2500\n6      1000      1000\n7      2800      2800\n8      2350      2400\n\n\nThis code returned a tibble where only the columns involving rents are included! Other useful helper functions include:\n\nstarts_with() finds variables that start with the given input\nends_with() finds variables that end with the given input\ncontains() finds variables that have the given input at any location in the name\n\nWhile for the example data set we are really only selecting two columns, using these functions allows your code to be more flexible as data may be added later for more years of rent, for example.\n\n\nCreating New Variables with mutate()\nSometimes we need to create another variable or column based on information already present in a tibble. For example, suppose we are interested in the cost per room, rather than total rent, in our data. We can create a new variable that is the rent divided by the number of rooms using mutate():\n\nmutate(housingdata, rent_per_room_2025 = rent_2025/numrooms)\n\n# A tibble: 8 √ó 6\n  name   numrooms rent_2024 rent_2025 city      rent_per_room_2025\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1 Grace         2      2665      2700 Vancouver              1350 \n2 Mei           3      4900      5000 Toronto                1667.\n3 Steven        1      2900      2900 Halifax                2900 \n4 Phuong        4      4950      5000 Vancouver              1250 \n5 Omar          2      2400      2500 Montreal               1250 \n6 Richa         1      1000      1000 Victoria               1000 \n7 Bruce         3      2800      2800 Halifax                 933.\n8 David         2      2350      2400 Vancouver              1200 \n\n\nWe can also clean this up by rounding our new variable to two decimal places using the round() function:\n\nmutate(housingdata, rent_per_room_2025 = round(rent_2025/numrooms,2))\n\n# A tibble: 8 √ó 6\n  name   numrooms rent_2024 rent_2025 city      rent_per_room_2025\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1 Grace         2      2665      2700 Vancouver              1350 \n2 Mei           3      4900      5000 Toronto                1667.\n3 Steven        1      2900      2900 Halifax                2900 \n4 Phuong        4      4950      5000 Vancouver              1250 \n5 Omar          2      2400      2500 Montreal               1250 \n6 Richa         1      1000      1000 Victoria               1000 \n7 Bruce         3      2800      2800 Halifax                 933.\n8 David         2      2350      2400 Vancouver              1200 \n\n\nAs we can see, the mutate() function took the data as the first argument, and then we listed the new variable name rent_per_room_2025 which we calculated by taking the rent in 2025 (rent_2025) and dividing it by the number of rooms in the house (numrooms). We wrapped round( x, 2) around the calculation to clean up the answer to two decimal places.\n\n\nThe Pipe Operator %&gt;%\nThe pipe operator (%&gt;%) is a convenient way to form a chain of commands on a tibble to perform multiple tasks at once.\nLet‚Äôs assume we want to modify a tibble using both select() and filter(). We can do so in one single line of code using the pipe operator. But for now, let‚Äôs start simple and use just one function using %&gt;%.\nLet‚Äôs say we want to subset our data and select only the rent and city columns on a tibble. We could use:\n\nselect(housingdata, starts_with(\"rent\"), city)\n\n# A tibble: 8 √ó 3\n  rent_2024 rent_2025 city     \n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1      2665      2700 Vancouver\n2      4900      5000 Toronto  \n3      2900      2900 Halifax  \n4      4950      5000 Vancouver\n5      2400      2500 Montreal \n6      1000      1000 Victoria \n7      2800      2800 Halifax  \n8      2350      2400 Vancouver\n\n\nwhich is a perfectly valid answer. However, we could also use the pipe operator, as:\n\nhousingdata %&gt;%\n  select(starts_with(\"rent\"), city)\n\n# A tibble: 8 √ó 3\n  rent_2024 rent_2025 city     \n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1      2665      2700 Vancouver\n2      4900      5000 Toronto  \n3      2900      2900 Halifax  \n4      4950      5000 Vancouver\n5      2400      2500 Montreal \n6      1000      1000 Victoria \n7      2800      2800 Halifax  \n8      2350      2400 Vancouver\n\n\nHere, we tell dplyr the tibble we want to transform (housingdata), and then use the pipe operator (%&gt;%) to tell dplyr what functions we want to perform on it.\n\n\n\n\n\n\nNote\n\n\n\nWhen using the pipe operator, we no longer need to include the dataframe in the first argument of the function. Compare the previous two code chunks to see what I mean.\n\n\nWhile it may not be obvious from this first example why the pipe operator is commonly used, let‚Äôs consider that we want to\n\nfilter on rents for 2025 above $2500\nselect all columns aside from name\ncreate a new variable for the rent per room in 2025 (rounded to 2 decimal places)\nreorder the rows by descending order of 2025 rents\n\nThe arrange() function can change the order of rows.\narrange(desc(column_name)) will arrange the roms in descending order for the column_name given. See more here!\n\n\nTo do all of these tasks, the pipe operator allows us to write clear and readable code:\n\nhousingdata %&gt;% \n  filter(rent_2025 &gt; 2500) %&gt;%\n  select(-name) %&gt;%\n  mutate(rent_per_room_2025 = round(rent_2025/numrooms,2)) %&gt;%\n  arrange(desc(rent_2025))\n\n# A tibble: 5 √ó 5\n  numrooms rent_2024 rent_2025 city      rent_per_room_2025\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1        3      4900      5000 Toronto                1667.\n2        4      4950      5000 Vancouver              1250 \n3        1      2900      2900 Halifax                2900 \n4        3      2800      2800 Halifax                 933.\n5        2      2665      2700 Vancouver              1350 \n\n\n\n\n\n\n\n\nNote\n\n\n\nAfter each function call, we need to include the pipe operator to tell dplyr that we‚Äôre not done yet, and the chain of commands continues on the next line.\n\n\nAnother thing to note is that the pipe operator creates a new tibble and does not alter the original. So, housingdata still contains all of the original rows and columns in its unaltered form. If we wanted to alter it (or save the output to a new variable), we need to assign it using &lt;-. For example, the following code will overwrite the original tibble:\n\nhousingdata &lt;- housingdata %&gt;% \n    filter(rent_2025 &gt; 2500) %&gt;%\n    select(-name) %&gt;%\n    mutate(rent_per_room_2025 = round(rent_2025/numrooms,2)) %&gt;%\n    arrange(desc(rent_2025))\n\nhousingdata\n\n# A tibble: 5 √ó 5\n  numrooms rent_2024 rent_2025 city      rent_per_room_2025\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1        3      4900      5000 Toronto                1667.\n2        4      4950      5000 Vancouver              1250 \n3        1      2900      2900 Halifax                2900 \n4        3      2800      2800 Halifax                 933.\n5        2      2665      2700 Vancouver              1350",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#worksheet-a2",
    "href": "webpages/lectures_i/lec3_dplyr.html#worksheet-a2",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Worksheet A2",
    "text": "Worksheet A2\nWorksheet A2 will guide you through some of the basics of dplyr.\n\nHaven‚Äôt attempted all of the questions on Worksheet A2? Then spend this time completing the worksheet.\nFinished attempting all of the questions? Then do the optional R4DS Data Transformation reading, and maybe even do some of the exercises for extra practice.\n\nPut any questions you have about the worksheet questions or about data manipulation in Slack.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#next-class-fev-case-study",
    "href": "webpages/lectures_i/lec3_dplyr.html#next-class-fev-case-study",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Next Class: FEV Case Study",
    "text": "Next Class: FEV Case Study\nNext class we will be working through the first part of the FEV Case Study.\nBy yourself or in small groups, work through the exercises in the case study. The teaching team will walk around and answer questions and chat about anything data manipulation related.\nWe will conclude class by going over instructor solutions.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#resources",
    "href": "webpages/lectures_i/lec3_dplyr.html#resources",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Resources",
    "text": "Resources\n\nVideo lecture: dplyr Part 1: Basic Data Manipulation\nVideo lecture: dplyr Part 2: Calculations on tibbles\nChapter 6 and Chapter 7 of Jenny Bryan‚Äôs STAT 545 book follows along with what we will be covering in Day 1 and Day 2 of this topic (although you won‚Äôt find the across() function).\n‚ÄúR for Data Science‚Äù is another great resource for learning data wrangling. Take a look at:\ndplyr‚Äôs introductory vignette is useful for orienting you to the package.\n\n\nAttribution\nExample created by Grace Tompkins. Notes originally created by Vincenzo Coia.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html",
    "href": "webpages/lectures_i/lec4_datavis.html",
    "title": "Lecture 4: Data Visualization",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nIdentify the seven components of the grammar of graphics underlying ggplot2.\nProduce plots with ggplot2 by implementing the components of the grammar of graphics.\nCustomize the look of ggplot2 graphs.\nChoose an appropriate plot type for analysis, based on an understanding of what makes a graph effective.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#learning-objectives",
    "href": "webpages/lectures_i/lec4_datavis.html#learning-objectives",
    "title": "Lecture 4: Data Visualization",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nIdentify the seven components of the grammar of graphics underlying ggplot2.\nProduce plots with ggplot2 by implementing the components of the grammar of graphics.\nCustomize the look of ggplot2 graphs.\nChoose an appropriate plot type for analysis, based on an understanding of what makes a graph effective.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#effective-data-visualization",
    "href": "webpages/lectures_i/lec4_datavis.html#effective-data-visualization",
    "title": "Lecture 4: Data Visualization",
    "section": "Effective Data Visualization",
    "text": "Effective Data Visualization\nPlots and other forms of data visualization are powerful tools for conveying complex relationships. While tables can be useful, data visualizations are often preferred to aid with identify patterns and relationships and emphasizing important findings in a research projects. This is especially true for presentations, where the audience may not have time to digest a large table of numbers. Jenny Bryan‚Äôs Challenger Example (https://speakerdeck.com/jennybc/ggplot2-tutorial) is a great example of why we may want to visualize data.\nNow the question is, what visualization should you use to convey an idea? Well, you need to first formulate the question you want the data visualization to answer. That is, you need to figure out what you want to convey before you start visualizing the data. From UBC‚Äôs A First Introduction to Data Science [1] book:\n\n‚ÄúA good visualization will clearly answer your question without distraction; a great visualization will suggest even what the question was itself without additional explanation. Imagine your visualization as part of a poster presentation for a project; even if you aren‚Äôt standing at the poster explaining things, an effective visualization will convey your message to the audience.‚Äù\n\nWe need to convey the message using a data visualization while removing as much unnecessary information as possible. Below is a direct quote from the A First Introduction to Data Science [1] containing their suggestions for effective data visualizations:\n‚ÄúConvey the message‚Äù\n\nMake sure the visualization answers the question you have asked most simply and plainly as possible.\nUse legends and labels so that your visualization is understandable without reading the surrounding text.\nEnsure the text, symbols, lines, etc., on your visualization are big enough to be easily read.\nEnsure the data are clearly visible; don‚Äôt hide the shape/distribution of the data behind other objects (e.g., a bar).√ü\nMake sure to use color schemes that are understandable by those with colorblindness (a surprisingly large fraction of the overall population‚Äîfrom about 1% to 10%, depending on sex and ancestry [2]). For example, ColorBrewer and the RColorBrewer R package [3] provide the ability to pick such color schemes, and you can check your visualizations after you have created them by uploading to online tools such as a color blindness simulator.\nRedundancy can be helpful; sometimes conveying the same message in multiple ways reinforces it for the audience.\n\n‚ÄúMinimize noise‚Äù\n\nUse colors sparingly. Too many different colors can be distracting, create false patterns, and detract from the message.\nBe wary of overplotting. Overplotting is when marks that represent the data overlap, and is problematic as it prevents you from seeing how many data points are represented in areas of the visualization where this occurs. If your plot has too many dots or lines and starts to look like a mess, you need to do something different.\nOnly make the plot area (where the dots, lines, bars are) as big as needed. Simple plots can be made small.\nDon‚Äôt adjust the axes to zoom in on small differences. If the difference is small, show that it‚Äôs small!",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#ggplot2-and-the-grammar-of-graphics",
    "href": "webpages/lectures_i/lec4_datavis.html#ggplot2-and-the-grammar-of-graphics",
    "title": "Lecture 4: Data Visualization",
    "section": "ggplot2 and the Grammar of Graphics",
    "text": "ggplot2 and the Grammar of Graphics\nIf you‚Äôve learned about data visualization in R before, you‚Äôve likely produced plots using ‚Äúbase R‚Äù methods (for example, the boxplot() function in R. It is a simple framework for making plots and is often ‚Äúenough‚Äù for producing basic plots. In this lecture, we are going to dive into ggplot2, a package R users often use to make more sophisticated plots! If you‚Äôve never used R to plot before, don‚Äôt worry. We aren‚Äôt assuming you have any experience with either method of plotting in R.\nWe will be utilising the ggplot2 and tidyverse packages throughout this lecture. To load them:\n\n# install.packages(\"tidyverse\") #uncomment if not already installed\n# install.packages(\"ggplot2\") #uncomment if not already installed\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nggplot2 is based on the grammar of graphics, which is a systematic approach for describing different components or aspects of a graph. It involves seven components (required components are indicated with the *):\n\nData*\n\nthe data you‚Äôre feeding into the plot, perhaps a tibble or dataframe\n\nAesthetic mappings*\n\na specification of how you will connect variables (for example, horizontal or vertical positioning, grouping, size, colour, shape)\n\nGeometric objects*\n\na specification of what the object will be drawn as (for example, a scatter plot, line, bar chart)\n\nScales\n\na specification of how a variable is mapped to its aesthetic\n\nStatistical transformations\n\na specification of whether and how the data are combined or transformed. For example, is a bar chart plotting the values or a relative frequency?\n\nCoordinate system\n\na specification of how the position aesthetics (x and y) are depicted in the plot. We typically use cartesian coordinates, though polar coordinates are also possible.\n\nFacet\n\na specification of data variables that partition the data into smaller ‚Äúsub plots‚Äù or panels\n\n\nIt‚Äôs okay if you don‚Äôt quite understand all of these components yet. We will walk through examples of commonly used plots and discuss which components are necessary!\n\nExample: Scatterplot\nTo build our first ggplot, we will use the gapminder data from the gapminder package. To install and load it, we use:\n\n# install.packages(\"gapminder\") #uncomment if not already installed\nlibrary(gapminder)\ndata(gapminder) \n\nhead(gapminder) #view first few rows of the tibble\n\n# A tibble: 6 √ó 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\n\nThe ggplot() function takes two arguments: data (the data frame or tibble containing your data that you‚Äôd like to plot) and mapping (aesthetic mappings applied to the entire plot. We use the aes() function inside of this argument.).\nLet‚Äôs start building the scatterplot! Let‚Äôs plot gdpPercap on the x axis and lifeExp on the y axis:\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp))\n\n\n\n\n\n\n\n\nNotice that we haven‚Äôt actually plotted anything! ggplot doesn‚Äôt know what type of plot we want to draw, only that we want gpdPercap on the x axis and lifeExp on the y axis from the gapminder data we provided. To tell ggplot that we want a scatterplot, we are going to add a layer to the plot using the + at the end of the previous line. geom_point() is the geometric object we‚Äôd like to add (i.e., a scatterplot):\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp)) +\n  geom_point()\n\n\n\n\n\n\n\n\nWe now have created a scatterplot! However, it‚Äôs a bit dense and difficult to see. We can specify an alpha transparency value within the geom_point() function to change the opacity:\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp)) +\n  geom_point(alpha = 0.2)\n\n\n\n\n\n\n\n\nThat‚Äôs already looking better! We can really tell now where there are a lot of observations.\nNow, let‚Äôs transform the scale of the x axis to see if there is a more linear relationship between life expectancy and the log transformation of GDP per capita. The transformation will be of the form scale_AES_TRANSFORMATION() where AES corresponds to which aesthetic value is being transformed, and the TRANSFORMATION is the transformation being completed (here it will be log10. We can also rename the x axis using the first argument. We also can change the labels on the x axis to be dollar format. Let‚Äôs add another layer to do so:\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp)) +\n  geom_point(alpha = 0.2) + \n  scale_x_log10(\"GDP per capita (log-scale)\", labels = scales::dollar_format())\n\n\n\n\n\n\n\n\nThe more translucent grey points are still a bit hard to see. Let‚Äôs change the background to a more minimalist theme using a theme() layer. While we‚Äôre at it, let‚Äôs also rename the y axis using a ylab() later:\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp)) +\n  geom_point(alpha = 0.2) + \n  scale_x_log10(\"GDP per capita (log-scale)\", labels = scales::dollar_format()) +\n  theme_minimal() +\n  ylab(\"Life Expectancy (Years)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNames of axes should have quotations ‚Äú‚Äù around them.\nThe order of the layers doesn‚Äôt matter after the geom_layer() layer.\n\n\n\n\nCommon Types of Plots\n\ngeom_point(): scatterplot\ngeom_line(): line plot\ngeom_bar(): bar chart\ngeom_histogram(): histogram\ngeom_boxplot(): box plot\ngeom_smooth(): adds a smooth trend line (various methods)\n\n\n\nAdvice for ggplot\nGoogle is absolutely your friend when building ggplots. I don‚Äôt think I‚Äôve ever made a plot without googling how to do it. ggplot is extremely powerful, flexible, and a bit scary to learn! If you need to build a plot, search it! Need to plot two histograms, separated by groups (say, gender), side by side? I‚Äôd google: ‚Äúggplot histogram grouped by variable‚Äù. This brings me to this blog post by R Charts that has a TON of different side by side histograms with code! ggplot is very much a ‚Äúlearn by doing‚Äù skill.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#worksheet-a3",
    "href": "webpages/lectures_i/lec4_datavis.html#worksheet-a3",
    "title": "Lecture 4: Data Visualization",
    "section": "Worksheet A3",
    "text": "Worksheet A3\n\nIt‚Äôs time to try ggplot1 yourself! Spend time working through Worksheet 3.\nFinished attempting all of the questions? Then do the optional R4DS Data Visualization reading, and maybe even do some of the exercises for extra practice.\n\nPost any questions you have on the Slack channel!",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#next-class-fev-case-study",
    "href": "webpages/lectures_i/lec4_datavis.html#next-class-fev-case-study",
    "title": "Lecture 4: Data Visualization",
    "section": "Next class: FEV Case Study",
    "text": "Next class: FEV Case Study\nWe will get a flavour for how you might use ggplot2 in the wild and get in even more practice by working through a continuation of our FEV case study from last week.\nBy yourself and in small groups, work through the exercises in the case study. We will also discuss instructor answers to each exercise.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#additional-resources",
    "href": "webpages/lectures_i/lec4_datavis.html#additional-resources",
    "title": "Lecture 4: Data Visualization",
    "section": "Additional Resources",
    "text": "Additional Resources\nVideo lectures for this topic (ignore the episode numbering):\n\nVideo Lecture: ggplot2 Part 1: Introduction to Plotting\nVideo Lecture: ggplot2 Part 2: Plotting for Exploratory Data Analysis\nThe R4DS Data Visualization chapter (provides an excellent overview of plotting in ggplot2 and the grammar of graphics. We especially recommend sections 3.1 to 3.4.)\nHadley Wickham‚Äôs ggplot2 book (a well-organized, approachable, and comprehensive coverage of ggplot2.)\nCheatsheets:\n\nThe ggplot2 cheatsheet (Also available through RStudio: ‚ÄúHelp‚Äù -&gt; ‚ÄúCheatsheets‚Äù -&gt; ‚ÄúData visualization with ggplot2‚Äù).\nR Cookbook Graphs\n\nCraig Hutton‚Äôs comprehensive blog post adopting a similar structure to our course notes, but with more explorations.\nResources about producing effective visualizations:\n\nFundamentals of Data Visualization by Claus Wilke is an excellent guide to designing effective visuals. If you only look at one resource, this should be it.\nVisualization Analysis and Design by Tamara Munzner is a gold-standard book for the theory of designing plots with a focus on human perception.\nBite-sized resources to help you produce effective visualizations:\n\nThe ‚Äúdo‚Äôs and don‚Äôts of effective graphics‚Äù in Jenny Bryan‚Äôs STAT 545 book provides some rules of thumb for producing effective visuals.\nVincenzo‚Äôs ‚ÄúCommunicating data‚Äù slides provide some rules of thumb.\nCallingbull.org‚Äôs entry on visualizations, by Carl T. Bergstrom and Jevin West, goes over several examples of improving ineffective visuals.\n\n\n\n\nAttribution\nLecture created by Vincenzo Coia.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html",
    "href": "webpages/lectures_i/lec5_tidydata.html",
    "title": "Lecture 5: Tidy Data",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nrecognize whether a given data set is ‚Äòtidy‚Äô or ‚Äòuntidy‚Äô for their analysis\nunderstand why ‚Äòtidy‚Äô data can be useful\nreshape a data set between ‚Äòlong‚Äô and ‚Äòwide‚Äô formats, using tidyr::pivot_longer() and tidyr::pivot_wider()\nunderstand how to grapple with explicit missing values created by pivoting",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#learning-objectives",
    "href": "webpages/lectures_i/lec5_tidydata.html#learning-objectives",
    "title": "Lecture 5: Tidy Data",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nrecognize whether a given data set is ‚Äòtidy‚Äô or ‚Äòuntidy‚Äô for their analysis\nunderstand why ‚Äòtidy‚Äô data can be useful\nreshape a data set between ‚Äòlong‚Äô and ‚Äòwide‚Äô formats, using tidyr::pivot_longer() and tidyr::pivot_wider()\nunderstand how to grapple with explicit missing values created by pivoting",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#tidy-data-and-the-tidyverse",
    "href": "webpages/lectures_i/lec5_tidydata.html#tidy-data-and-the-tidyverse",
    "title": "Lecture 5: Tidy Data",
    "section": "Tidy Data and the Tidyverse",
    "text": "Tidy Data and the Tidyverse\nIn the last two weeks, we learned about the dplyr package for data manipulation and the ggplot2 package for graphing. These two packages are part of the ‚Äútidyverse‚Äù: a collection of data science packages that are designed to have input data frames and output data frames that are tidy. In fact, we can load all packages in the tidyverse at once with the single command library(tidyverse).\nHere, we are using the word ‚Äútidy‚Äù in a technical sense - we‚Äôre not talking about how ‚Äúneat‚Äù or ‚Äúorganized‚Äù your data is. Instead, ‚Äútidy‚Äù is a very specific set of rules for storing data.\nTidy data is defined as data where\n\neach variables form a column,\neach observation forms a row, and\neach cell is a single measurement. [1]\n\nFor example, the following data set containing cat and dog names by family is not tidy. We have multiple observations per row (a cat, and a dog observation):\n\n\n\nFamily\nCat Name\nDog Name\n\n\n\n\nTompkins\nSumo\nMochi\n\n\nTruong\nMr.¬†Meow\nBowser\n\n\nMaclean\nGoose\n\n\n\n\nInstead, a tidy version of this data set may look like this:\n\n\n\nPet Name\nType\nFamily\n\n\n\n\nSumo\nCat\nTompkins\n\n\nMochi\nDog\nTompkins\n\n\nMr.¬†Meow\nCat\nTruong\n\n\nBowser\nDog\nTruong\n\n\nGoose\nCat\nMaclean\n\n\n\nEach row is an observation, each variable is a column, and each cell is a single measurement. Our data is tidy!\nAll of the data we used before this week were already tidy. This made it easy to use the tidyverse packages dplyr and ggplot2 to do what we needed to do. Oftentimes however, data is not collected in a tidy way. So, what happens do we do when we have untidy data? Let‚Äôs explore it!\n\nExample: Drinks\nThe fivethirtyeight R package contains a dataset called drinks. This dataset was compiled as part of a FiveThirtyEight article that explored (among other things) which countries consumes the most alcohol. Let‚Äôs look at a subset of the data:\n\n# install.packages(\"fivethirtyeight\") #uncomment if not installed\nlibrary(fivethirtyeight)\nlibrary(tibble)\nlibrary(tidyverse)\n\ndrinks_tbl1 &lt;- as_tibble(drinks) %&gt;% \n  select(-total_litres_of_pure_alcohol) #remove total liters variable\n\nhead(drinks_tbl1) #view the first few rows of the data\n\n# A tibble: 6 √ó 4\n  country           beer_servings spirit_servings wine_servings\n  &lt;chr&gt;                     &lt;int&gt;           &lt;int&gt;         &lt;int&gt;\n1 Afghanistan                   0               0             0\n2 Albania                      89             132            54\n3 Algeria                      25               0            14\n4 Andorra                     245             138           312\n5 Angola                      217              57            45\n6 Antigua & Barbuda           102             128            45\n\n\nThe following graphic was made from the drinks dataset.\n\n\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nWith a partner or a small group discuss the following questions think about if the data is tidy or untidy. If tidy, what would the ggplot code look like to reproduce this graph? If untidy, what would the tidy format look like? Sketch the first few rows of the data. Now, what would the ggplot code look like to reproduce this graph?\n\n\n\n\nExample: Bake-off\nIt‚Äôs clear from the definition that tidiness is an attribute of a dataset. But did you know that tidiness also depends on what you are planning to do with the data? That‚Äôs because what‚Äôs an observation and what‚Äôs a variable depends on the data analysis plan!\nWe will demonstrate using data from ‚ÄúThe Great British Bake Off‚Äù compiled by Allison Hill in the R package bakeoff. The graphics that follow (and the code to produce the graphics) were lightly adapted from Allison‚Äôs Plot Twist talk.\nFirst, let‚Äôs decide on some questions we can address with this data.\n\nHow did viewership change as new series came out?\nThe show moved channels after Series 7. Was viewership higher, lower, or about the same before and after the move?\n\nThese questions have implicitly defined our observations: they are individual units of the most granular populations we are trying to describe or compare. Here, the populations to be compared are series, and units within them are episodes. The variables now fall into place: they are measured attributes of our observations (episodes): episode number, viewership, series membership, etc. This means that the following representation of viewership data is tidy for the ‚Äúchange in viewership over series‚Äù analysis:\n\n# install.packages(\"bakeoff\") #uncomment if not yet installed\nlibrary(bakeoff)\nlibrary(tidyverse)\n\nratings_tbl1 &lt;- ratings %&gt;% #save output to new tibble called ratings_tbl1\n  mutate(ep_id = row_number()) %&gt;% # create variable for episode number\n  select(ep_id, viewers_7day, series, episode) #select specific columns\n\nhead(ratings_tbl1) #view first few rows of tibble\n\n# A tibble: 6 √ó 4\n  ep_id viewers_7day series episode\n  &lt;int&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1     1         2.24      1       1\n2     2         3         1       2\n3     3         3         1       3\n4     4         2.6       1       4\n5     5         3.03      1       5\n6     6         2.75      1       6\n\n\nEvery row is an observation (a unique episode), and the columns are variables (episode number across series, 7-day viewership, series, and episode number within series).\nThis is a typical example where the tidy format makes it easy to do our analysis. For example, to investigate these questions, we might make a bar plot of the number of viewers in millions within a 7-day window per episode, coloured by series. The following code uses the tidy tibble ratings_tbl1 to make this bar plot. Notice that it was easy to use our graphing environment of choice (ggplot2 in the tidyverse) to make the plot because our data is tidy, and the tidyverse is designed to work with tidy data.\n\nseries_labels &lt;- ratings_tbl1 %&gt;% #save output to series_labels\n  mutate(series=as.factor(series)) %&gt;% #ensure series variable is a factor (categorical variable)\n  group_by(series) %&gt;% #group by series\n  summarize(y_position = median(viewers_7day) + 1, # calculate positions for the bar charts\n            x_position = mean(ep_id)) #\n\n# make the plot\nratings_tbl1 %&gt;% \n  mutate(series=as.factor(series)) %&gt;% # ensure series is a factor variable\n  ggplot(aes(x = ep_id, y = viewers_7day, fill = series)) + #set x and y axes, tell ggplot that we want things coloured by series\n    geom_col(alpha = .9) + #tell ggplot we want a boxplot, change translucency with alpha\n    ggtitle(\"7-Day Viewership across Series 1-10\") + #add a title\n    geom_text(data = series_labels, aes(label = series, #add text for series numbers\n                                      x = x_position, \n                                      y = y_position)) +\n    theme_classic() +  #add a classic theme\n    scale_fill_manual(values = bakeoff_palette(),\n                    guide = \"none\") + #set the colours so they aren't rainbow\n    xlab(\"Episode Number\") +  #add x axis label\n    ylab(\"7-Day Viewership (millions)\") #add y axis label\n\n\n\n\n\n\n\n\nNow let‚Äôs consider a different set of questions:\n\nHow did viewership grow between premiere to final episode in each series?\nDoes the premiere-to-final-episode growth vary across series?\n\nTo investigate these questions, we might make a bar plot like the one below displaying percentage increase in the number of viewers in millions within a 7-day window from the premiere episode to finale episode for the first 10 series, using the tidy tibble ratings_tbl2:\n\nhead(ratings_tbl2)\n\n# A tibble: 6 √ó 3\n  series first  last\n  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 1       2.24  2.75\n2 2       3.1   5.06\n3 3       3.85  6.74\n4 4       6.6   9.45\n5 5       8.51 13.5 \n6 6      11.6  15.0 \n\n\nFirst, we can calculate the percentage change in viewership using mutate():\n\nratings_tbl2 &lt;- ratings_tbl2 %&gt;%  #overwrite original df so new variable saves\n   mutate(pct_change = (last - first)/first) #calculate percent change\n\nhead(ratings_tbl2) #view first few rows of tibble\n\n# A tibble: 6 √ó 4\n  series first  last pct_change\n  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1 1       2.24  2.75      0.228\n2 2       3.1   5.06      0.632\n3 3       3.85  6.74      0.751\n4 4       6.6   9.45      0.432\n5 5       8.51 13.5       0.588\n6 6      11.6  15.0       0.295\n\n\nThen, we can visualize this using a bar chart:\n\nratings_tbl2 %&gt;% \n  ggplot(aes(x = fct_rev(series), y=pct_change)) + #initialize the plot\n  geom_col(fill = bakeoff::bakeoff_colors(\"baltic\"), alpha = .5) + #set bar chart with fill colours, semi-translucent \n  labs(x = \"Series\", y = \"% Increase in Viewers, First to Last Episode\") + #add x labels\n  ggtitle(\"% Increase in Viewers from Premiere to Finale\") + #add y labels\n  scale_y_continuous(labels = scales::percent) + #change y axis to percentage \n  theme_classic() + #add classic theme\n  coord_flip() #flip horizontally\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nWith a partner or a small group:\n\nWhat do you think ratings_tbl2 looks like?\nWhy is it tidy? (Hint: what are the observations and variables?)\nCould you have calculated the information in ratings_tbl2 using ratings_tbl1? (No need to write code - just discuss whether it‚Äôs possible.)",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#pivoting",
    "href": "webpages/lectures_i/lec5_tidydata.html#pivoting",
    "title": "Lecture 5: Tidy Data",
    "section": "Pivoting",
    "text": "Pivoting\nOnce you have figured out what‚Äôs tidy for you, you may come to realize that your data is not tidy. As we have discussed, it will typically save you time and frustration to tidy it before moving on in your analysis.\nVery often this will involve using ‚Äúpivoting‚Äù type functions. For example, the tidyr package in the tidyverse has two main pivoting functions:\n\npivot_longer() makes datasets longer: it moves some information in the columns into new rows, thereby increasing the number of rows of the dataset.\npivot_wider() makes datasets wider: it moves some information in the rows into new columns, thereby decreasing the number of rows of the dataset.\n\nBy now, you should have a sense for why this might be useful for tidying!\n\nPivoting Wider\nHere is some code to create a variable for whether an episode is the first or last episode of the season to ratings_tbl1 and subset to only the data from the first and last episodes of each season.\n\nratings_tbl1 &lt;- ratings_tbl1 %&gt;% #overwrite ratings_tbl1\n group_by(series) %&gt;% #group by series\n  filter(episode == 1 | episode == max(episode)) %&gt;% #get only the first and last episodes\n  ungroup() %&gt;% #ungroup the data\n  mutate(episode_fl = recode(episode, `1` = \"first\", .default = \"last\")) #add a new variable indicatign whether or not the episode was first or last, and recode the variable to \"first\" or \"last\"\n\nhead(ratings_tbl1)\n\n# A tibble: 6 √ó 5\n  ep_id viewers_7day series episode episode_fl\n  &lt;int&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     \n1     1         2.24      1       1 first     \n2     6         2.75      1       6 last      \n3     7         3.1       2       1 first     \n4    14         5.06      2       8 last      \n5    15         3.85      3       1 first     \n6    24         6.74      3      10 last      \n\n\nThis is not the same format as ratings_tbl2, which was the tidy format for our earlier ‚Äúviewership growth within series‚Äù analysis. But it does contain the same information. To finish converting ratings_tbl1 into ratings_tbl2, we need to make ratings_tbl1 wider: we need to move some information in the rows (the info about whether each episode is the first or last episode of each season) into new columns.\nWe can solve this problem using pivot_wider, which needs three pieces of information.\n\nWhat is a set of columns that uniquely identifies each observation? Put their names in the id_cols argument.\nWhere should the names for the new columns come from? Put the name of the column you want to take the new variable names from in the names_from argument.\nWhat values should the new columns contain? Put the name of the columns you want to take the values from to values_from in the values_from argument.\n\nNote that if you don‚Äôt specify an id_cols argument, pivot_wider will assume that you want it to be every column except those in names_from and values_from.\n\nratings_tbl2 &lt;- ratings_tbl1 %&gt;% #overwrite ratings_tbl2\n  pivot_wider(id_cols = series, #pivot with id as series\n              names_from=episode_fl, #get column names from episode_fl\n              values_from=viewers_7day) #fill in values form viewers_7day\n\nhead(ratings_tbl2)\n\n# A tibble: 6 √ó 3\n  series first  last\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  2.24  2.75\n2      2  3.1   5.06\n3      3  3.85  6.74\n4      4  6.6   9.45\n5      5  8.51 13.5 \n6      6 11.6  15.0 \n\n\nAlso note that any columns not included in id_cols, names_from, and values_from (e.g.¬†ep_id) will simply be dropped.\nIf we wanted to keep the info in ep_id as well, we would add it to the values_from argument:\n\nratings_tbl1 %&gt;% \n  pivot_wider(id_cols = series, \n              names_from=episode_fl, \n              values_from=c(viewers_7day, ep_id)) #now including ep_id in the values_from call to include it in the output\n\n# A tibble: 10 √ó 5\n   series viewers_7day_first viewers_7day_last ep_id_first ep_id_last\n    &lt;dbl&gt;              &lt;dbl&gt;             &lt;dbl&gt;       &lt;int&gt;      &lt;int&gt;\n 1      1               2.24              2.75           1          6\n 2      2               3.1               5.06           7         14\n 3      3               3.85              6.74          15         24\n 4      4               6.6               9.45          25         34\n 5      5               8.51             13.5           35         44\n 6      6              11.6              15.0           45         54\n 7      7              13.6              15.9           55         64\n 8      8               9.46             10.0           65         74\n 9      9               9.55             10.3           75         84\n10     10               9.62             10.0           85         94\n\n\n\n\nPivoting Longer\n\nThe Basics: Column Names Contain Variable Values\nHere is a snippet of WHO data on the number of tuberculosis cases in different years in different countries.\n\n\n# A tibble: 3 √ó 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\nIf we wanted to compare tuberculosis cases over time by country (e.g.¬†by plotting the year on the x-axis and case count on the y-axis with a line for each country), then this format is not tidy. We want to (graphically) compare years within countries, so there should be one observation per unit within each population (country-years). In this case, we do not observe units within each country-year, so each observation is a country-year. The variables then fall into place: the country and year labels, and the case counts.\n(Aside: if we had measured more data, then perhaps there would be more units within each population! Imagine if we had case-level information, like severity. Then we could view cases as observations within the country-year populations, and we would have variables like country, year, case ID, and severity.)\nSo the tidy format here puts the variables (the year, the country, and the case counts) on the columns. There are 6 rows, one for each unique country-year combination. In this example, the tidy format is longer. That means to produce it using table4a, we need to lengthen it by moving some information in the column names (the info about the measurement year) into new rows.\nWe can solve this problem using pivot_longer, which needs three pieces of information.\n\nWhich are the columns that we want to expand into more rows? Put their names in the cols argument.\nWe want to save the information in the names of those columns as values in new column(s) of our dataset. What should we name these new column(s)? This is the names_to argument.\nWe also want to preserve the information in the values of those columns - so we should save them as values in a new column of our dataset. What should we name it? This is the values_to argument.\n\n\ntable4a %&gt;% pivot_longer(cols = c(`1999`, `2000`), #pivot these columns\n                         names_to = \"year\", #new column name is year\n                         values_to = \"cases\") #use cases as the values of the column\n\n# A tibble: 6 √ó 3\n  country     year   cases\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\nNow our data is tidy!\n\n\nExample: Column Names Contain Multiple Variable Values\nHere‚Äôs a more realistic (but still simplified) look at the WHO Tuberculosis data.\n\nwho_demo &lt;- who2 %&gt;% \n  select(country, year, starts_with(\"sp\")) %&gt;%\n  rename_with(function(x) \n    str_remove(x, pattern=\"sp_\"), \n    starts_with(\"sp\")) %&gt;% \n  filter(year %in% c(1999, 2000)) %&gt;% \n  filter(country %in% c(\"Afghanistan\", \"Brazil\", \"China\"))\n\nhead(who_demo)\n\n# A tibble: 6 √ó 16\n  country      year m_014 m_1524 m_2534 m_3544 m_4554 m_5564  m_65 f_014 f_1524\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan  1999     8     55     55     47     34     21     8    25    139\n2 Afghanistan  2000    52    228    183    149    129     94    80    93    414\n3 Brazil       1999   301   3662   5401   5827   4630   2634  2121   372   2909\n4 Brazil       2000  1894   7268  11568  11906   8623   5085  4494  1859   6719\n5 China        1999  1247  18961  29328  25095  24239  21564 21367  1431  15178\n6 China        2000  1131  19111  29399  25206  25593  21429 21771  1420  14536\n# ‚Ñπ 5 more variables: f_2534 &lt;dbl&gt;, f_3544 &lt;dbl&gt;, f_4554 &lt;dbl&gt;, f_5564 &lt;dbl&gt;,\n#   f_65 &lt;dbl&gt;\n\n\nThis time, cases are broken down by gender (f/m) and by age range (014\\1524\\2534\\3544\\4554\\5564\\65).\nSuppose now that we are interested in comparing tuberculosis rates over time across (potentially) gender, age, and country. Then the most granular population we are trying to describe is a country, gender, age, and year combination, and like in the last example, we have no measured sub-units within that population, so an observation is a unique combination of country, gender, age, and year. (What a mouthful!)\nOnce we‚Äôve sorted that out, the variables fall into place: country, year, gender, age range, and case count. Values for gender and age range are currently located in the column names of who_demo, and values for case count are currently spread across multiple columns. So to tidy who_demo up, we need to use pivot_longer() to move the info in the columns into new rows.\nConceptually, this is pretty similar to the last example: we want to use the information in m_014, m_1524, etc. to create new rows. So we should put those column names into the cols argument. But now, we want the information in their column names - the gender and age - to go into two new columns: gender and age. We can do this by specifying two column names in the names_to argument: gender and age.\nBut how is pivot_longer() to know which part of the column name m_014 corresponds to the gender, and which part corresponds to the age? You need to tell it that the pieces of information are separated by the ‚Äú_‚Äù character using the names_sep argument.\nFinally, we can specify the name of the new column we want the values in the m_014, m_1524, etc. columns to go into with the values_to argument.\n\nwho_demo %&gt;% pivot_longer(cols = !(country:year), # all columns aside from country to year\n                          names_to = c(\"gender\", \"age\"), #new columns named age and gender\n                          names_sep = \"_\",#current gender and age are a single variable separated by _\n                          values_to = \"cases\") #use the cases column for the values\n\n# A tibble: 84 √ó 5\n   country      year gender age   cases\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n 1 Afghanistan  1999 m      014       8\n 2 Afghanistan  1999 m      1524     55\n 3 Afghanistan  1999 m      2534     55\n 4 Afghanistan  1999 m      3544     47\n 5 Afghanistan  1999 m      4554     34\n 6 Afghanistan  1999 m      5564     21\n 7 Afghanistan  1999 m      65        8\n 8 Afghanistan  1999 f      014      25\n 9 Afghanistan  1999 f      1524    139\n10 Afghanistan  1999 f      2534    160\n# ‚Ñπ 74 more rows\n\n\n\n\nExample: Column Names Contain Variable Names And Values\nSo far we have seen examples where the column names contain variable values. But what if they contain names AND values?\nLet‚Äôs have a look at the household dataset (loaded with the tidyr package), which has the date of birth and names of two children in families. Let‚Äôs say that we wanted to investigate how children names relate to their date of birth.\n\nhead(household)\n\n# A tibble: 5 √ó 5\n  family dob_child1 dob_child2 name_child1 name_child2\n   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      \n1      1 1998-11-26 2000-01-29 Susan       Jose       \n2      2 1996-06-22 NA         Mark        &lt;NA&gt;       \n3      3 2002-07-11 2004-04-05 Sam         Seth       \n4      4 2004-10-10 2009-08-27 Craig       Khai       \n5      5 2000-12-05 2005-02-28 Parker      Gracie     \n\n\nWe are trying to learn about the population from which these children belong; it is hard to say precisely what that is without having more information about how this data was collected, but it is likely something like ‚Äúall children living in a particular place in a particular year‚Äù. The units in this population are children. So to tidy this data, we‚Äôd want ‚Äúdate of birth‚Äù and ‚Äúname‚Äù to be two variables/columns associated with an observation/row (a child). We know we want to use pivot_longer(), because we want to make household longer by creating new variables. But wait! The names of the ‚Äúdate of birth‚Äù/‚Äúname‚Äù variables AND the values of the ‚Äúchild‚Äù variable are BOTH in the column names of household!\nInspecting the documentation for pivot_longer() very carefully reveals that you can use a special specification of the names_to argument to resolve this problem.\n\nhousehold %&gt;% pivot_longer(cols = -family, # all columns except family\n                           names_to = c(\".value\", \"child\"), #change column names, .value is a placeholder\n                           names_sep = \"_\") # dob and child are currently separated by _ in one single variable\n\n# A tibble: 10 √ó 4\n   family child  dob        name  \n    &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt; \n 1      1 child1 1998-11-26 Susan \n 2      1 child2 2000-01-29 Jose  \n 3      2 child1 1996-06-22 Mark  \n 4      2 child2 NA         &lt;NA&gt;  \n 5      3 child1 2002-07-11 Sam   \n 6      3 child2 2004-04-05 Seth  \n 7      4 child1 2004-10-10 Craig \n 8      4 child2 2009-08-27 Khai  \n 9      5 child1 2000-12-05 Parker\n10      5 child2 2005-02-28 Gracie\n\n\nThe special \".value\" specification says that we want to use the first component of the pivoted column name as a variable name, and make a new column with values coming from the second component of the pivoted column name. The second thing we pass into names_to names that new column.\nThis process is best described by Figure 6.7 from R4DS.\nBut wait! Row 4 is a bunch of NAs! Does that mean this data isn‚Äôt tidy??\nThe fact that there is an NA does not necessarily mean that this data is untidy. To be clear: for the purpose of the tidy data definition, an indicator for a missing value is a value.\nWhether this data is untidy depends on the data context. Essentially, the question we should ask is: ‚ÄúIs row 4 an observation that we are missing information about? Or is it simply an artifact of our pivoting procedure?‚Äù\nSuppose this study was designed to only sample families with two children. Then, row 4 could be a real observation that we are missing information about: family 2 should have only been included if they had two children. Perhaps this reflects family 2 filling out a survey that asks them the number of children (in which they listed 2), but then getting distracted and forgetting to fill out the information for their second child. In this case, our data is tidy, and the tidy data format is a real advantage: it reveals missing information in our data set that was not obvious from the original untidy format.\nNow suppose this study just samples families at large. We know from experience about the world that some families have one children, some families have two, and some families have more. Then, it seems possible that row 4 is not a real observation: family 2 might just have a single child. In this case, we have a row for something that is not an observation, so we would like to tidy up by dropping it. We could actually have done this by altering our original pivot_wider() call as follows:\n\nhousehold %&gt;% pivot_longer(cols = -family, \n                           names_to = c(\".value\", \"child\"), \n                           names_sep = \"_\", \n                           values_drop_na = TRUE) #remove NAs\n\n# A tibble: 9 √ó 4\n  family child  dob        name  \n   &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt; \n1      1 child1 1998-11-26 Susan \n2      1 child2 2000-01-29 Jose  \n3      2 child1 1996-06-22 Mark  \n4      3 child1 2002-07-11 Sam   \n5      3 child2 2004-04-05 Seth  \n6      4 child1 2004-10-10 Craig \n7      4 child2 2009-08-27 Khai  \n8      5 child1 2000-12-05 Parker\n9      5 child2 2005-02-28 Gracie\n\n\nThis discussion highlights the importance of knowing the context in which your data is collected for tidying (and for your analysis at large). Here and elsewhere, it really pays to be in close contact with the people who generated your data.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#separating-and-uniting",
    "href": "webpages/lectures_i/lec5_tidydata.html#separating-and-uniting",
    "title": "Lecture 5: Tidy Data",
    "section": "Separating and Uniting",
    "text": "Separating and Uniting\nThe tidyr package has a function for gluing columns together (unite) and for cutting columns apart (separate). Why might this help us tidy? Here is another snippet of WHO Tuberculosis data.\n\ntable3 &lt;- tibble(country = c(\"Afghanistan\", \"Afghanistan\", \"Brazil\", \"Brazil\", \"China\", \"China\"),\n                 year = c(1999, 2000, 1999, 2000, 1999, 2000),\n                 rate = c(\"745/19987071\", \"2666/20595360\", \"37737/172006362\", \n                          \"80488/174504898\", \"212258/1272915272\", \"213766/1280428583\"))\n\ntable3\n\n# A tibble: 6 √ó 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\nThe rate column contains the values of two variables: case counts and population counts. We would like to snip it apart at the ‚Äú/‚Äù character to create two columns:\n\ntable5 &lt;- table3 %&gt;% separate(col = rate, \n                    into = c(\"cases\", \"population\"))\ntable5\n\n# A tibble: 6 √ó 4\n  country      year cases  population\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 Afghanistan  1999 745    19987071  \n2 Afghanistan  2000 2666   20595360  \n3 Brazil       1999 37737  172006362 \n4 Brazil       2000 80488  174504898 \n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\nThe col argument specifies the column we want to separate, and the into argument specifies the names of the new columns. The sep argument (not specified here) specifies where we want to cut. The default is pretty clever - it separates at any non-alphanumeric value. (How this is accomplished involves regular expressions, which are very useful when working with character data. We will learn more about regular expressions in STAT 545B. )",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#the-merits-of-untidy-data",
    "href": "webpages/lectures_i/lec5_tidydata.html#the-merits-of-untidy-data",
    "title": "Lecture 5: Tidy Data",
    "section": "The Merits of Untidy Data",
    "text": "The Merits of Untidy Data\nAs we‚Äôve seen, tidy data is often very helpful. But there are also times when untidy data is good. Here are a few reasons:\n\nThe format that lends itself best to fast computations might not be tidy. Case Study: Tidy Genomics.\nUntidy data is often easier for humans to interpret and edit. See Untidy Data: The Unreasonable Effectiveness of Tables.\nWe could lose important information about the context in which the data was collected by cleaning and tidying raw data. This can have important ethical implications; see Chapter 5 of the book ‚ÄúData Feminism‚Äù by Catherine D‚ÄôIgnazio and Lauren F. Klein.\n\nIn summary, tidiness is a very useful concept, and tidying data is often useful. But we should remember that absolutes are few and far between in data science and statistics. Just because tidying data is often useful, doesn‚Äôt mean it‚Äôs always useful.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#worksheet-a4",
    "href": "webpages/lectures_i/lec5_tidydata.html#worksheet-a4",
    "title": "Lecture 5: Tidy Data",
    "section": "Worksheet A4",
    "text": "Worksheet A4\nSpend the rest of this class and next class working through Worksheet A4.\n\nFinished attempting all of the questions? Then do the optional R4DS Tidying reading, and maybe even do some of the exercises for extra practice.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#resources",
    "href": "webpages/lectures_i/lec5_tidydata.html#resources",
    "title": "Lecture 5: Tidy Data",
    "section": "Resources",
    "text": "Resources\n\nVideo Lecture: tidyr for Pivoting and Tidy Data\nTo learn how to use the pivot_*() functions, consult tidyr‚Äôs pivot vignette.\nTo get a better understanding of the concept of tidy data:\n\nHadley Wickham‚Äôs paper on Tidy Data is the gold standard treatment of tidy data.\nA ‚Äúcode heavy‚Äù version of the tidy data paper is tidyr‚Äôs ‚ÄúTidy Data‚Äù vignette.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#attribution",
    "href": "webpages/lectures_i/lec5_tidydata.html#attribution",
    "title": "Lecture 5: Tidy Data",
    "section": "Attribution",
    "text": "Attribution\nAlbert Y. Kim inspired the in-class exercises using the drinks data set from fivethirtyeight. Allison Horst and Julia Lowndes created the illustrated tidy data series. Alison Hill inspired the Great British Bakeoff example. We are immensely grateful to these people for creating amazing educational materials!\nWe would also like to thank Samantha Tyner for pointing us towards the Data Feminism book during her week as the curator of the @WomenInStat Twitter account.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html",
    "href": "webpages/lectures_i/lec6b_dates.html",
    "title": "Lecture 6B: Factors and Dates",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\nThroughout this lecture, we will be using functions from X packages, which we install and load through:\n# install.packages(c(\"tidyverse\", \"gapminder\", \"lubidate\"))\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(lubridate)",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#factors",
    "href": "webpages/lectures_i/lec6b_dates.html#factors",
    "title": "Lecture 6B: Factors and Dates",
    "section": "Factors",
    "text": "Factors\n\n‚ÄúThere is no other object that creates as much trouble as factors.‚Äù - Patrick Burns, ‚ÄúThe R Inferno‚Äù.\n\nIn R, we use factors to represent categorical variables: variables that take on a fixed number of known values (i.e.¬†levels). For example, in the penguins data set, species is a factor with three levels: ‚ÄúAdelie‚Äù, ‚ÄúChinstrap‚Äù, and ‚ÄúGentoo‚Äù. We can see this by looking at the str() (structure) of the tibble:\n\nstr(penguins)\n\n'data.frame':   344 obs. of  8 variables:\n $ species    : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island     : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_len   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_dep   : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_len: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass  : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year       : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nor we can explicitly look at the class and levels of the variable of interest by:\n\nclass(penguins$species)\n\n[1] \"factor\"\n\nlevels(penguins$species)\n\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n\nUnder the hood, R stores a factor with (say) 3 levels as a numeric vector containing integers between 1 and 3, paired with a character vector of length 3 that identifies the mapping between the numbers 1, 2, and 3 and the levels.\nThis is not immediately obvious, because R will print factors using the character string levels rather than the numbers that it stores:\n\nset.seed(100) #make reproducible (more on this later)\n\npenguins %&gt;% \n  slice_sample(n=10) %&gt;% #take 10 random rows\n  pull(species) #output the species only\n\n [1] Gentoo    Adelie    Gentoo    Adelie    Chinstrap Chinstrap Adelie   \n [8] Adelie    Gentoo    Chinstrap\nLevels: Adelie Chinstrap Gentoo\n\n\nThis dual nature of factors creates a whole slew of hidden traps and headaches, especially for new R users!\n\n\n\n\n\n\nCaution\n\n\n\nSometimes factors are coded (i.e., written) in the data as integers. Without explicitly telling R, R will assume any numeric data are just regular old numbers.\nAlways ensure that factors are explicit in your code!\n\n\nFor example, suppose in the penguins data set than instead of their names, species had levels ‚Äú1‚Äù, ‚Äú2‚Äù, and ‚Äú3‚Äô where‚Äù1‚Äù could represent Gentoo, ‚Äú2‚Äù Adelie, and 3 ‚ÄúChinstrap‚Äù penguins. So, instead of having the names of penguin species as strings, they are coded as numeric values.\n\npenguins2 &lt;- penguins %&gt;%\n  mutate(species = recode(species, \"Gentoo\" = 1, \"Adelie\" = 2, \"Chinstrap\" = 3))\n\nstr(penguins2)\n\n'data.frame':   344 obs. of  8 variables:\n $ species    : num  2 2 2 2 2 2 2 2 2 2 ...\n $ island     : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_len   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_dep   : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_len: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass  : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year       : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nWe see here that R assumes that species is a numeric variable, not a categorical variable. To ensure R knows that species is categorical, we can use:\n\npenguins2 &lt;- penguins2 %&gt;% #overwrite existing tibble\n  mutate(species = as.factor(species)) #overwrite species to be a factor using as.factor\n\nstr(penguins2)\n\n'data.frame':   344 obs. of  8 variables:\n $ species    : Factor w/ 3 levels \"1\",\"2\",\"3\": 2 2 2 2 2 2 2 2 2 2 ...\n $ island     : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_len   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_dep   : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_len: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass  : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year       : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nNow we see that species is a factor with three levels!\nNevertheless, factors are important and worth the pain. Many functions throughout the R landscape expect categorical variables to be coded as factors. For example, when making plots in either ggplot2 or in base R, we need factors in order to map categorical variables to aesthetic elements like colour.\nTo make our lives easier, we will work with factors through the forcats package loaded as part of the tidyverse.\n\nReordering Factor Levels\nBy default, factors are ordered alphabetically or numerically. However, in many cases factors have a logical ordering they should follow. For example, you may have an education variable dictating the level of schooling a student is currently in (i.e., elementary, secondary, post-secondary, graduate). It is natural to order the factor in this way. In other cases, you may just want to reorder the levels of a factor so that it plots a certain way. Reordering data can be useful for both data visualization and model fitting.\nTo see the current ordering of a factor variable, we can call levels().\n\nlevels(penguins$species)\n\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n\nWe see here, the levels of the factor are ordered alphabetically.\n\nReordering Levels of a Factors Manually\nThere are many ways to reorder the levels of a factor in R. To reorder the levels of the factor, we can use built in R functions such as ordered():\n\npenguins3 &lt;- penguins %&gt;%\n  mutate(species = ordered(species, levels = c(\"Gentoo\", \"Chinstrap\", \"Adelie\"))) #change species to an ordered factor with the specified ordering\n\nlevels(penguins3$species) #see the levels of species\n\n[1] \"Gentoo\"    \"Chinstrap\" \"Adelie\"   \n\n\nNow, when we call str() on the penguins data, we see that the factor is explicitly ordered, with out new ordering:\n\nstr(penguins3)\n\n'data.frame':   344 obs. of  8 variables:\n $ species    : Ord.factor w/ 3 levels \"Gentoo\"&lt;\"Chinstrap\"&lt;..: 3 3 3 3 3 3 3 3 3 3 ...\n $ island     : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_len   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_dep   : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_len: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass  : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year       : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\n\n\nReordering Levels of a Factors Based on a Condition Using forcats\nPerhaps we want to reorder levels based on some condition, perhaps the ordering levels by frequency, or perhaps by the another summary statistic (which could be useful for effective data visualization!). We can easily do so using the forcats package. Let‚Äôs look again at the original penguins data set and look at the frequency of each species using ggplot:\n\nggplot(penguins, aes(x = species, fill = species)) + #use species variable (no y needed)\n  geom_bar() + #draw a bar chart \n  theme(legend.position = \"none\")  + #remove redundant legend\n  xlab(\"Species\") + #add x axis label\n  ylab(\"Count\") + # add y axis label\n  ggtitle(\"Penguin Species Frequencies\") #add a title\n\n\n\n\n\n\n\n\nThis data visualization is fine. But there‚Äôs one step we can do to make it even better: order bars by largest to smallest (or smallest to largest) so readers can easily spot which species is the most common. This is especially useful when the number of levels is large!\nWe can do this in two ways: edit the original tibble to have new factor ordering, or order the factors directly in the ggplot2 call so that the original tibble isn‚Äôt overwritted. We will show both ways. We will use the forcats package in both examples.\nOption A: Reorder Tibble Directly\nTo reorder the factor levels according to the frequency in the tibble, we can use fct_reorder():\n\npenguins4 &lt;- penguins #initialize a new dataset we will overwrite, save original\npenguins4$species &lt;- penguins$species %&gt;% #overwrite species in penguins4\n  fct_infreq() #relevel the factor by frequency\n\nlevels(penguins4$species)\n\n[1] \"Adelie\"    \"Gentoo\"    \"Chinstrap\"\n\n\nWe see the ordering is Adelie, Gentoo, and then Chinstrap. If you look at the previous plot, you‚Äôll see that these are ordered from smallest to largest frequencies. The original ordering was alphabetical.\nTo order from smallest to largest, we had fct_rev() to the chain:\n\npenguins4$species &lt;- penguins4$species %&gt;%\n  fct_infreq() %&gt;% #relevel the factor by frequency\n  fct_rev()\n\nlevels(penguins4$species)\n\n[1] \"Chinstrap\" \"Gentoo\"    \"Adelie\"   \n\n\nNow the levels are reversed!\nWe can then plot our data using penguins4:\n\nggplot(penguins4, aes(x = species, fill = species)) + #use species variable (no y needed)\n  geom_bar() + #draw a bar chart \n  theme(legend.position = \"none\")  + #remove redundant legend  \n  xlab(\"Species\") + #add x axis label\n  ylab(\"Count\") + # add y axis label\n  ggtitle(\"Penguin Species Frequencies\") #add a title\n\n\n\n\n\n\n\n\nOf course, an even better visualization would involve flipping the axes:\n\nggplot(penguins4, aes(x = species, fill = species)) + #use species variable (no y needed)\n  geom_bar() + #draw a bar chart \n  theme(legend.position = \"none\")  + #remove redundant legend  \n  xlab(\"Species\") + #add x axis label\n  ylab(\"Count\") + # add y axis label\n  ggtitle(\"Penguin Species Frequencies\") + #add a title\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt may look like they are ordered from largest to smallest, but they are actually ordered from smallest to largest. When flipped, ggplot puts the first level on the bottom.\n\n\nOption B: Reorder the Factor in the ggplot Call\nWe can do these steps directly in ggplot without overwriting or making a new tibble!\n\npenguins %&gt;% #this is the original data frame with alphabetical ordering\n  mutate(species = species %&gt;%\n           fct_infreq() %&gt;% #order by frequency\n           fct_rev()) %&gt;%  #reverse ordering\n  ggplot( aes(x = species, fill = species)) + #no longer specify the data set in ggplot() as this is passed in by the pipe %&gt;%\n    geom_bar() + \n    theme(legend.position = \"none\")  +\n    xlab(\"Species\") + \n    ylab(\"Count\") + \n    ggtitle(\"Penguin Species Frequencies\") + \n    coord_flip()\n\n\n\n\n\n\n\n\nWe get the exact same plot with a single chunk of code! And, the original tibble penguins remains unchanged with the alphabetical ordering of the species factors.\n\nlevels(penguins$species)\n\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n\n\n\n\n\n\n\nExercise\n\n\n\nThe gapminder dataset contains information on GDP per capita (gdpPercap) by country. Add to the following ggplot to visualize the GDP per capita, ordered by GDP per capita, for countries in Asia in 2007. Copy the code block to edit and run it in R.\nlibrary(gapminder)\nlibrary(tidyverse)\n\ngapminder %&gt;%\n  filter( ) %&gt;% #FILL THIS IN: filter by countries in Asia\n  mutate() %&gt;% #FILL THIS IN: change ordering of country by gdpPercap\n  ggplot(aes(country, gdpPercap)) + \n    geom_point() + \n    coord_flip() + \n    scale_y_continuous(\"GDP per Capita, 2007\", labels = scales::dollar_format()) + \n    xlab(\"Country\")\n  \n\n\nAnswer below! No peaking until you‚Äôve attempted this problem!\n\ngapminder %&gt;%\n  filter(continent == \"Asia\", year == 2007) %&gt;% #filter by countries in Asia\n  mutate(country = fct_reorder(country, gdpPercap)) %&gt;% #change ordering of country by gdpPercap\n  ggplot(aes(country, gdpPercap)) + \n    geom_point() + \n    coord_flip() + \n    scale_y_continuous(\"GDP per Capita, 2007\", labels = scales::dollar_format()) + \n    xlab(\"Country\")\n\n\n\n\n\n\n\n\n\n\n\nExpanding Factor Levels\nPerhaps we may want to visualize that in our data set, there are no Emperor or King penguins. To do so, we can add ‚ÄúEmperor‚Äù and ‚ÄúKing‚Äù as possible factor levels for species in our penguins data set. We do so by fct_expand()\n\npenguins %&gt;% #this is the original data frame with alphabetical ordering\n  mutate(species = species %&gt;%\n           fct_expand(\"King\", \"Emperor\") %&gt;% #NEW: expand levels to include king and emperor\n           fct_infreq() %&gt;% \n           fct_rev()\n           ) %&gt;%  \n  ggplot( aes(x = species, fill = species)) + \n    geom_bar() + \n    theme(legend.position = \"none\")  +\n    xlab(\"Species\") + \n    ylab(\"Count\") + \n    ggtitle(\"Penguin Species Frequencies\") + \n    coord_flip() + \n    scale_x_discrete(drop = FALSE) #NEW: do not drop empty factor levels\n\n\n\n\n\n\n\n\nNow we add to the visualization that there were no King or Emperor penguins collected in the data.\n\nRemoving Factor Levels\nLet‚Äôs suppose we were only interested in comparing Adelie and Chinstrap penguins. We could drop the Gentoo level using forcats by:\n\npenguins_no_gentoo &lt;- penguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;%\n  droplevels()\n\nlevels(penguins_no_gentoo$species)\n\n[1] \"Adelie\"    \"Chinstrap\"\n\n\nWe can also do this along with the ggplot call by:\n\npenguins %&gt;% #this is the original data frame with alphabetical ordering\n  mutate(species = species %&gt;%\n\n           fct_infreq() %&gt;% \n           fct_rev()\n           ) %&gt;%  \n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% #NEW: filter only these species\n  droplevels() %&gt;% #NEW: drop if not adelie or chinstrap species\n  ggplot( aes(x = species, fill = species)) + \n    geom_bar() + \n    theme(legend.position = \"none\")  +\n    xlab(\"Species\") + \n    ylab(\"Count\") + \n    ggtitle(\"Penguin Species Frequencies\") + \n    coord_flip() + \n    scale_x_discrete(drop = FALSE) #NEW: do not drop empty factor levels",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#dates-and-times",
    "href": "webpages/lectures_i/lec6b_dates.html#dates-and-times",
    "title": "Lecture 6B: Factors and Dates",
    "section": "Dates and Times",
    "text": "Dates and Times\nOften you will need to work with dates and times in your data. For example, we could have had a variable in the FEV data set that contains the date of each patient visit.\nDates and times seem simple, but they are actually one of the most complicated things you will encounter in data analysis. Why? Think about this:\n\nAre there 365 days in every year?\nAre there 30 days in every month?\nAre there 24 hours in every day?\n\nThe answer to all of these questions is NO. What a headache this can be when trying to compute how much time has elapsed between two date/times!\nThe lubridate package can help us with a lot of the headaches that dates and times cause. It can create date and time objects from different inputs, extract important pieces of information like year/month/day, do hard math with dates and times, and help you navigate time zones.",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#nyc-flights-case-study",
    "href": "webpages/lectures_i/lec6b_dates.html#nyc-flights-case-study",
    "title": "Lecture 6B: Factors and Dates",
    "section": "NYC Flights Case Study",
    "text": "NYC Flights Case Study\nWe‚Äôll show off how to use the lubridate package in the tidyverse to work with date variables in datasets in this NYC Flights case study.\nFor the sake of time, we‚Äôll just go over the solutions together, instead of having you attempt exercises on your own first. We think this will be sufficient to get a hang of the basics of lubridate. That being said, want extra practice? Then check out the R4DS Dates and Times Chapter!",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#worksheet-a5",
    "href": "webpages/lectures_i/lec6b_dates.html#worksheet-a5",
    "title": "Lecture 6B: Factors and Dates",
    "section": "Worksheet A5",
    "text": "Worksheet A5\nTry your hand at using factors by working through the factors portion of Worksheet A5.\nFinished attempting all of the questions? Then do the optional R4DS Factors reading, and maybe even do some of the exercises for extra practice.",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#additional-resources",
    "href": "webpages/lectures_i/lec6b_dates.html#additional-resources",
    "title": "Lecture 6B: Factors and Dates",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nVideo lecture: Special Data Types in R: Dates, Times, and Factors\nChapter IV of https://stat545.com/\nThe forcats package page and reference guide on page.\nThe R4DS chapter on Dates and Times\nThe tsibble vignette to learn more about embedding a time series within a tibble.\n\n\nAttribution\nWritten by Grace Tompkins with examples from Vincenzo Coia",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7a_readwritedata.html",
    "href": "webpages/lectures_i/lec7a_readwritedata.html",
    "title": "Lecture 7A: Reading and Writing Data",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nRead and write a delimited file, like a csv, from R using the readr package.\nMake relative paths using the here::here() function.\nRead data from a spreadsheet\nRead and write R binary files (rds files) from R.\n\nRequired packages:\n\nlibrary(tidyverse)\nlibrary(here)\n\n\n\n\n\n\n\nImportant\n\n\n\nIn some of the eariler examples, I will be demonstrating using absolute and relative file paths. On Mac OS, files are written with forward slashes (i.e., datasets/penguins.csv). On Windows, backslashes are used (i.e., datasets\\penguins.csv). My examples are writted for MacOS - the only thing you‚Äôd need to change in the examples are the direction of the slashes if you plan to reproduce my code!\nLater in the lecture, we discuss the here::here() function which solves this problem completely.\n\n\nCommon file formats include\n\nSpreadsheets: Excel, Google Sheets, Numbers\nDelimited files: Plaintext files containing data, e.g.¬†comma separated values (CSVs), tab separated values (TSVs)\nR binary: A serialization of an R object to a binary file. Basically, that means that it can be loaded in and out of R, but it can‚Äôt be opened by anything but R.\n\nCSVs are the most ‚Äúone-size-fits-all‚Äù: you can open them in spreadsheet software, but they are also plaintext, so are lightweight, can be opened in any text editor, and can be ‚Äúdiff‚Äùed.¬†Spreadsheets are nice for human interaction (like through Excel), but can be clunky in R. R binary is quite restrictive and we don‚Äôt tend to store data this way. Our lecture will focus on CSVs.\n\n\nJenny Bryan‚Äôs website has a fabulous section on reading and writing files in R. We‚Äôre going to summarize a few of the important functions here, but if you‚Äôd like to learn more then check out that website for more in-depth explorations!\nWe are going to focus on reading and writing data using the readr package, because we think it has the most ‚Äúwork right out of the box‚Äù experience.\nWe will start by talking about how to read and write Comma Separated Value (CSV) files (files that end in .csv). CSVs are often used to store data. When the penguins data set is stored as a .csv, the first few entries look like when opened as a text file:\nspecies,island,bill_len,bill_dep,flipper_len,body_mass,sex,year\nAdelie,Torgersen,39.1,18.7,181,3750,male,2007 Adelie,Torgersen,39.5,17.4,186,3800,female,2007 Adelie,Torgersen,40.3,18,195,3250,female,2007 Adelie,Torgersen,NA,NA,NA,NA,NA,2007 Adelie,Torgersen,36.7,19.3,193,3450,female,2007 Adelie,Torgersen,39.3,20.6,190,3650,male,2007 Adelie,Torgersen,38.9,17.8,181,3625,female,2007 Adelie,Torgersen,39.2,19.6,195,4675,male,2007\nNow, this isn‚Äôt exactly easy for humans to read, but saving data as CSVs has its advantages. The data is stored in a simple form (lightweight - files aren‚Äôt large) that has broad compatibility and can be used in a wide range of applications. And of course, we can use functions in R to make it more readable. A few main functions of note are\n\nread_csv(): tidyverse equivalent of read.csv() used to read from a CSV to a tibble\nwrite_csv(): tidyverse equivalent of write.csv() used to export a tibble into CSV format\n\nLet‚Äôs assume that a file called penguins.csv is saved in a dataset folder in our current directory. We can read in, and save the tibble as a variable called penguins using:\n\npenguins &lt;- read_csv(\"datasets/penguins.csv\")\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_len, bill_dep, flipper_len, body_mass, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins)\n\n# A tibble: 6 √ó 8\n  species island    bill_len bill_dep flipper_len body_mass sex     year\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie  Torgersen     39.1     18.7         181      3750 male    2007\n2 Adelie  Torgersen     39.5     17.4         186      3800 female  2007\n3 Adelie  Torgersen     40.3     18           195      3250 female  2007\n4 Adelie  Torgersen     NA       NA            NA        NA &lt;NA&gt;    2007\n5 Adelie  Torgersen     36.7     19.3         193      3450 female  2007\n6 Adelie  Torgersen     39.3     20.6         190      3650 male    2007\n\n\nPretty easy! Note that the file path needs to be a string, relative to where you are now in the directory (i.e., where the R script you‚Äôre working on is saved. You can always call getwd() to see what directory you‚Äôre working on currently, and we‚Äôll show more tools for dealing with directories later in this lecture.)\nWe can manipulate the data, and save the output as a new CSV. For example,\n\npenguins_2007 &lt;- penguins %&gt;%\n  filter(year == 2007) #filter only on year 2007\n\nwrite_csv(penguins_2007, \"datasets/penguins_2007.csv\") #save csv in datasets folder, name as penguins_2007.csv\n\nNow, in my datasets folder, I have penguins and penguins_2007.\n\n\n\n\n\n\nNote\n\n\n\nWant to read and write to an Excel file? The readxl package in the tidyverse is for you!\nFor the very niche option of R binary: read_rds() and write_rds().\n\n\n\n\n\nAs previously mentioned, we need to specify where we are reading/writing our data from/to. The best practice is to use a relative path. This helps with reproducibility and automation!\nI could always read in my penguins dataset using an absolute file path where the file path begins at the root of your computer (for me, it is a long chain of folders in /Users/......../STAT545/stat454.github.io/webpages/lectures_i/datasets/penguins.csv). This, however, is not best practice. As previously mentioned, this string telling me where the file path is can also differ for Windows users! I‚Äôd have to manually change all of the forward slashes to backslashes to make this run on Windows.\nWe will use the here package for relative file paths. Let‚Äôs (install, if necessary, and) load it and call the function here()\n\n\n# install.packages(\"here\")\nlibrary(here)\nhere()\n\n[1] \"/Users/gracetompkins/Library/CloudStorage/OneDrive-UBC/Teaching/STAT545/STAT545.github.io\"\n\n\nI get that long chain of folders where this R Project (which I used to build this website) is stored. The cool thing about here is that I can specify a file path relative to my project root (the above location) without using any operating system-specific strings.\nFor example, the penguins.csv data set is located in webpages &gt; lectures_i &gt; datasets within my R project folder. I can access it by:\n\npenguins &lt;- read_csv(here(\"webpages\", \"lectures_i\", \"datasets\", \"penguins.csv\"))\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_len, bill_dep, flipper_len, body_mass, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins) #view first few entries of the tibble\n\n# A tibble: 6 √ó 8\n  species island    bill_len bill_dep flipper_len body_mass sex     year\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie  Torgersen     39.1     18.7         181      3750 male    2007\n2 Adelie  Torgersen     39.5     17.4         186      3800 female  2007\n3 Adelie  Torgersen     40.3     18           195      3250 female  2007\n4 Adelie  Torgersen     NA       NA            NA        NA &lt;NA&gt;    2007\n5 Adelie  Torgersen     36.7     19.3         193      3450 female  2007\n6 Adelie  Torgersen     39.3     20.6         190      3650 male    2007\n\n\nThis is reproducible!",
    "crumbs": [
      "Lecture 7A: Reading and Writing Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7a_readwritedata.html#reading-and-writing-data-in-r",
    "href": "webpages/lectures_i/lec7a_readwritedata.html#reading-and-writing-data-in-r",
    "title": "Lecture 7A: Reading and Writing Data",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nRead and write a delimited file, like a csv, from R using the readr package.\nMake relative paths using the here::here() function.\nRead data from a spreadsheet\nRead and write R binary files (rds files) from R.\n\nRequired packages:\n\nlibrary(tidyverse)\nlibrary(here)\n\n\n\n\n\n\n\nImportant\n\n\n\nIn some of the eariler examples, I will be demonstrating using absolute and relative file paths. On Mac OS, files are written with forward slashes (i.e., datasets/penguins.csv). On Windows, backslashes are used (i.e., datasets\\penguins.csv). My examples are writted for MacOS - the only thing you‚Äôd need to change in the examples are the direction of the slashes if you plan to reproduce my code!\nLater in the lecture, we discuss the here::here() function which solves this problem completely.\n\n\nCommon file formats include\n\nSpreadsheets: Excel, Google Sheets, Numbers\nDelimited files: Plaintext files containing data, e.g.¬†comma separated values (CSVs), tab separated values (TSVs)\nR binary: A serialization of an R object to a binary file. Basically, that means that it can be loaded in and out of R, but it can‚Äôt be opened by anything but R.\n\nCSVs are the most ‚Äúone-size-fits-all‚Äù: you can open them in spreadsheet software, but they are also plaintext, so are lightweight, can be opened in any text editor, and can be ‚Äúdiff‚Äùed.¬†Spreadsheets are nice for human interaction (like through Excel), but can be clunky in R. R binary is quite restrictive and we don‚Äôt tend to store data this way. Our lecture will focus on CSVs.\n\n\nJenny Bryan‚Äôs website has a fabulous section on reading and writing files in R. We‚Äôre going to summarize a few of the important functions here, but if you‚Äôd like to learn more then check out that website for more in-depth explorations!\nWe are going to focus on reading and writing data using the readr package, because we think it has the most ‚Äúwork right out of the box‚Äù experience.\nWe will start by talking about how to read and write Comma Separated Value (CSV) files (files that end in .csv). CSVs are often used to store data. When the penguins data set is stored as a .csv, the first few entries look like when opened as a text file:\nspecies,island,bill_len,bill_dep,flipper_len,body_mass,sex,year\nAdelie,Torgersen,39.1,18.7,181,3750,male,2007 Adelie,Torgersen,39.5,17.4,186,3800,female,2007 Adelie,Torgersen,40.3,18,195,3250,female,2007 Adelie,Torgersen,NA,NA,NA,NA,NA,2007 Adelie,Torgersen,36.7,19.3,193,3450,female,2007 Adelie,Torgersen,39.3,20.6,190,3650,male,2007 Adelie,Torgersen,38.9,17.8,181,3625,female,2007 Adelie,Torgersen,39.2,19.6,195,4675,male,2007\nNow, this isn‚Äôt exactly easy for humans to read, but saving data as CSVs has its advantages. The data is stored in a simple form (lightweight - files aren‚Äôt large) that has broad compatibility and can be used in a wide range of applications. And of course, we can use functions in R to make it more readable. A few main functions of note are\n\nread_csv(): tidyverse equivalent of read.csv() used to read from a CSV to a tibble\nwrite_csv(): tidyverse equivalent of write.csv() used to export a tibble into CSV format\n\nLet‚Äôs assume that a file called penguins.csv is saved in a dataset folder in our current directory. We can read in, and save the tibble as a variable called penguins using:\n\npenguins &lt;- read_csv(\"datasets/penguins.csv\")\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_len, bill_dep, flipper_len, body_mass, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins)\n\n# A tibble: 6 √ó 8\n  species island    bill_len bill_dep flipper_len body_mass sex     year\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie  Torgersen     39.1     18.7         181      3750 male    2007\n2 Adelie  Torgersen     39.5     17.4         186      3800 female  2007\n3 Adelie  Torgersen     40.3     18           195      3250 female  2007\n4 Adelie  Torgersen     NA       NA            NA        NA &lt;NA&gt;    2007\n5 Adelie  Torgersen     36.7     19.3         193      3450 female  2007\n6 Adelie  Torgersen     39.3     20.6         190      3650 male    2007\n\n\nPretty easy! Note that the file path needs to be a string, relative to where you are now in the directory (i.e., where the R script you‚Äôre working on is saved. You can always call getwd() to see what directory you‚Äôre working on currently, and we‚Äôll show more tools for dealing with directories later in this lecture.)\nWe can manipulate the data, and save the output as a new CSV. For example,\n\npenguins_2007 &lt;- penguins %&gt;%\n  filter(year == 2007) #filter only on year 2007\n\nwrite_csv(penguins_2007, \"datasets/penguins_2007.csv\") #save csv in datasets folder, name as penguins_2007.csv\n\nNow, in my datasets folder, I have penguins and penguins_2007.\n\n\n\n\n\n\nNote\n\n\n\nWant to read and write to an Excel file? The readxl package in the tidyverse is for you!\nFor the very niche option of R binary: read_rds() and write_rds().\n\n\n\n\n\nAs previously mentioned, we need to specify where we are reading/writing our data from/to. The best practice is to use a relative path. This helps with reproducibility and automation!\nI could always read in my penguins dataset using an absolute file path where the file path begins at the root of your computer (for me, it is a long chain of folders in /Users/......../STAT545/stat454.github.io/webpages/lectures_i/datasets/penguins.csv). This, however, is not best practice. As previously mentioned, this string telling me where the file path is can also differ for Windows users! I‚Äôd have to manually change all of the forward slashes to backslashes to make this run on Windows.\nWe will use the here package for relative file paths. Let‚Äôs (install, if necessary, and) load it and call the function here()\n\n\n# install.packages(\"here\")\nlibrary(here)\nhere()\n\n[1] \"/Users/gracetompkins/Library/CloudStorage/OneDrive-UBC/Teaching/STAT545/STAT545.github.io\"\n\n\nI get that long chain of folders where this R Project (which I used to build this website) is stored. The cool thing about here is that I can specify a file path relative to my project root (the above location) without using any operating system-specific strings.\nFor example, the penguins.csv data set is located in webpages &gt; lectures_i &gt; datasets within my R project folder. I can access it by:\n\npenguins &lt;- read_csv(here(\"webpages\", \"lectures_i\", \"datasets\", \"penguins.csv\"))\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_len, bill_dep, flipper_len, body_mass, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins) #view first few entries of the tibble\n\n# A tibble: 6 √ó 8\n  species island    bill_len bill_dep flipper_len body_mass sex     year\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie  Torgersen     39.1     18.7         181      3750 male    2007\n2 Adelie  Torgersen     39.5     17.4         186      3800 female  2007\n3 Adelie  Torgersen     40.3     18           195      3250 female  2007\n4 Adelie  Torgersen     NA       NA            NA        NA &lt;NA&gt;    2007\n5 Adelie  Torgersen     36.7     19.3         193      3450 female  2007\n6 Adelie  Torgersen     39.3     20.6         190      3650 male    2007\n\n\nThis is reproducible!",
    "crumbs": [
      "Lecture 7A: Reading and Writing Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7a_readwritedata.html#section",
    "href": "webpages/lectures_i/lec7a_readwritedata.html#section",
    "title": "Lecture 7A: Reading and Writing Data",
    "section": "",
    "text": "Exercise\n\n\n\nOpen RStudio. Go to Session =&gt; Set Working Directory =&gt; Choose Directory and then pick a folder you would like to read and write data into. Then, run the following piece of code in a new R Script:\nlibrary(tidyverse) \nlibrary(gapminder)\n\ngap_asia_2007 &lt;- gapminder %&gt;% \n  filter(year == 2007, continent == \"Asia\")\nhead(gap_asia_2007)\nWrite gap_asia_2007 to a comma-separated value (csv) file named exported_file.csv with just one command:\nwrite_csv(FILL_THIS_IN, \"exported_file.csv\")\nCheck out your files after executing this line!\nNow, let‚Äôs practice reading csvs by reading the file we just wrote back into R:\ngap_asia_2007_in &lt;- read_csv(\"FILL_THIS_IN\")\nCheck out your R environment after executing this line!\nAlso notice the output of running read_csv. This tells us about the types of variables that were read in. It‚Äôs a good habit to check this every time you run a read_ function. Sometimes we might want to change how these variable types are specified.",
    "crumbs": [
      "Lecture 7A: Reading and Writing Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7a_readwritedata.html#resources",
    "href": "webpages/lectures_i/lec7a_readwritedata.html#resources",
    "title": "Lecture 7A: Reading and Writing Data",
    "section": "Resources",
    "text": "Resources\n\nVideo lecture: Reading and Writing Data\nThe ‚ÄúWriting and Reading files‚Äù chapter of stat545.com.\n\n\nAttribution\nWritten by Grace Tompkins using materials from Vincenzo Coia and Jenny Bryan.",
    "crumbs": [
      "Lecture 7A: Reading and Writing Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html",
    "title": "Lecture 7B: Tibble Joins",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\nWe will require the tidyverse functions for this chapter:\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#overview-of-join-functions",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#overview-of-join-functions",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Overview of join functions",
    "text": "Overview of join functions\nNote: In order to merge two tibbles, you need to have an identifier variable that has unique values for every row of observations in both tibbles.\nCreate two sample tibbles:\n\n# First tibble\ndf1 &lt;- tibble(ID = 1:3,                     \n              Name = c(\"Sophie\", \"Josh\",\"Alex\"))\n\n# Second tibble\ndf2 &lt;- tibble(ID = 2:4,                      \n              Age = c(20,50,31))",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#mutating-joins",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#mutating-joins",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Mutating joins",
    "text": "Mutating joins\n\nJoin matching rows from df2 to df1\n\n\n\n\n\n\nleft_join(df1, df2, by = \"ID\")\n\n# A tibble: 3 √ó 3\n     ID Name     Age\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 Sophie    NA\n2     2 Josh      20\n3     3 Alex      50\n\n\n\n\nJoin matching rows from df1 to df2\n\n\n\n\n\n\nright_join(df1, df2, by = \"ID\")\n\n# A tibble: 3 √ó 3\n     ID Name    Age\n  &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n1     2 Josh     20\n2     3 Alex     50\n3     4 &lt;NA&gt;     31\n\n\n\n\nRetain only rows present in both sets\n\n\n\n\n\n\ninner_join(df1, df2, by = \"ID\")\n\n# A tibble: 2 √ó 3\n     ID Name    Age\n  &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n1     2 Josh     20\n2     3 Alex     50\n\n\n\n\nRetain all values, all rows\n\n\n\n\n\n\nfull_join(df1, df2, by = \"ID\")\n\n# A tibble: 4 √ó 3\n     ID Name     Age\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 Sophie    NA\n2     2 Josh      20\n3     3 Alex      50\n4     4 &lt;NA&gt;      31",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#filtering-joins",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#filtering-joins",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Filtering joins",
    "text": "Filtering joins\n\nRetain all rows in df1 that have a match in df2\n\n\n\n\n\n\nsemi_join(df1, df2, by = \"ID\")\n\n# A tibble: 2 √ó 2\n     ID Name \n  &lt;int&gt; &lt;chr&gt;\n1     2 Josh \n2     3 Alex \n\n\n\n\nRetain all rows in df1 that do not have a match in df2\n\n\n\n\n\n\nanti_join(df1, df2, by = \"ID\")\n\n# A tibble: 1 √ó 2\n     ID Name  \n  &lt;int&gt; &lt;chr&gt; \n1     1 Sophie",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#binding",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#binding",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Binding",
    "text": "Binding\n\nAppend df2 to df1 as new rows\n\n\n\n\n\n\nbind_rows(df1, df2)\n\n# A tibble: 6 √ó 3\n     ID Name     Age\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 Sophie    NA\n2     2 Josh      NA\n3     3 Alex      NA\n4     2 &lt;NA&gt;      20\n5     3 &lt;NA&gt;      50\n6     4 &lt;NA&gt;      31\n\n\n\n\nAppend df2 to df1 as new columns\n\n\n\n\n\n\nbind_cols(df1, df2)\n\nNew names:\n‚Ä¢ `ID` -&gt; `ID...1`\n‚Ä¢ `ID` -&gt; `ID...3`\n\n\n# A tibble: 3 √ó 4\n  ID...1 Name   ID...3   Age\n   &lt;int&gt; &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n1      1 Sophie      2    20\n2      2 Josh        3    50\n3      3 Alex        4    31",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-multiple-2-tibbles",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-multiple-2-tibbles",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Joining multiple (>2) tibbles",
    "text": "Joining multiple (&gt;2) tibbles\nCreate a third tibble\n\ndf3 &lt;- tibble(ID = 1:5,                      \n              Height = c(175,167,190,155,160))\n\n\n\n\n\n\nUse piping operator (%&gt;%) to layer multiple join functions\n\nfull_join(df1, df2, by = \"ID\") %&gt;%\n  full_join(df3, by = \"ID\") \n\n# A tibble: 5 √ó 4\n     ID Name     Age Height\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     1 Sophie    NA    175\n2     2 Josh      20    167\n3     3 Alex      50    190\n4     4 &lt;NA&gt;      31    155\n5     5 &lt;NA&gt;      NA    160",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-tibbles-on-multiple-conditions",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-tibbles-on-multiple-conditions",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Joining tibbles on multiple conditions",
    "text": "Joining tibbles on multiple conditions\n\n\n\n\n\nCreate two new tibbles df4 and df5\n\ndf4 &lt;- tibble(FirstName = c(\"Sophie\", \"Josh\",\"Alex\"),\n              LastName=c(\"Wang\",\"Smith\",\"Smith\"),\n              Age = c(42,20,50))\n\ndf5 &lt;- tibble(First_name = c(\"Josh\",\"Alex\",\"Sophie\"),        \n              Last_name=c(\"Smith\",\"Smith\",\"Jones\"),\n              Height = c(167,190,155))\n\n\n\n\n\n\n\nfull_join(df4, df5, by = c(\"FirstName\" = \"First_name\", \"LastName\" = \"Last_name\"))\n\n# A tibble: 4 √ó 4\n  FirstName LastName   Age Height\n  &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 Sophie    Wang        42     NA\n2 Josh      Smith       20    167\n3 Alex      Smith       50    190\n4 Sophie    Jones       NA    155",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#set-operations",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#set-operations",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Set operations",
    "text": "Set operations\nCreate sample tibbles\n\n\n\n\n\n\n# First tibble\ndf6 &lt;- tibble(Number = 1:3,                     \n              Letter = c(\"A\", \"B\",\"C\"))\n\n# Second tibble\ndf7 &lt;- tibble(Number = 2:4,                      \n              Letter = c(\"B\",\"C\",\"D\"))\n\n\nInclude rows that appear in both tibbles\n\n\n\n\n\n\n# First tibble\ndf6 &lt;- tibble(Number = 1:3,                     \n              Letter = c(\"A\", \"B\",\"C\"))\n\n# Second tibble\ndf7 &lt;- tibble(Number = 2:4,                      \n              Letter = c(\"B\",\"C\",\"D\"))\n\n\n\nInclude rows that appear in either or both tibbles\n\n\n\n\n\n\nunion(df6, df7)\n\n# A tibble: 4 √ó 2\n  Number Letter\n   &lt;int&gt; &lt;chr&gt; \n1      1 A     \n2      2 B     \n3      3 C     \n4      4 D     \n\n\n\n\nInclude rows that appear in one tibble/dataset but not another\n\n\n\n\n\nInclude rows that appear in df6 but not in df7\n\nsetdiff(df6, df7)\n\n# A tibble: 1 √ó 2\n  Number Letter\n   &lt;int&gt; &lt;chr&gt; \n1      1 A     \n\n\nInclude rows that appear in df7 but not in df6\n\nsetdiff(df7, df6)\n\n# A tibble: 1 √ó 2\n  Number Letter\n   &lt;int&gt; &lt;chr&gt; \n1      4 D",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-tibbles-with-different-types-of-variables",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-tibbles-with-different-types-of-variables",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Joining tibbles with different types of variables",
    "text": "Joining tibbles with different types of variables\nYou can also join tibbles with sets of predictions:\n\nset.seed(1) #make reproducible\n\nx &lt;- rnorm(5) #randomly sample 5 times from a N(0,1) distribution\n\nmodel1 &lt;- tibble(x = x, yhat = 2.1 + 3.2 * x) #do prediction based on the linear function\nmodel2 &lt;- tibble(x = x, yhat = 1.5 + 2.9 * x)\n\nleft_join(model1, model2, by = \"x\")\n\n# A tibble: 5 √ó 3\n       x  yhat.x yhat.y\n   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 -0.626  0.0953 -0.317\n2  0.184  2.69    2.03 \n3 -0.836 -0.574  -0.923\n4  1.60   7.20    6.13 \n5  0.330  3.15    2.46",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#worksheet-a5",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#worksheet-a5",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Worksheet A5",
    "text": "Worksheet A5\nTry your hand at basics of tibble joins by working through the corresponding part of Worksheet A5.\nThere will be some class time to go over solutions if you got stuck on any questions.",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#resources",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#resources",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Resources",
    "text": "Resources\n\nVideo lecture: Tibble Joins with dplyr\n‚ÄúRelational Data‚Äù chapter in ‚ÄúR for Data Science‚Äù.\n‚ÄúTwo-table verbs‚Äù vignette gives a concise overview of tibble joins with dplyr.\nJenny‚Äôs Join Cheatsheet for a quick reference to joins.\ndplyr cheatsheet for all these concepts packed onto a sheet of paper.\n\n\nAttributions\nWritten by Albina Gibadullina and Vincenzo Coia",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec8b_advfunctions.html",
    "href": "webpages/lectures_ii/lec8b_advfunctions.html",
    "title": "Lecture 8b: Advanced Functions",
    "section": "",
    "text": "We will learn about a couple of advanced topics:\n\nData-masking and the curly-curly {{}}\nDefault values\nEllipses ...\nHandling NA‚Äôs\n\nThese topics are covered in the R4DS Functions book chapter as well. So if you miss this class, then the R4DS Functions reading is a good alternative.\nWe will be using the following packages throughout this lecture:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\nlibrary(gapminder)\n\n\nExample: Counting Missing Values by Group\nHere‚Äôs some code that:\n\ngroups penguins by species, then summarizes the number of missing values in each variable.\ngroups gapminder by continent, then summarizes the number of missing values in each variable.\n\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarize(across(everything(), ~ sum(is.na(.x))))\n\n# A tibble: 3 √ó 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;      &lt;int&gt;          &lt;int&gt;         &lt;int&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie         0              1             1                 1           1\n2 Chinstrap      0              0             0                 0           0\n3 Gentoo         0              1             1                 1           1\n# ‚Ñπ 2 more variables: sex &lt;int&gt;, year &lt;int&gt;\n\n\n\ngapminder %&gt;% \n  group_by(continent) %&gt;% \n  summarize(across(everything(), ~ sum(is.na(.x))))\n\n# A tibble: 5 √ó 6\n  continent country  year lifeExp   pop gdpPercap\n  &lt;fct&gt;       &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;int&gt;     &lt;int&gt;\n1 Africa          0     0       0     0         0\n2 Americas        0     0       0     0         0\n3 Asia            0     0       0     0         0\n4 Europe          0     0       0     0         0\n5 Oceania         0     0       0     0         0\n\n\nThese steps to summarize the data are quite similar! Instead of coding each step multiple times, let‚Äôs turn it into a function.\n\n\n\n\n\n\nExercise 1\n\n\n\nBy yourself or in small groups, try to turn the code above into a function called summarizeby_fun(). Document your code!\n\n\nWe will go over the solution in class.\n\n\nData-masking and the Curly-Curly {{}}\nSometimes your function needs to take in variable names without quotation marks and work with them that way.\nFor example, select(penguins, species) does not put quotation marks around lifeExp ‚Äì the reasoning being that lifeExp is like a variable in our workspace, if we were to include column names in our R Environment ‚Äì and select(\"penguins\", \"species\") will not do the same thing.\nIf your function needs to do this, then you need to work with the arguments with extra care inside the function definition. Whenever we use those arguments, we need to embrace them within two curly brackets ‚Äì an operator called ‚Äúcurly curly‚Äù.\nTake this function that produces a quick scatterplot between two columns in a dataset as an example.\nquick_scatter &lt;- function(data, x, y) {\n  ggplot(data, aes(x, y)) + #note curly brackets here!\n     geom_point()\n}\n\nquick_scatter(penguins, bill_length_mm, body_mass_g)\nError in `geom_point()`:\n! Problem while computing aesthetics.\n‚Ñπ Error occurred in the 1st layer.\nCaused by error:\n! object 'bill_length_mm' not found\nWhy doesn‚Äôt this work? The reason is that R is looking for variables named bill_len and body_mass in the workspace, and cannot find them. To fix the problem, we can change the function definition so that `x` and `y` are embraced within two curly brackets {{}} (‚Äúcurly curly‚Äù):\n\nquick_scatter &lt;- function(data, x, y) {\n  ggplot(data, aes({{ x }}, {{ y }})) + #note curly brackets here!\n     geom_point()\n}\n\nquick_scatter(penguins, bill_length_mm, body_mass_g)\n\n\n\n\n\n\n\n\nBut, you can only use curly-curly when passing your function‚Äôs argument to another function that‚Äôs anticipating a variable name without brackets.\n\n\n\n\n\n\nTip\n\n\n\nIn the `dplyr` documentation, if you spy the words ‚Äúdata masking‚Äù or ‚Äútidy selection‚Äù, then you will need to curly-curly your arguments when using those functions within your custom function.\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nMake a modification to our function summarizeby_fun(): allow the user to also pass in which variables they want to summarize. (Right now it just summarizes all of them.)\n\n\nWe will go over the solution in class.\n\n\nDefault Parameters\nRecall the dice-rolling example from the previous lecture. Sometimes you want to use a function frequently without re-writing the same parameters over and over again. Let‚Äôs make a more flexible function that allows us to change the number of faces on the dice being rolled.\n\n#' @details\n#' Simulates rolling `num_dice` number of dice with `n_sides` sides and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @param n_sides integer representing the number of sides of each dice\n#' @return the sum of the dice rolled\n  \nroll_dice &lt;- function(n_sides, num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum(sample(1:n_sides, num_dice, replace=TRUE)) #sample two numbers from one to n_sides with replacement, return sum\n}\n\nNotice now that in this function, there are two parameters (the new one is n_sides). We are also sampling from 1:nsides instead of 1:10 to make the function more flexible. I also renamed the function to roll_dice as we are not necessarily rolling d10 dice.\nSo to roll 2, 10-sided dice, I can call:\n\nroll_dice(n_sides = 10, num_dice = 2)\n\n[1] 9\n\n\nIf I wanted to make the default number of sides to 10, I can do that in the function()!\n\n#' @details\n#' Simulates rolling `num_dice` number of dice with `n_sides` sides and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @param n_sides integer representing the number of sides of each dice. Default is 10.\n#' @return the sum of the dice rolled\n  \nroll_dice &lt;- function(n_sides = 10, num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum(sample(1:n_sides, num_dice, replace=TRUE)) #sample two numbers from one to n_sides with replacement, return sum\n}\n\nWe have set n_sides = 10 as the default. This means the function will assume we have a 10 sided dice unless otherwise specified. Let‚Äôs roll 3 dice using 10 sided dice (the default):\n\nroll_dice(num_dice = 3)\n\n[1] 19\n\n\nI didn‚Äôt need to include n_sides = 10 in my function call! But I can if I want to change it to a number other than 10. Let‚Äôs roll 3 standard 6-sided dice\n\nroll_dice(n_sides = 6, num_dice = 3)\n\n[1] 12\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nMake a new argument for the summarizeby_fun() we made previously called .groups that makes it default to dropping the groups in the output.\n\n\n\n\nEllipses (...)\nThe ellipses allow a function to accept a variable number of additional unnamed arguments beyond what is explicitly written in the function. Many built-in functions have ... listed (check out c()!)\n\n\n\n\n\n\nInstructor Demo\n\n\n\nWe‚Äôll modify our function together using ellipses to get extra functionality: we‚Äôll allow the user to group by more than one variable.\n\n\n\n\nHandling NAs\nMissing data is essentially inevitable. Few studies are able to collect 100% of the data they intend to.\nMissing data can heavily complicate analyses and even lead to biased results when not handled properly. Missing data is a big research area in statistics! But for this class, we are going to focus on dealing with missing data using a simple example.\nLet‚Äôs look at the flipper length of penguins in the penguins data set and count how many missing values there are using the is.na() function in R. is.na(flipper_len) will return a vector full of TRUE or FALSE values indicating whether or not the observation was missing. As TRUE is coded as a 1 and FALSE as a 0, we can sum over these to count how many missing values there are.\n\nflipper_len &lt;- penguins$flipper_length_mm #save this data as its own vector\nsum(is.na(flipper_len)) # count how many NAs there are in the flipper data\n\n[1] 2\n\n\nWe see we have two missing values. Let‚Äôs see if we can summarize the quantiles of the lengths:\nquantile(flipper_len)\nError in quantile.default(flipper_length) :\nmissing values and NaN's not allowed if 'na.rm' is FALSE\nWe see here that missing values are not allowed unless we specify na.rm = TRUE. When na.rm = TRUE, we remove missing values from the data and then calculate the quantiles. This is also referred to as a complete case analysis.\n\nquantile(flipper_len, na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n 172  190  197  213  231 \n\n\nNow suppose we wanted to make our own function that utilized the quantile() built-in function:\n\n#' @details\n#' calculates the range of data by finding the 100th and 0th quantile and finding their difference\n#'\n#' @param vec a vector that we want to find the range of\n#' @return the difference in the maximum and minimum\n  \nget_range &lt;- function(vec){\n  quantiles &lt;- quantile(vec, na.rm = TRUE) #calc quantiles, remove NA's\n  return(max(quantiles) - min(quantiles)) #calculate and return the range\n}\n\nget_range(flipper_len)\n\n[1] 59\n\n\nWe could also include na.rm in our function parameters to allow the user to specify whether or not it should be set to TRUE or FALSE. We can use a default, as well.\n\n#' @details\n#' calculates the range of data by finding the 100th and 0th quantile and finding their difference\n#'\n#' @param vec a vector that we want to find the range of\n#' @param na.rm logical, whether or not to remove NAs. Default set to TRUE.\n#' @return the difference in the maximum and minimum\n  \nget_range &lt;- function(vec, na.rm = TRUE){\n  quantiles &lt;- quantile(vec, na.rm = na.rm) #calc quantiles, remove NA's\n  return(max(quantiles) - min(quantiles)) #calculate and return the range\n}\n\nget_range(flipper_len) #default to true\n\n[1] 59\n\n\n\n\nAttribution\nSome of these notes were originally compiled by previous iterations of the instructional staff, including Vincenzo Coia.",
    "crumbs": [
      "Lecture 8b: Advanced Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html",
    "href": "webpages/lectures_ii/lec9_rpackages.html",
    "title": "Lecture 9: R Packages",
    "section": "",
    "text": "From this topic, students are anticipated to be able to build a basic R package, especially using the devtools package.",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html#why-r-packages",
    "href": "webpages/lectures_ii/lec9_rpackages.html#why-r-packages",
    "title": "Lecture 9: R Packages",
    "section": "Why R Packages?",
    "text": "Why R Packages?\nAs mentioned in the ‚Äúfunctions‚Äù topic, your analysis will probably benefit from homemade functions: making functions forces you to think about your analysis in terms of its key computational parts, and makes for robust and readable code. Here are a few benefits that result by bundling these functions into an R package:\n\nOrganized documentation\nSharability\nBuilt-in checks to ensure your package is working\nTemplates for organizing your work\nEasy way to share datasets\n\nThe alternative is keeping the functions stored in separate files, and source()ing them into your analysis scripts, but this can become unwieldy. Plus, if your package becomes really nice, you might want to share it with the world!\nFor this topic, we‚Äôll be making an R package like the toy square package, by following along with ‚ÄúThe Whole Game‚Äù Chapter of ‚ÄúR packages‚Äù. Here‚Äôs a checklist based on that chapter. If you miss class, check out How to Make an R Package video lecture, then try following along using the book, and coming to office hours or asking questions on Slack if you get stuck.\n\n\n\n\n\n\nTip\n\n\n\nMany of the functions we call are from the devtools package in R. If you‚Äôre getting errors when trying to run some commands, try reloading devtools in the Console by running library(devtools).",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html#minimal-working-example",
    "href": "webpages/lectures_ii/lec9_rpackages.html#minimal-working-example",
    "title": "Lecture 9: R Packages",
    "section": "Minimal Working Example",
    "text": "Minimal Working Example\nFirst, make a minimal viable product:\n\nIn any R console, install (if necessary) and load the devtools package in the console (do this every time you go to work on your package).\n\nYou will create a new R Project in the next step, so don‚Äôt worry about the location now.\n\nRun create_package() in the console (NOTE: all devtools functions should be written in the console).\n\nBetter defaults than going through the File menu.\nSet the file path to be wherever you‚Äôd like the package to live. I‚Äôll be saving it on my desktop in a (not yet created) folder called ‚Äúpowers‚Äù by calling create_package(\"~/Desktop/powers\")\nAllow access if a pop-up appears, and RStudio will refresh to your new Project.\nIf you look at the new folder that was created (mine is on my desktop), you‚Äôll see an R Project, a DESCRIPTION file, a NAMESPACE file, and an R folder where all of your functions will be.\n\nCreate a simple function in a .R file, and save it in the R folder\n\nyou can do this by navigating to the R folder on the right hand pane of your R Project under ‚ÄúFiles‚Äù, opening the R folder, and selecting ‚ÄúNew File‚Äù &gt; ‚ÄúR Script‚Äù\n\n\n\n\n\nName the file ‚Äúsquare.R‚Äù. We will be adding a simple function to file with an #' @export command to ensure it works properly with our package\n\n#' @export\nsquare &lt;- function(x){\n  x^2\n}\n\n\nIn the console, reload devtools and run the document() function.\n\nAny function with the #' @export tag will be exported to the namespace file which contains a list of functions we want to make available in the R package.\n\nRun use_git() to start using version control and hosting your package on Github:\n\nPrefer to start your project on GitHub? Or locally? Either way, useful instructions for what to do can be found in ‚ÄúHappy Git with R‚Äù Part III.\n\nRun load_all() in the console to test your package out\n\nIf R Restarted, then you need to reload devtools before running load_all().\nsee if square(5) returns the correct answer\n\nCheck that the package is intact: run check() in the Console\nEdit the DESCRIPTION file\n\nFirst, run use_mit_license(\"Your Name\") in the Console.\nOpen the DESCRIPTION file and edit the Author information and Package Title.\nPackage: powers\nTitle: Easy computation of powers\nVersion: 0.0.0.9000\nAuthors@R: \n    person(\"YOUR FIRST NAME\", \"YOUR LAST NAME\", , \"YOUR EMAIL\", role = c(\"aut\", \"cre\"))\nDescription: Calculates various powers of numeric data (squares, cubics, etc)\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.3.2\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3\n\nAdd a README file\n\nRun use_readme_rmd() in the Console.\nOpen the RMD file and add some information for the package.\n---\noutput: github_document\n---\n\n&lt;!-- README.md is generated from README.Rmd. Please edit that file --&gt;\n\n\n\n\n\n\n\n# powers Package\n\nThis is a minimal working example of my first R Package for STAT545!\n\n## Installation\n\nPackage installation can be done directly by calling\n`devtools::install_github(\"YOUR_GITHUB_USERNAME/powers\")`\n\n## Example\n\nThis is a basic example which shows you how to solve a common problem:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(powers)\n#&gt; \n#&gt; Attaching package: 'powers'\n#&gt; The following object is masked _by_ '.GlobalEnv':\n#&gt; \n#&gt;     square\nsquare(c(2,4,5))\n#&gt; [1]  4 16 25\n```\n:::\n\n\n\n\nRender the README every time with build_readme().\n\nDocument the function:\n\nNavigate back to the function square we made and click anywhere inside of the function. Select ‚ÄúCode‚Äù &gt; ‚ÄúInsert roxygen skeleton‚Äù\nEdit the documentation for param, returns, and examples. You can also add a @title and @description. Here‚Äôs what mine looks like:\n\n\n#' @title Square a single value or vector\n#' @description\n#' Squares a single numeric value or a numeric vector\n#'\n#' @param x, numeric\n#'\n#' @returns numeric, vector\n#'\n#' @examples\n#' square(5)\n#' square(c(4, 5, 6))\n#' @export\nsquare &lt;- function(x){\n  x^2\n}\n\nRun document() again in the Console.\nRun check() again to make sure your examples are working.\n\nInstall and Restart (Ctrl + Shift + B (Windows & Linux) or Cmd + Shift + B (macOS)) , or run install() in the console. Try loading the package and using it!",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html#expand-your-package",
    "href": "webpages/lectures_ii/lec9_rpackages.html#expand-your-package",
    "title": "Lecture 9: R Packages",
    "section": "Expand Your Package",
    "text": "Expand Your Package\nNow, let‚Äôs expand the R package that we just created:\n\nRun use_testthat() in the Console (re-load devtools if R recently restarted)\n\nThis will create a folder called tests and a testthat.R file which we will add our tests to.\nRun use_test(\"square\") in the Console. This will create a file called test-square.R\nUpdate it to include the following tests (and save the file!):\ntest_that(\"square works\", {\n  expect_equal(square(3), 9)\n  expect_equal(square(0), 0)\n  expect_equal(square(c(2,4)), c(4,16))\n  expect_equal(square(c(3, NA)), c(9, NA))\n})\nCheck all tests with test() in the Console. This also happens with check().\n\nWe don‚Äôt really need to use functions from another package here, but practice declaring your general intention to use some functions from the dplyr namespace by running use_package(\"dplyr\") in the Console only once. Now your package will be able to use the dplyr package functions.\nConnect your local package to Github with use_github(). Say yes to committing and publishing the changes. Now your package should be on GitHub!\nMake a vignett, a long-form document that serves as a detailed guide or tutorial for an R package:\n\nuse_vignette(\"powers\")\nbuild_vignettes().\n\nInclude data with the R package with use_data(R_OBJECT_HERE). Then document a string of its name in a new R script using a different collection of roxygen tags.\n\nI‚Äôll add the mtcars dataset using use_data(mtcars)\n\nRelease your package:\n\nMake a NEWS.md file with use_news_md() and add the main development notes.\nCommit changes (in Terminal on RStudio)\n\ngit add .\ngit commit -m \"Adding Vignette:\"\n\nPush Changes (in Terminal on RStudio)\n\ngit push origin main\n(If you get an error, try going to the Git section in the top right hand pane and push from there)\n\nTag a release on GitHub.\n\nRecall How to tag a release from the Collaborative Project Milestone 1:\n\nNavigate to the main page (root) of your GitHub repository.\nThere should be a small link on the right-hand-side of your page that says ‚ÄúCreate a new release‚Äù. Click that.\nFor the tag version/name, put 1.0.0\nChoose a release title and description (this is less important).\nDo not check off ‚ÄúThis is a pre-release‚Äù.\nClick ‚ÄúPublish Release‚Äù.\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry installing the package that the person beside you just created. Restart RStudio, load devtools and see if you can use devtools::install_github(\"YOUR_GITHUB_USERNAME/powers\") to install their package. Load in the newly installed powers package and test out the square function and see if it works!",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html#resources",
    "href": "webpages/lectures_ii/lec9_rpackages.html#resources",
    "title": "Lecture 9: R Packages",
    "section": "Resources",
    "text": "Resources\nVideo Lecture:\n\nHow to Make an R Package\n\nWritten material:\n\nSee ‚ÄúThe Whole Game‚Äù Chapter of ‚ÄúR packages‚Äù for a concise overview of the entire process of making an R package.\n\nThe entire ‚ÄúR packages‚Äù book is overall a great resource to read if you‚Äôre wanting to learn more.\n\nSee Writing R Extensions, the authoritative and comprehensive (but dry) resource for writing R packages.\nPackage development cheat sheet\nTo learn more about using S3 object oriented functions in your package, see ‚ÄúAdvanced R‚Äù Chapter 13: S3.",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/casestudies/fev_datamanipulation.html",
    "href": "webpages/casestudies/fev_datamanipulation.html",
    "title": "Lecture 3 Case Study: Data Manipulation on FEV Dataset",
    "section": "",
    "text": "Copy the following code into a new RMarkdown Document:\n---\ntitle: 'FEV Case Study: Data Manipulation'\noutput: html_document\ndate: \"2025-07-31\"\n---\n\n\n\n## Introduction \n\nWe will perform exploratory data analysis of the `fev` data set. \nLet's start by getting the data set. Load the `readr` package (more on this later) and run `fev &lt;- read_tsv(\"https://raw.githubusercontent.com/GTPB/PSLS20/master/data/fev.txt\")` to get access to it. Let's also load `dplyr` while we're at it - we'll need it to do the exercises! \n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"dplyr\") #uncomment and run once, if needed\n#install.packages(\"readr\") #uncomment and run once, if needed\n\nlibrary(dplyr)\nlibrary(readr)\nfev &lt;- read_tsv(\"https://raw.githubusercontent.com/GTPB/PSLS20/master/data/fev.txt\")\nfev_tbl &lt;- as_tibble(fev) %&gt;% mutate(across(gender:smoking, ~ as.factor(.x))) #assign gender and smoking as factors (more on this later, too!)\n```\n:::\n\n## The `fev` data set \n\nIt is now widely believed that smoking tends to impair lung function. Much of the data to support this claim arises from studies of pulmonary function in adults who are long-time smokers. A question then arises whether such deleterious effects of smoking can be detected in children who smoke. To address this question, measures of lung function were made in about 600 children seen for a routine check up in a particular pediatric clinic. The children participating in this study were asked whether they were current smokers.\n\nA common measurement of lung function is the forced expiratory volume (FEV), which measures how much air you can blow out of your lungs in a short period of time. A higher FEV is usually associated with better respiratory function. It is well known that prolonged smoking diminishes FEV in adults, and those adults with diminished FEV also tend to have decreased pulmonary function as measured by other clinical variables, such as blood oxygen and carbon dioxide levels.\n\nData collected from the study on the relationship between smoking status and lung function (measured by FEV) in children are contained in the `fev_tbl` dataset. Here is a data dictionary:\n\n| Variable Name | Description | \n| :--: |:--: |\n| age           | subject age (years) | \n| fev           | measured forced exhalation volume (litres/second)| \n| height        | subject height (inches) | \n| gender        | subject gender (here, male or female) | \n| smoking         | smoking status (yes or no) | \n\n\nHere is a few rows of the data set:\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(fev_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 √ó 5\n    age   fev height gender smoking\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  \n1     9  1.71   57   f      0      \n2     8  1.72   67.5 f      0      \n3     7  1.72   54.5 f      0      \n4     9  1.56   53   m      0      \n5     9  1.90   57   m      0      \n6     8  2.34   61   f      0      \n```\n\n\n:::\n:::\n\n\n## Understanding the data structure\n\n### Exercise 1\n\nAm I missing any variables compared to the data dictionary? Let's check. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\n### Exercise 2\n\nNext: are there any duplicate case numbers? Are there any duplicate subject IDs?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nNow we know that no cases were entered twice, and each case corresponds to a different patient. \n\n## Understanding the patients in the study\n\n### Exercise 3\n\nLet's summarize the age of the patients first, by computing the mean, standard deviation, min, and max of the patient ages. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nSomething's a little odd about these summaries. Remember: this is a smoking study on children.\n\n- Why would a 3 year old be enrolled in a smoking study?  \n- Why would a 19 year old be enrolled in a study on children? \n\n### Exercise 4\n\nI'm now a bit worried: what's the youngest patient who smokes in this dataset?\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE \n```\n:::\n\nLooks like the youngest patient who smokes is 9. Seems young to me, but much less far-fetched than (say) 3. \n\n### Exercise 5\n\nWhat about the 19 year olds? Should they be included? The definition of a \"child\" can vary from study to study. Possible definitions include &lt; 21 and &lt; 18.  Let's find out who the patients 18 or older are and what their case numbers are so that we can ask our point of contact for the study about them. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE \n```\n:::\n\n**Aside**: if it turns out that we need to exclude any of these odd-looking patients from our final data analysis, then we will need to re-run everything after this point with their data removed. Isn't it nice that we are preparing this report in R Markdown?  \n\n### Exercise 6\n\nThis is a smoking study, so it seems useful to know what proportion of the study participants are smokers. In fact, let's break it down by sex, and calculate the proportion of girls who are smokers and the proportion of boys who are smokers, as well as the number of girls and the number of boys in the study. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nThe proportion of girls who are smokers is higher than the proportion of boys that are smokers.\n\n### Exercise 7\n\nIs this because there are more smokers among teenage girls than teenage boys? Or is this a phenomenon that is uniform across age groups? To find out, let's calculate: \n\n- the proportion and number of girls aged 0-6 who are smokers\n- the proportion and number of girls aged 7-12 who are smokers \n- the proportion and number of girls aged 13-19 who are smokers\n- the proportion and number of boys aged 0-6 who are smokers\n- the proportion and number of boys aged 7-12 who are smokers \n- the proportion and number of boys aged 13-19 who are smokers\n\nHint: you will need to create a new variable that has three categories: age 0-6, age 7-12, and age 13-19. You can do so with `fev_tbl %&gt;% mutate(age_cat = cut(age, c(0, 6, 12, 19)))`.\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nThere are no smokers (female or male) in the 0-6 group. There is a higher proportion of girls in the 7-12 group who are smokers than boys in the 7-12 group. Ditto the 13-19 group. \n\n## Does smoking have an effect on lung function? \n\nLet's continue exploring the data set with a closer eye to our main research question: does smoking have an effect on lung function in children? \n\n### Exercise 8\n\nLet's start by summarizing the FEV of the smokers and non-smokers. Let's calculate the mean, standard deviation, and number of observations in each group. We will mainly be comparing the means to gather information about the question, but the standard deviation and number of observations are important to look at too. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\nWe see that the mean FEV in the smoking group seems to be substantially higher than the average FEV in the non-smoking group. That is, the smokers appear to have *better* lung function than the non-smokers. \n\nDoes this surprise you? Recall that this is an observational study - children were not randomly assigned to smoke or not smoke. We might then have reason to suspect that the association between FEV and smoking status is confounded by some other factors. For example, \nwe already know that the youngest smoker in our data set is 9, while the non-smokers are as young as 3. This suggests that the smokers in our data set are generally older than the non-smokers. Furthermore, we might expect older children to have higher FEV, because they are bigger and have bigger lungs. Could age be a confounder here? Maybe the smoking group has higher lung function simply because they are older and bigger.\n\nWe will investigate this point next week after we have learned about graphing tools.",
    "crumbs": [
      "Lecture 3 Case Study: Data Manipulation on FEV Dataset"
    ]
  },
  {
    "objectID": "webpages/casestudies/nycflights_dates.html",
    "href": "webpages/casestudies/nycflights_dates.html",
    "title": "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)",
    "section": "",
    "text": "The NYC Flights data set contains (among many other things) on-time performance data for all flights departing a New York City airport in 2013. Let‚Äôs load it from the package nycflights13. Let‚Äôs also load the tidyverse; the key package we will be using from it today is lubridate.\nThere‚Äôs lots to explore in this data set, and lots of variables! We‚Äôll work with a super pared down version.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.2     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(nycflights13)\n\nflights_demo &lt;- flights %&gt;% \n  select(year, month, day, hour, minute, flight, carrier)\n\nhead(flights_demo)\n\n# A tibble: 6 √ó 7\n   year month   day  hour minute flight carrier\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;int&gt; &lt;chr&gt;  \n1  2013     1     1     5     15   1545 UA     \n2  2013     1     1     5     29   1714 UA     \n3  2013     1     1     5     40   1141 AA     \n4  2013     1     1     5     45    725 B6     \n5  2013     1     1     6      0    461 DL     \n6  2013     1     1     5     58   1696 UA     \n\n\nThis currently contains the scheduled departure time of every flight, as well its carrier and flight code.",
    "crumbs": [
      "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)"
    ]
  },
  {
    "objectID": "webpages/casestudies/nycflights_dates.html#nyc-flights-data",
    "href": "webpages/casestudies/nycflights_dates.html#nyc-flights-data",
    "title": "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)",
    "section": "",
    "text": "The NYC Flights data set contains (among many other things) on-time performance data for all flights departing a New York City airport in 2013. Let‚Äôs load it from the package nycflights13. Let‚Äôs also load the tidyverse; the key package we will be using from it today is lubridate.\nThere‚Äôs lots to explore in this data set, and lots of variables! We‚Äôll work with a super pared down version.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.2     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(nycflights13)\n\nflights_demo &lt;- flights %&gt;% \n  select(year, month, day, hour, minute, flight, carrier)\n\nhead(flights_demo)\n\n# A tibble: 6 √ó 7\n   year month   day  hour minute flight carrier\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;int&gt; &lt;chr&gt;  \n1  2013     1     1     5     15   1545 UA     \n2  2013     1     1     5     29   1714 UA     \n3  2013     1     1     5     40   1141 AA     \n4  2013     1     1     5     45    725 B6     \n5  2013     1     1     6      0    461 DL     \n6  2013     1     1     5     58   1696 UA     \n\n\nThis currently contains the scheduled departure time of every flight, as well its carrier and flight code.",
    "crumbs": [
      "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)"
    ]
  },
  {
    "objectID": "webpages/casestudies/nycflights_dates.html#exercises",
    "href": "webpages/casestudies/nycflights_dates.html#exercises",
    "title": "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)",
    "section": "Exercises",
    "text": "Exercises\n\nDate-Time Creation and Extraction\nI want to add a fake flight to this data set: AC 123, scheduled to depart at 9:00am on Oct 1 2013.\nWe can use a family of functions named as permutations of ‚Äúy‚Äù, ‚Äúm‚Äù, and ‚Äúd‚Äù to convert character input into special Date objects.\n\nmdy(\"Oct 1 2013\")\n\n[1] \"2013-10-01\"\n\n\n\nmdy(\"October 1st 2013\")\n\n[1] \"2013-10-01\"\n\n\nWe just need to get the order right in what‚Äôs passed in - lubridate does the rest!\nWe can use a similar family of functions to convert character input into special Date-Time objects. Let‚Äôs be careful to get the timezone right too, in case it turns out to be important later.\n\n(new_sched_dep_time &lt;- mdy_hm(\"Oct 1 2013 9:00\", tz = \"America/New_York\"))\n\n[1] \"2013-10-01 09:00:00 EDT\"\n\n\nNow let‚Äôs make a 1-row tibble with the components we need: year, month, day, hour, minute, carrier, and flight code. The key will be the year(), month(), etc. functions from the lubridate package.\n\n(new_flight &lt;- tribble(~year, ~month, ~day, ~hour, ~minute, ~flight, ~carrier, \n                      year(new_sched_dep_time), month(new_sched_dep_time), \n                      day(new_sched_dep_time), hour(new_sched_dep_time), \n                      minute(new_sched_dep_time), 123, \"AC\"))\n\n# A tibble: 1 √ó 7\n   year month   day  hour minute flight carrier\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;  \n1  2013    10     1     9      0    123 AC     \n\n\nLike magic!!! We can then add it to the flights_demo dataset using bind_rows().\n\nflights_demo &lt;- bind_rows(flights_demo, new_flight)\n\n\n\nDate-Time Math\nThe full flights dataset has info about the departure delays of these flights. Let‚Äôs make another simplified version for demo purposes with that info.\n\nflights_demo2 &lt;- flights %&gt;% \n  select(year, month, day, dep_time, sched_dep_time, dep_delay)\n\nhead(flights_demo2)\n\n# A tibble: 6 √ó 6\n   year month   day dep_time sched_dep_time dep_delay\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n1  2013     1     1      517            515         2\n2  2013     1     1      533            529         4\n3  2013     1     1      542            540         2\n4  2013     1     1      544            545        -1\n5  2013     1     1      554            600        -6\n6  2013     1     1      554            558        -4\n\n\nThe dep_delay variable contains the number of minutes the flight departs either early or late, with a positive number if the flight departs late, and a negative number if the flight departs early. How was this variable made?\nLet‚Äôs see one way how. Let‚Äôs make two Date-Time objects corresponding to the departure and scheduled departure of our fake flight. If we subtract them, then we get a difftime object.\n\nnew_sched_dep_time &lt;- ymd_hm(\"2013 October 1 9:00\", tz = \"America/New_York\")\nnew_dep_time &lt;- ymd_hm(\"2013 Oct 1 9:15\", tz = \"America/New_York\")\n\nnew_dep_time - new_sched_dep_time \n\nTime difference of 15 mins\n\n\nBeautiful! In this case, this calculation was easy to do by hand, but it would‚Äôve been more annoying if we were calculating the time elapsed between (say) December 11th 2010 3:17am and March 24th 2011 11:51pm.\ndifftime objects produce human readable output, but can be a little annoying when you want output in consistent units. duration objects to the rescue - they always use seconds! Let‚Äôs do the math again but this time coerce the result to a duration object.\n\n(duration_delay &lt;- as.duration(new_dep_time - new_sched_dep_time))\n\n[1] \"900s (~15 minutes)\"\n\n\nFinally we can convert this to minutes by creating a duration object that spans a minute using the convenience function dminutes(), and doing date-time division.\n\nduration_delay/dminutes(1)\n\n[1] 15",
    "crumbs": [
      "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)"
    ]
  },
  {
    "objectID": "webpages/collabproj/collabproj_deliverable1.html",
    "href": "webpages/collabproj/collabproj_deliverable1.html",
    "title": "Collaborative Project: Deliverable 1",
    "section": "",
    "text": "Due September 19th, 2025 at 11:59pm PT",
    "crumbs": [
      "Collaborative Project: Deliverable 1"
    ]
  },
  {
    "objectID": "webpages/collabproj/collabproj_deliverable2.html",
    "href": "webpages/collabproj/collabproj_deliverable2.html",
    "title": "Collaborative Project: Deliverable 2",
    "section": "",
    "text": "Due September 26th, 2025 at 11:59pm PT",
    "crumbs": [
      "Collaborative Project: Deliverable 2"
    ]
  },
  {
    "objectID": "webpages/faq.html",
    "href": "webpages/faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "September - December of each academic year. Typical format: STAT 545A 1.5 credits in September through mid October, followed by STAT 545B 1.5 credits from mid October through early December."
  },
  {
    "objectID": "webpages/faq.html#when-is-the-course-offered",
    "href": "webpages/faq.html#when-is-the-course-offered",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "September - December of each academic year. Typical format: STAT 545A 1.5 credits in September through mid October, followed by STAT 545B 1.5 credits from mid October through early December."
  },
  {
    "objectID": "webpages/faq.html#what-happened-to-stat-547m",
    "href": "webpages/faq.html#what-happened-to-stat-547m",
    "title": "Frequently Asked Questions",
    "section": "What happened to STAT 547M?",
    "text": "What happened to STAT 547M?\nSTAT 547M became STAT 545B in 2020, so that the course codes align. Otherwise, these are the same courses."
  },
  {
    "objectID": "webpages/faq.html#what-happened-to-the-guidebook",
    "href": "webpages/faq.html#what-happened-to-the-guidebook",
    "title": "Frequently Asked Questions",
    "section": "What happened to the guidebook?",
    "text": "What happened to the guidebook?\nWe used a guidebook in 2019/2020. It‚Äôs still available at https://stat545guidebook.netlify.app, but had become deprecated in place of worksheets and some tutorials."
  },
  {
    "objectID": "webpages/faq.html#why-are-there-two-courses-instead-of-a-single-stat-545-course",
    "href": "webpages/faq.html#why-are-there-two-courses-instead-of-a-single-stat-545-course",
    "title": "Frequently Asked Questions",
    "section": "Why are there two courses, instead of a single ‚ÄúSTAT 545‚Äù course?",
    "text": "Why are there two courses, instead of a single ‚ÄúSTAT 545‚Äù course?\nFor several years, Jenny Bryan taught STAT 545A as a 1.5 credit course. She ‚Äì and many students ‚Äì felt there was a lot of great, relevant content that could go into an additional 1.5 credits.\nA full semester of data exploration, visualization, and all-around data wrangling was piloted in 2014/2015. It was structured as two half courses primarily so that several year‚Äôs worth of STAT 545A alums could register for the second part (then STAT 547M) and get the ‚Äúmissing half‚Äù of the course. And now it‚Äôs hard to break the cycle."
  },
  {
    "objectID": "webpages/faq.html#i-have-taken-stat-545a-for-1.5-credits-in-the-past.-can-i-take-stat-545b",
    "href": "webpages/faq.html#i-have-taken-stat-545a-for-1.5-credits-in-the-past.-can-i-take-stat-545b",
    "title": "Frequently Asked Questions",
    "section": "I have taken STAT 545A for 1.5 credits in the past. Can I take STAT 545B?",
    "text": "I have taken STAT 545A for 1.5 credits in the past. Can I take STAT 545B?\nYES. But STAT 545 keeps changing to keep current with the R world. It is your responsibility to level up."
  },
  {
    "objectID": "webpages/faq.html#can-i-just-take-the-second-half-i.e.-stat-545b",
    "href": "webpages/faq.html#can-i-just-take-the-second-half-i.e.-stat-545b",
    "title": "Frequently Asked Questions",
    "section": "Can I just take the second half, i.e.¬†STAT 545B?",
    "text": "Can I just take the second half, i.e.¬†STAT 545B?\nNO, not unless you have taken STAT 545A previously."
  },
  {
    "objectID": "webpages/faq.html#can-i-just-take-the-second-half-i.e.-stat-545b-ill-do-a-self-study-for-stat-545a.",
    "href": "webpages/faq.html#can-i-just-take-the-second-half-i.e.-stat-545b-ill-do-a-self-study-for-stat-545a.",
    "title": "Frequently Asked Questions",
    "section": "Can I just take the second half, i.e.¬†STAT 545B? I‚Äôll do a self-study for STAT 545A.",
    "text": "Can I just take the second half, i.e.¬†STAT 545B? I‚Äôll do a self-study for STAT 545A.\nUnfortunately, the answer is still no. As much as we‚Äôd want to say yes to you, it just becomes too difficult for us to evaluate your level without having seen deliverables for STAT 545A."
  },
  {
    "objectID": "webpages/faq.html#i-am-an-undergraduate.-can-i-take-this-course",
    "href": "webpages/faq.html#i-am-an-undergraduate.-can-i-take-this-course",
    "title": "Frequently Asked Questions",
    "section": "I am an undergraduate. Can I take this course?",
    "text": "I am an undergraduate. Can I take this course?\nMaybe, if there‚Äôs room. Contact the instructor."
  },
  {
    "objectID": "webpages/faq.html#what-if-ive-never-had-a-stats-class",
    "href": "webpages/faq.html#what-if-ive-never-had-a-stats-class",
    "title": "Frequently Asked Questions",
    "section": "What if I‚Äôve never had a stats class?",
    "text": "What if I‚Äôve never had a stats class?\nThere are no official pre-requisites for STAT 545A but most students will have had at least one prior statistics course or comparable experience."
  },
  {
    "objectID": "webpages/faq.html#im-not-enrolled-can-i-sit-in-during-class",
    "href": "webpages/faq.html#im-not-enrolled-can-i-sit-in-during-class",
    "title": "Frequently Asked Questions",
    "section": "I‚Äôm not enrolled ‚Äì can I sit in during class?",
    "text": "I‚Äôm not enrolled ‚Äì can I sit in during class?\nUnfortunately not. The room is usually at capacity, and further, we‚Äôve allocated TA time for the specific number of students attending the class."
  },
  {
    "objectID": "webpages/faq.html#id-like-to-officially-audit-can-i",
    "href": "webpages/faq.html#id-like-to-officially-audit-can-i",
    "title": "Frequently Asked Questions",
    "section": "I‚Äôd like to officially audit ‚Äì can I?",
    "text": "I‚Äôd like to officially audit ‚Äì can I?\nAbsolutely! Please take a look at what is required of auditors so that you have an understanding of your expectations coming into the course; then, fill out the form (graduate version) and send it to the instructor to get signed."
  },
  {
    "objectID": "webpages/faq.html#the-course-is-full-can-i-audit-instead",
    "href": "webpages/faq.html#the-course-is-full-can-i-audit-instead",
    "title": "Frequently Asked Questions",
    "section": "The course is full ‚Äì can I audit instead?",
    "text": "The course is full ‚Äì can I audit instead?\nYou‚Äôll still have to join the waitlist ‚Äì auditing still counts as a seat in the class, so auditing is not a way around the course capacity.\nIn all cases, I encourage you to register! Or if the course is full, join the waitlist. Alternatively, you can engage in your own self-study using our online resources."
  },
  {
    "objectID": "webpages/faq.html#the-course-is-full.-is-there-a-chance-that-the-course-capacity-will-increase",
    "href": "webpages/faq.html#the-course-is-full.-is-there-a-chance-that-the-course-capacity-will-increase",
    "title": "Frequently Asked Questions",
    "section": "The course is full. Is there a chance that the course capacity will increase?",
    "text": "The course is full. Is there a chance that the course capacity will increase?\nUnfortunately, the course enrollment capacity will not increase. But, I encourage you to join the waitlist."
  },
  {
    "objectID": "webpages/faq.html#the-course-is-listed-as-restricted.-what-should-i-do",
    "href": "webpages/faq.html#the-course-is-listed-as-restricted.-what-should-i-do",
    "title": "Frequently Asked Questions",
    "section": "The course is listed as ‚Äúrestricted‚Äù. What should I do?",
    "text": "The course is listed as ‚Äúrestricted‚Äù. What should I do?\nWhen all the open seats are taken, the course is listed as ‚Äúrestricted‚Äù, as the remaining seats can only be taken by students of specific types. If you are a student of that type, then go ahead and register through SSC! Otherwise, I encourage you to join the waitlist."
  },
  {
    "objectID": "webpages/faq.html#can-i-take-this-course-if-im-not-a-statistics-student",
    "href": "webpages/faq.html#can-i-take-this-course-if-im-not-a-statistics-student",
    "title": "Frequently Asked Questions",
    "section": "Can I take this course if I‚Äôm not a Statistics student?",
    "text": "Can I take this course if I‚Äôm not a Statistics student?\nThis course is open to any graduate student at UBC. Students from other departments vastly outnumber those from Statistics. In fact, the most successful students are often grad students from other fields who need to analyze and visualize data for a thesis. They are highly motivated and excel.\nHowever, if you have never programmed or worked at the command line before, prepare for a shock. This will be a powerful, positive experience, but it‚Äôs a big adjustment. Come suffer through the worst part of the learning curve in good company!"
  },
  {
    "objectID": "webpages/faq.html#do-i-need-a-computer",
    "href": "webpages/faq.html#do-i-need-a-computer",
    "title": "Frequently Asked Questions",
    "section": "Do I need a computer?",
    "text": "Do I need a computer?\nYES. You absolutely must have access to a computer on which you can install software, download data, etc. In fact, class meetings will be a mix of lecture, discussion, and live coding. Students will get the most out of this if they can bring their own laptop to class every day. If this is not possible, we will try to help you work something out."
  },
  {
    "objectID": "webpages/faq.html#are-they-any-prerequisites",
    "href": "webpages/faq.html#are-they-any-prerequisites",
    "title": "Frequently Asked Questions",
    "section": "Are they any prerequisites?",
    "text": "Are they any prerequisites?\nThere are no official pre-requisites for STAT 545A, but most students will have had at least one prior statistics course or comparable experience.\nSTAT 545B requires STAT 545A."
  },
  {
    "objectID": "webpages/mda/mda_deliverable1.html#deliverable-1-will-be-due-on-friday-october-3rd-2025-at-1159pm-pt.",
    "href": "webpages/mda/mda_deliverable1.html#deliverable-1-will-be-due-on-friday-october-3rd-2025-at-1159pm-pt.",
    "title": "Mini Data Analysis: Deliverable 1",
    "section": "Deliverable 1 will be due on Friday October 3rd, 2025 at 11:59pm PT.",
    "text": "Deliverable 1 will be due on Friday October 3rd, 2025 at 11:59pm PT.",
    "crumbs": [
      "Mini Data Analysis: Deliverable 1"
    ]
  },
  {
    "objectID": "webpages/mda/mda_deliverable2.html#deliverable-2-will-be-due-on-wednesday-october-22nd-2025-at-1159pm-pt",
    "href": "webpages/mda/mda_deliverable2.html#deliverable-2-will-be-due-on-wednesday-october-22nd-2025-at-1159pm-pt",
    "title": "Mini Data Analysis: Deliverable 2",
    "section": "Deliverable 2 will be due on Wednesday October 22nd, 2025 at 11:59pm PT",
    "text": "Deliverable 2 will be due on Wednesday October 22nd, 2025 at 11:59pm PT",
    "crumbs": [
      "Mini Data Analysis: Deliverable 2"
    ]
  },
  {
    "objectID": "webpages/syllabus/syllabusA.html",
    "href": "webpages/syllabus/syllabusA.html",
    "title": "Syllabus: STAT 545 A (Part I)",
    "section": "",
    "text": "Acknowledgement\nUBC‚Äôs Point Grey Campus is located on the traditional, ancestral, and unceded territory of the xwm…ôŒ∏kw…ôy…ôm (Musqueam) people. The land it is situated on has always been a place of learning for the Musqueam people, who for millennia have passed on their culture, history, and traditions from one generation to the next on this site.\n\n\nCourse Information\n\n\n\n\n\n\n\n\n\n\nCourse Title\nCourse Code\nCredit Value\nClass Times\nClass Location\n\n\nExploratory Data Analysis Part I\nSTAT 545 A\n1.5\nMonday/Wednesday: 9:00am - 10:20am\nCEME 1202\n\n\n\n\n\nPrerequisites\nWhile there are no formal pre-requisites for STAT 545 A, students should be familiar with basic statistical analyses and have taken at least one introductory statistics course.\nSTAT545 A is a pre-requisite for STAT545 B. No exceptions.\n\n\nContact and Office Hours\n\n\n\n\n\n\n\n\n\nInstructor\nContact Details\nOffice Location\nOffice Hours\n\n\n\n\nGrace Tompkins\ngrace&lt;at&gt;stat.ubc.ca\nESB 3134\nTBD\n\n\n\n\n\n\nTeaching Assistants\n\n\n\n\nTBD\n\n\nTBD\n\n\nTBD\n\n\n\n\n\nCourse Structure\nThis course will feature short lectures and in-class demonstrations so students get hands-on experience with the help of their instructor and TAs. Dedicated time will be given in lecture for students to work through assigned worksheets.\nPlease bring a charged laptop to every class. If you do not have a personal laptop, one can be borrowed through the UBC library.\n\n\nSchedule of Topics\nSTAT 545 A (Part I):\n\n\n\nWeek\nDate\nTopic\nIn-class work\n\n\n\n\n1\nTuesday Sept 2\nInstallation\n\n\n\n\nThursday Sept 4\nIntro to STAT545 and R\nWorksheet A1\n\n\n\n\n\n\n\n\n2\nTuesday Sept 9\nAuthoring and Reproducibility\nEnsure you have completed the installation instructions from Sept 2*!\n\n\n\nThursday Sept 11\nVersion Control\n\n\n\n\n\n\n\n\n\n3\nTuesday Sept 16\nData Manipulation with dplyr\nWorksheet A2\n\n\n\nThursday Sept 18\n\nWorksheet A2\n\n\n\n\n\n\n\n\n4\nTuesday Sept 23\nData Visualization\nWorksheet A3\n\n\n\nThursday Sept 25\n\nWorksheet A3\n\n\n\n\n\n\n\n\n5\nTuesday Sept 30\n*** NO CLASS ***\n\n\n\n\nThursday Oct 2\nTidy Data\nWorksheet A4\n\n\n\n\n\n\n\n\n6\nTuesday Oct 7\nModel Fitting\nWorksheet A4\n\n\n\nThursday Oct 9\nFactors and Dates\nWorksheet A5\n\n\n\n\n\n\n\n\n7\nTuesday Oct 14\nReading and Writing Data, and Tibble Joins\nWorksheet A5\n\n\n\nThursday Oct 16\nReview and Work Session\nWorksheet A5, Mini Data Analysis (MDA)\n\n\n\nThis schedule is subject to change. Any changes will be announced via the #annoucements channel on Slack, and major changes will be sent out via email.\n\n\nAssessments\nThis course will have autograded, formative worksheets meant to guide you through a number of exercises.\n\n\n\n\n\n\n\n\nAssessment\nPercent Grade\nNote\n\n\n\n\nWorksheets\n20%\nGuided worksheets\n\n\nMini Data Analysis\n45%\nStudents write their own mini analysis\n\n\nCollaborative Project\n35%\nTeam project intended for practicing version control and collaboration\n\n\n\n\nWorksheets\nWorksheets are interactive assignments that allow students to get real-time feedback on their code. Your grade will be based on the number of correct answers provided. There are unlimited attempts for the worksheets, and time will be given in class to work through them.\nWorksheets are produced with Jupyter Notebooks, and will be submitted on Canvas.\n\n\n\nWorksheet\nRelease Date\nDue Date (11:59PM PT)\n\n\n\n\nWorksheet A1\nSeptember 2nd, 2025\nNA\n\n\nWorksheet A2\nSeptember 15th, 2025\nSeptember 22nd, 2025\n\n\nWorksheet A3\nSeptember 22nd, 2025\nSeptember 29th, 2025\n\n\nWorksheet A4\nSeptember 29th, 2025\nOctober 13th, 2025\n\n\nWorksheet A5\nOctober 13th, 2025\nOctober 20th, 2025\n\n\n\n\n\nCollaborative Project\nTeams will be randomly assigned. The idea behind the collaborative project is to practice using Version Control and collaborative tools on Github, troubleshoot broken R code, and rewrite code to address issues. There will be two deliverables for the project:\n\n\n\n\n\n\n\n\nCollaborative Project Milestone\nRelease Date\nDue Date (11:59pm PT)\n\n\n\n\nDeliverable 1 (100 points)\nSeptember 4th, 2025\nSeptember 19th, 2025\n\n\nDeliverable 2 (78 points)\nSeptember 4th, 2025\nSeptember 26th, 2025\n\n\n\nInstructions will be posted on the Course Website under ‚ÄúCollaborative Project‚Äù\n\n\nMini Data Analysis\nConduct your own mini data analysis! The goal of this assignment is to become more familiar with R and generate a reproducible report using RMarkdown and various packages, such as tibble. There are two equally weighted deliverables:\n\n\n\n\n\n\n\n\nMini Data Analysis Milestone\nRelease Date\nDue Date (11:59PM PT)\n\n\n\n\nDeliverable 1 (36 points)\nSeptember 26th, 2025\nOctober 3rd, 2025\n\n\nDeliverable 2 (36 points)\nSeptember 26th, 2025\nOctober 22nd, 2025\n\n\n\n\n\n\nAuditing Students\nAuditing students are expected to complete all assessments (see above). All assessments are graded on a pass/fail basis for those officially auditing.\nYou must be registered as an auditing student to attend lectures due to capacity limitations.\n\n\nCourse Communications\nWe will be using Slack as our primary platform of all course-related communications! Students will be emailed an invite to their class‚Äô Slack workspace.\nOfficial course communications will occur on the #announcements channel. You will receive an invite on the first day of classes. Please notify the instructor by email if you have not received your personal invite.\nOur STAT 545 team will be actively monitoring Slack during regular working hours (9am to 5pm PT, Monday to Friday). You are free to ask questions outside of this window but please keep in mind that there are no expectations for the team to answer questions outside of working hours or on weekends or holidays.\nTo make the most out of Slack, please\n\nUse the #general channel for clarifications, asking about course organization, or clarifying instructions. Things you post on the #general channel will be seen by everyone, so please do not provide information that gives away answers to assignments.\nMake a group chat with our TAs when you need more personalized help, or have an issue with grading. They may direct you to the #general channel when appropriate, or direct you to the instructor.\nDirect message the instructor if there is a concern that is more personal (i.e., you need to self declare an absense) or if you have already talked to the TAs about an issue and are unsatisfied. You can also direct message the instructor if you are having issues with a group member in any group-related assignments.\nPost in the #random channel if you find things related to the course that you‚Äôd like to share\n\n\n\nPrivacy\nSlack and GitHub are hosted on servers stored outside of Canada. Please keep this in mind.\n\n\nPolicies\n\nRegrade Requests\nRegrade requests must be sent to the TAs through Slack within one week of the assessment being returned. If required, regrade requests can be escalated to the instructor only if the request has already been brought up to the TA team and the student is unsatisfied. The instructor reserves the right to regrade the entire assessment, resulting in a higher or lower mark than originally provided.\n\n\nLate Policies\nWorksheets (and larger assignments, if applicable) are due at 11:59pm PT on the date indicated in the course schedule. For a late submission, a 24 hour extension will be provided for the first offense. Late submissions will be given a grade of 0 for subsequent occurrences.\nThere is a zero-tolerance policy for late projects, including the mini data analysis and the collaborative project. If you are having issues with a team member regarding any group work, reach out to the instructor directly through Slack or email.\n\n\nAcademic Concession\nUBC no longer requires a doctor‚Äôs note (or supporting documentation) for academic concession. A self-declaration will suffice ‚Äì here is a template you can use. The form is also posted on our Canvas page. Please submit this to the instructor via email.\nExamples of ‚Äúconflicting responsibility‚Äù are conference travel and time-sensitive field work.\nIf you arrange to have an assignment submitted late, you may not be able to receive feedback from your peers.\n\n\nPlagiarism\nPlagiarism, which is intellectual theft, occurs where an individual submits or presents the oral or written work of another person as his or her own and can include:\n\nmultiple students submitting the same response\ncopying from sources without citing them\ncopying verbatim (word-for-word) from source and citing, but failing to make it explicit that this is a quotation (quotations should be used only rarely, if at all)\n\nStudents are responsible for ensuring that any work submitted does not constitute plagiarism. Students who are in any doubt as to what constitutes plagiarism should consult their instructor before handing in any assignments.\nFor more information see the UBC Academic Misconduct policies.\n\n\nCode Plagiarism\nStudents must correctly cite any code that has been authored by someone else or by the student themselves for other assignments. Cases of code plagiarism may include, but are not limited to:\n\nthe reproduction (copying and pasting) of code with none or minimal reformatting (e.g., changing the name of the variables)\nthe translation of an algorithm or a script from a language to another\nthe generation of code by automatic code-generations software\n\nAn ‚Äúadequate acknowledgement‚Äù requires a detailed identification of the (parts of the) code reused and a full citation of the original source code that has been reused.\n\n\nUBC‚Äôs Policies and Resources to Support Student Success\nUBC provides resources to support student learning and to maintain healthy lifestyles but recognizes that sometimes crises arise and so there are additional resources to access including those for survivors of sexual violence. UBC values respect for the person and ideas of all members of the academic community. Harassment and discrimination are not tolerated nor is suppression of academic freedom. UBC provides appropriate accommodation for students with disabilities and for religious, spiritual and cultural observances. UBC values academic honesty and students are expected to acknowledge the ideas generated by others and to uphold the highest academic standards in all of their actions. Details of the policies and how to access support are available here.\n\n\nYour personal health\nIf you‚Äôre sick, it‚Äôs important that you stay home ‚Äì no matter what you think you may be sick with (e.g., cold, flu, other). Your precautions will help reduce risk and keep everyone safer. The structure of this class is intended to provide flexibility so that you can prioritize your health and still be able to succeed.\nIf you do miss class because of illness:\n\nConsult the class resources on the course website\nCome to office hours on Zoom.\nUse Slack to carry out discussions.\n\nIf you miss an assessment due to illness, see the above section on Academic Concessions, and review the UBC policy here: http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,329,0,0\n\n\nInstructor health\nIf I am ill, then I will not come to class. If that happens, here‚Äôs what you can expect:\n\nIf I am well enough to teach, I will conduct virtual lectures through Zoom until I am well. If this happens, you will be tagged in an announcement via Slack with information. You can anticipate that this would very likely be a last minute announcement. Our classroom will still be available for you to sit and attend an online session, although it is recommended that you bring headphones.\nIf I am not well enough to teach, it is possible that one or more teaching assistants will take my place. But if not, we will either try to make up for lost time, make new resources to aid in your learning, or make accommodations regarding the assessments.\n\n\n\n\nCopyright\nCourse materials are licensed under Creative Commons 4.0.",
    "crumbs": [
      "Syllabus: STAT 545 A (Part I)"
    ]
  },
  {
    "objectID": "webpages/syllabus/syllabusB.html",
    "href": "webpages/syllabus/syllabusB.html",
    "title": "Syllabus: STAT 545 B (Part II)",
    "section": "",
    "text": "Acknowledgement\nUBC‚Äôs Point Grey Campus is located on the traditional, ancestral, and unceded territory of the xwm…ôŒ∏kw…ôy…ôm (Musqueam) people. The land it is situated on has always been a place of learning for the Musqueam people, who for millennia have passed on their culture, history, and traditions from one generation to the next on this site.\n\n\nCourse Information\n\n\n\n\n\n\n\n\n\n\nCourse Title\nCourse Code\nCredit Value\nClass Times\nClass Location\n\n\nExploratory Data Analysis Part II\nSTAT 545 B\n1.5\nMonday/Wednesday: 9:30am - 10:50am\nCEME 1202\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSTAT545 B starts half an hour later than STAT545 A!\n\n\n\n\nPrerequisites\nSTAT545 A is a pre-requisite for STAT545 B. No exceptions.\n\n\nContact and Office Hours\n\n\n\n\n\n\n\n\n\nInstructor\nContact Details\nOffice Location\nOffice Hours\n\n\n\n\nGrace Tompkins\ngrace&lt;at&gt;stat.ubc.ca\nESB 3134\nTBD\n\n\n\n\n\n\nTeaching Assistants\n\n\n\n\nTBD\n\n\nTBD\n\n\nTBD\n\n\n\n\n\nCourse Structure\nThis course will feature short lectures and in-class demonstrations so students get hands-on experience with the help of their instructor and TAs. Dedicated time will be given in lecture for students to work through assigned worksheets.\nPlease bring a charged laptop to every class. If you do not have a personal laptop, one can be borrowed through the UBC library.\n\n\nSchedule of Topics\nSTAT 545 A (Part I):\n\n\n\nWeek\nDate\nTopic\nIn-class work\n\n\n\n\n8\nTuesday Oct 21\nFunctions\nWorksheet B1\n\n\n\nThursday Oct 23\nAdvanced Functions\nWorksheet B1, Assignment 1\n\n\n\n\n\n\n\n\n9\nTuesday Oct 28\nR Packages\n\n\n\n\nThursday Oct 30\nR Packages\nAssignment 2\n\n\n\n\n\n\n\n\n10\nTuesday Nov 4\nDashboards\n\n\n\n\nThursday Nov 6\nDashboards\nAssignment 3\n\n\n\n\n\n\n\n\n11\nTuesday Nov 11\nNO LECTURE: REMEMBRANCE DAY\n\n\n\n\nThursday Nov 13\nAutomation\n\n\n\n\n\n\n\n\n\n12\nTuesday Nov 18\nCharacter Data\nWorksheet B2\n\n\n\nThursday Nov 20\n\nWorksheet B2\n\n\n\n\n\n\n\n\n13\nTuesday Nov 25\nList Columns\nWorksheet B3\n\n\n\nThursday Nov 27\n\nWorksheet B3\n\n\n\n\n\n\n\n\n14\nTuesday Dec 2\nWebsites and Slides\n\n\n\n\nThursday Dec 4\nReview and Work Session\nAssignment 4\n\n\n\nThis schedule is subject to change. Any changes will be announced via the #annoucements channel on Slack, and major changes will be sent out via email.\n\n\nAssessments\nThis course will have autograded, formative worksheets meant to guide you through a number of exercises.\n\n\n\n\n\n\n\n\nAssessment\nPercent Grade\nNote\n\n\n\n\nWorksheets (3)\n20%\nGuided worksheets\n\n\nAssignments (4)\n80%\nMore independent analyses and tasks\n\n\n\n\nWorksheets\nWorksheets are interactive assignments that allow students to get real-time feedback on their code. Your grade will be based on the number of correct answers provided. There are unlimited attempts for the worksheets, and time will be given in class to work through them.\nWorksheets are produced with Jupyter Notebooks, and will be submitted on Canvas.\n\n\n\nWorksheet\nRelease Date\nDue Date (11:59PM PT)\n\n\n\n\nWorksheet B1\nMonday Oct 20, 2025\nMonday Oct 27, 2025\n\n\nWorksheet B2\nFriday Nov 14, 2025\nThursday Nov 27, 2025\n\n\nWorksheet B3\nThursday Nov 27, 2025\nThursday Dec 4, 2025\n\n\n\n\n\nAssignments\nThere are four formal assignments for this course:\n\n\n\nAssignment\nRelease Date\nDue Date (11:59pm PT)\n\n\n\n\nAssignment 1\nTuesday Oct 21, 2025\nFriday Oct 31, 2025\n\n\nAssignment 2\nFriday Oct 31, 2025\nFriday Nov 7, 2025\n\n\nAssignment 3\nFriday Nov 7, 2025\nFriday Nov 21, 2025\n\n\nAssignment 4\nFriday Nov 21, 2025\nThursday Dec 4, 2025\n\n\n\nInstructions will be posted on the Course Website under ‚ÄúAssignments‚Äù\n\n\n\nAuditing Students\nAuditing students are expected to complete all assessments (see above). All assessments are graded on a pass/fail basis for those officially auditing.\nYou must be registered as an auditing student to attend lectures due to capacity limitations.\n\n\nCourse Communications\nWe will be using Slack as our primary platform of all course-related communications! Students will be emailed an invite to their class‚Äô Slack workspace.\nOfficial course communications will occur on the #announcements channel. You will receive an invite on the first day of classes. Please notify the instructor by email if you have not received your personal invite.\nOur STAT 545 team will be actively monitoring Slack during regular working hours (9am to 5pm PT, Monday to Friday). You are free to ask questions outside of this window but please keep in mind that there are no expectations for the team to answer questions outside of working hours or on weekends or holidays.\nTo make the most out of Slack, please\n\nUse the #general channel for clarifications, asking about course organization, or clarifying instructions. Things you post on the #general channel will be seen by everyone, so please do not provide information that gives away answers to assignments.\nMake a group chat with our TAs when you need more personalized help, or have an issue with grading. They may direct you to the #general channel when appropriate, or direct you to the instructor.\nDirect message the instructor if there is a concern that is more personal (i.e., you need to self declare an absense) or if you have already talked to the TAs about an issue and are unsatisfied. You can also direct message the instructor if you are having issues with a group member in any group-related assignments.\nPost in the #random channel if you find things related to the course that you‚Äôd like to share\n\n\n\nPrivacy\nSlack and GitHub are hosted on servers stored outside of Canada. Please keep this in mind.\n\n\nPolicies\n\nRegrade Requests\nRegrade requests must be sent to the TAs through Slack within one week of the assessment being returned. If required, regrade requests can be escalated to the instructor only if the request has already been brought up to the TA team and the student is unsatisfied. The instructor reserves the right to regrade the entire assessment, resulting in a higher or lower mark than originally provided.\n\n\nLate Policies\nWorksheets (and larger assignments, if applicable) are due at 11:59pm PT on the date indicated in the course schedule. For a late submission, a 24 hour extension will be provided for the first offense. Late submissions will be given a grade of 0 for subsequent occurrences.\nThere is a zero-tolerance policy for late projects, including the mini data analysis and the collaborative project. If you are having issues with a team member regarding any group work, reach out to the instructor directly through Slack or email.\n\n\nAcademic Concession\nUBC no longer requires a doctor‚Äôs note (or supporting documentation) for academic concession. A self-declaration will suffice ‚Äì here is a template you can use. The form is also posted on our Canvas page. Please submit this to the instructor via email.\nExamples of ‚Äúconflicting responsibility‚Äù are conference travel and time-sensitive field work.\nIf you arrange to have an assignment submitted late, you may not be able to receive feedback from your peers.\n\n\nPlagiarism\nPlagiarism, which is intellectual theft, occurs where an individual submits or presents the oral or written work of another person as his or her own and can include:\n\nmultiple students submitting the same response\ncopying from sources without citing them\ncopying verbatim (word-for-word) from source and citing, but failing to make it explicit that this is a quotation (quotations should be used only rarely, if at all)\n\nStudents are responsible for ensuring that any work submitted does not constitute plagiarism. Students who are in any doubt as to what constitutes plagiarism should consult their instructor before handing in any assignments.\nFor more information see the UBC Academic Misconduct policies.\n\n\nCode Plagiarism\nStudents must correctly cite any code that has been authored by someone else or by the student themselves for other assignments. Cases of code plagiarism may include, but are not limited to:\n\nthe reproduction (copying and pasting) of code with none or minimal reformatting (e.g., changing the name of the variables)\nthe translation of an algorithm or a script from a language to another\nthe generation of code by automatic code-generations software\n\nAn ‚Äúadequate acknowledgement‚Äù requires a detailed identification of the (parts of the) code reused and a full citation of the original source code that has been reused.\n\n\nUBC‚Äôs Policies and Resources to Support Student Success\nUBC provides resources to support student learning and to maintain healthy lifestyles but recognizes that sometimes crises arise and so there are additional resources to access including those for survivors of sexual violence. UBC values respect for the person and ideas of all members of the academic community. Harassment and discrimination are not tolerated nor is suppression of academic freedom. UBC provides appropriate accommodation for students with disabilities and for religious, spiritual and cultural observances. UBC values academic honesty and students are expected to acknowledge the ideas generated by others and to uphold the highest academic standards in all of their actions. Details of the policies and how to access support are available here.\n\n\nYour personal health\nIf you‚Äôre sick, it‚Äôs important that you stay home ‚Äì no matter what you think you may be sick with (e.g., cold, flu, other). Your precautions will help reduce risk and keep everyone safer. The structure of this class is intended to provide flexibility so that you can prioritize your health and still be able to succeed.\nIf you do miss class because of illness:\n\nConsult the class resources on the course website\nCome to office hours on Zoom.\nUse Slack to carry out discussions.\n\nIf you miss an assessment due to illness, see the above section on Academic Concessions, and review the UBC policy here: http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,329,0,0\n\n\nInstructor health\nIf I am ill, then I will not come to class. If that happens, here‚Äôs what you can expect:\n\nIf I am well enough to teach, I will conduct virtual lectures through Zoom until I am well. If this happens, you will be tagged in an announcement via Slack with information. You can anticipate that this would very likely be a last minute announcement. Our classroom will still be available for you to sit and attend an online session, although it is recommended that you bring headphones.\nIf I am not well enough to teach, it is possible that one or more teaching assistants will take my place. But if not, we will either try to make up for lost time, make new resources to aid in your learning, or make accommodations regarding the assessments.\n\n\n\n\nCopyright\nCourse materials are licensed under Creative Commons 4.0.",
    "crumbs": [
      "Syllabus: STAT 545 B (Part II)"
    ]
  },
  {
    "objectID": "webpages/worksheets.html",
    "href": "webpages/worksheets.html",
    "title": "Worksheets",
    "section": "",
    "text": "Links to worksheets go here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT545 A/B: Exploratory Data Analysis (Fall 2025)",
    "section": "",
    "text": "Welcome to STAT 545 at the University of British Columbia! Whether you‚Äôre a student enrolled in STAT 545 or simply someone looking to learn how to write reproducible and collaborative data analyses, it is our hope that this website will serve as a great resource for learning these new skills!\nIn short, this course will enable you to confidently write clean and modern data analyses in R using version control software (GitHub), and creating reports using R Markdown. The primary focus will be on using these technologies to conduct analyses with daily workflow, rather than the statistical theory and methods for analysis.\n\n\n\n\n\n\n\n\nThis course is divided into two parts. In Part I (STAT545 A), we will introduce\n\nR and RStudio,\nReport generation with R Markdown,\nProject organization, workflow, and coding style,\nData management with dataframes and tibbles using tidyverse,\nData visualization with ggplot2, and\nVersion control using Git and Github.\n\nIn Part II (STAT545 B), we will dive deeper into\n\nWriting functions in R,\nAdvanced computations on data,\nFunctional programming with purrr,\nR packages,\nInteractive pages, apps, and graphics with RShiny, and\nWebsite development using Quarto.\n\nIf you are a student enrolling in this course for credit at UBC, you MUST take STAT 545 A to enroll in STAT545 B. There are no exceptions to this rule."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "STAT545 A/B: Exploratory Data Analysis (Fall 2025)",
    "section": "",
    "text": "Welcome to STAT 545 at the University of British Columbia! Whether you‚Äôre a student enrolled in STAT 545 or simply someone looking to learn how to write reproducible and collaborative data analyses, it is our hope that this website will serve as a great resource for learning these new skills!\nIn short, this course will enable you to confidently write clean and modern data analyses in R using version control software (GitHub), and creating reports using R Markdown. The primary focus will be on using these technologies to conduct analyses with daily workflow, rather than the statistical theory and methods for analysis.\n\n\n\n\n\n\n\n\nThis course is divided into two parts. In Part I (STAT545 A), we will introduce\n\nR and RStudio,\nReport generation with R Markdown,\nProject organization, workflow, and coding style,\nData management with dataframes and tibbles using tidyverse,\nData visualization with ggplot2, and\nVersion control using Git and Github.\n\nIn Part II (STAT545 B), we will dive deeper into\n\nWriting functions in R,\nAdvanced computations on data,\nFunctional programming with purrr,\nR packages,\nInteractive pages, apps, and graphics with RShiny, and\nWebsite development using Quarto.\n\nIf you are a student enrolling in this course for credit at UBC, you MUST take STAT 545 A to enroll in STAT545 B. There are no exceptions to this rule."
  },
  {
    "objectID": "index.html#your-teaching-team-2025",
    "href": "index.html#your-teaching-team-2025",
    "title": "STAT545 A/B: Exploratory Data Analysis (Fall 2025)",
    "section": "Your Teaching Team (2025)",
    "text": "Your Teaching Team (2025)\nMy name is Grace Tompkins (she/her) and I‚Äôll be your course instructor. I‚Äôm a Biostatistician and recent PhD graduate passionate about teaching! I‚Äôm excited to be guiding you throughout this course.\n\n\n\nInstructor: Grace Tompkins\n\n\nI am joined by a wonderful group of TAs, including:\n‚Ä¶.\nPlease reach out if you have any concerns or questions at grace&lt;at&gt;stat.ubc.ca, or through our Slack channel."
  },
  {
    "objectID": "webpages/casestudies/fev_datavis.html",
    "href": "webpages/casestudies/fev_datavis.html",
    "title": "Lecture 4 Case Study: Data Visualization with FEV Dataset",
    "section": "",
    "text": "Copy and paste the following code into a new RMarkdown Document.\n---\ntitle: 'FEV Case Study: Graphing'\nauthor: \"Lucy\"\ndate: \"2023-08-28\"\noutput: html_document\n---\n\n\n\n## Review \n\nWe'll continue exploring the FEV data set from last week. Let's start by loading the data and required packages.\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"dplyr\") #uncomment and run once, if needed\n#install.packages(\"readr\") #uncomment and run once, if needed\n#install.packages(\"ggplot2\") #uncomment and run once, if needed\n\nlibrary(dplyr)\nlibrary(readr)\nlibrary(ggplot2)\n\nfev &lt;- read_tsv(\"https://raw.githubusercontent.com/GTPB/PSLS20/master/data/fev.txt\")\nfev_tbl &lt;- as_tibble(fev) %&gt;% mutate(across(gender:smoking, ~ as.factor(.x))) #assign gender and smoking as factors (more on this later, too!)\n```\n:::\n\nLast week, we found that the mean FEV in the smoking group was substantially higher than the average FEV in the non-smoking group. That is, the smokers appear to have *better* lung function than the non-smokers. \n\nWe also had a theory as to why: the association between FEV and smoking status may be confounded, eg. by age/size.\n\nWe'll investigate further this week with our newly acquired plotting skills! \n\nHere are some helpful resources for making plots, now that we are moving towards less \"guided\" exercises: \n\n- [ggplot2 package webpage](https://ggplot2.tidyverse.org/index.html)\n- [ggplot2 Book](https://ggplot2-book.org/)\n- [R Graphics Cookbook](https://r-graphics.org/)\n\n## Smoking and FEV (unadjusted)\n\n### Exercise 1 \n\nNow that we have plotting tools, let's make a plot that compares the FEV of smokers to the FEV of non-smokers. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nThis broadly tells the same story as the summaries we calculated last week, but conveys more information and is more visually engaging. \n\n## Searching for potential confounders \n\nLet's do some digging to see if we can root out some potential confounders.\n\n### Exercise 2\n\nLast week, we found that the youngest patient who smokes is 9, suggesting that there is a difference in the age distribution among smokers and non-smokers. Make a plot that compares these two distributions.\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nAgain, we see that the smokers are overall older than the non-smokers. \n\n### Exercise 3\n\nWe think that age should be related to height, which in turn should be related to FEV. Let's investigate that more systematically now with plotting. \n\nHow would you like to investigate that with plotting? Here's one suggestion, though you don't have to take it: make a plot with two panels, one that has a scatterplot of height versus age for the female patients, and one that has a scatterplot of height versus age for the male patients. \n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nWe see that the within-sex trend is similar: height is linear-ish at younger ages, and flat-ish at older ages. Boys wind up taller at older ages. \n\nWe will then make a scatterplot of FEV versus height.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(fev_tbl, aes(x = height, y = fev)) + \n  geom_jitter(width=0.2, alpha = 0.75) + \n  ggtitle(\"FEV versus height\") +\n  ylab(\"FEV (l/s)\") +\n  xlab(\"Height (inches)\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](fev_datavis_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nWe see that taller participants generally have higher FEV. \n\n## Smoking and lung function: a more nuanced look\n\nNow that we know that the smokers are older and bigger and have higher FEV, let's look at the relationship between FEV and smoking status *adjusted* for height. \n\n### Exercise 4\n\nMake a scatterplot of FEV versus height, with points marked by smoking status.\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nBased on this plot, it seems like the FEV of smokers and non-smokers *of the same height* is pretty similar.",
    "crumbs": [
      "Lecture 4 Case Study: Data Visualization with FEV Dataset"
    ]
  }
]