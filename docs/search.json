[
  {
    "objectID": "webpages/lectures_ii/lec8a_functions.html",
    "href": "webpages/lectures_ii/lec8a_functions.html",
    "title": "Lecture 8a: Functions",
    "section": "",
    "text": "From this lecture, students are expected to be able to:\nWe will require the following packages for this lecture:\nlibrary(roxygen2)\nlibrary(testthat)",
    "crumbs": [
      "Lecture 8a: Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec8a_functions.html#self-made-r-functions",
    "href": "webpages/lectures_ii/lec8a_functions.html#self-made-r-functions",
    "title": "Lecture 8a: Functions",
    "section": "Self-made R Functions",
    "text": "Self-made R Functions\nAt this point in the course, we‚Äôve used lots of functions, like mean(), mutate(), and pivot_longer(). But it can be really useful to write your own function. For example, the ability to writing your own functions can supercharge your group_by() %&gt;% summarize() workflow: you can write your own function to use inside summarize(), instead of relying solely on functions built into R or available in packages!\nSo why write functions? In short, it avoids repeatedly duplicating code. This is helpful because:\n\nIt shortens your code ‚Äì crucially, without losing interpretability ‚Äì making it easier and faster to read through and process its overall intent.\nIf your needs change, then you only need to change your code in one place (the function definition) rather than a bunch of places.\nBullet points 1 and 2 mean that using functions typically leads to fewer bugs and fewer headaches.\n\nA good rule of thumb is whenever you find yourself repeating code more than a few times, consider writing a function.\nHere‚Äôs a simple example of a function I wrote to simulate rolling a user-inputted number of D10s (a 10-sided die used for tabletop gaming) and returning the sum of the dice.\n\nroll_d10 &lt;- function(num_dice) { \n    sum(sample(1:10, num_dice, replace=TRUE))\n}\n\nroll_d10(2)\n\n[1] 17\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis is not reproducible code, as the output will change each time I run this function as I am randomly sampling. If I wanted to make this reproducible, then I would set the seed to (say) 123 before running my function with set.seed(123).\n\n\n\nDocumentation\nYou should have also noticed by now that other people‚Äôs functions in packages are documented - there‚Äôs information about:\n\nwhat the function does, at a high level\nthe objects it expects you to input\nthe object that the function outputs\n\nAt an absolute minimum, functions should have some comments indicating what the function does and what the inputs are. However, to make the function more user-friendly, commenting each line can be extremely helpful to let the user know exactly what‚Äôs happening under the hood. For example, we could comment the above function to make it more clear:\n\nroll_d10 &lt;- function(num_dice) { \n  # this function simulates rolling `num_dice` number of 10-sided dice and outputs the sum\n  # note: no seed is used so the function will return a dice combination each time it is run\n  #\n  # inputs:\n  # - num_dice: number of dice you wish to roll\n  \n    sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers with replacement between 1 and 10, return sum\n}\n\n# test function\nroll_d10(2)\n\n[1] 9\n\n\nWe can do even better than this wutg roxygen2 tags to document the function! These tags are placed immediately above the function definition. Although roxygen2 tags are designed for use when creating R packages, they provide a standardized way to document a function ‚Äì and make it easy for you to migrate your function to an R package if need be! Roxygen comment lines always start with #' , the usual # for a comment, followed immediately by a single quote ':\n#' Description of function goes here\n#' \n#' @param x description of the parameter input x goes here\n#' @param y description of the parameter input x goes here\n#' @returns description of the what function returns goes here\n\nname_of_function &lt;- function(x, y) {\n  your function goes here!\n}\nFor the dice example, we could write:\n\n#' @details\n#' Simulates rolling `num_dice` number of dice for a 10 sided dice and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @return the sum of the dice rolled\n  \nroll_d10 &lt;- function(num_dice) { \n    sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers from one to 10 with replacement, return sum\n}\n\nroll_d10(2)\n\n[1] 19\n\n\n\n\nTesting\nWhen you‚Äôre using other people‚Äôs functions ‚Äì like those in packages ‚Äì they often work. However, as you have probably discovered by this point, it is very easy to inadvertently write code ‚Äì and therefore functions ‚Äì that do not work. Because of this, it‚Äôs important to test the functions we write to make sure they work. It is useful to ensure that\nIt‚Äôs useful to think of a few cases to test, along with edge cases (conditions that fall outside the typical or expected parameters) and see if the function performs\nLet‚Äôs try rolling 4 dice:\n\nroll_d10(4)\n\n[1] 23\n\n\nNow, let‚Äôs try rolling no dice. The expected output should be 0.\n\nroll_d10(0)\n\n[1] 0\n\n\nInstead of manually coding test cases over and over, we can use functions from the testthat package in R. For example, when rolling no dice, we would expect the output to be 0. We can use the expect_equal() function to confirm this. The function won‚Äôt output anything if the output is as expected:\n\nexpect_equal(roll_d10(0), 0)\n\nor will throw an error if not:\nexpect_equal(roll_d10(0), 2)\nError: roll_d10(0) not equal to 2.\n1/1 mismatches\n[1] 0 - 2 == -2\nThe test_that() function makes these tests even more readable:\n\ntest_that(\"Rolling no dice equals 0\", {\n  expect_equal(roll_d10(0), 0)\n})\n\nTest passed üéä\n\n\nMore examples for the test_that() can be found on on this Video Lecture.\n\n\nError Handling\nLet‚Äôs try inputting a nonsense input, like 2.5 dice. This input doesn‚Äôt make sense, so let‚Äôs see what happens:\n\nroll_d10(2.5)\n\n[1] 8\n\n\nInteresting! This is something we should consider controlling for when creating our function.\nWithin a function call, we can force errors to appear using the stop() function and conditional statements. For example, we may only want to allow whole numbers (positive numbers of dice) to be inputs. We can do this by seeing if the num_dice %% 1function returns 0. %% is the ‚Äúmodular division‚Äù function which returns the remainder after division. Whole numbers will not have any remainder when divided by 1. Let‚Äôs update our function:\n\n#' @details\n#' Simulates rolling `num_dice` number of dice and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @return the sum of the dice rolled\n  \nroll_d10 &lt;- function(num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers from one to 10 with replacement, return sum\n}\n\nSo rolling 2 dice shouldn‚Äôt throw an error:\n\nroll_d10(2)\n\n[1] 14\n\n\nBut rolling 2.5 dice should:\nroll_d10(2.5)\nError in roll_d10(2.5) : num_dice must be an integer\nOur function is working as expected for this edge case!\n\n\nReturns\nBy default, your function will return the last thing computed in your function. However, we can return other items, like lists and vectors and dataframes using return().\nWhile perhaps redundant as the last line of code here is what we want to output, we could explictly tell R what to output by:\n\n#' @details\n#' Simulates rolling `num_dice` number of dice with `n_sides` sides and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @return the sum of the dice rolled\n  \nroll_d10 &lt;- function(num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum_dice &lt;- sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers from one to 10 with replacement, save as sum_dice\n    \n    #output\n    return(sum_dice)\n}\n\nWe could also return a vector of the the number of dice, and the number of faces of each dice, and the sum.\n\n#' @details\n#' Simulates rolling `num_dice` number of dice with `n_sides` sides and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @param n_sides integer representing the number of sides of each dice.\n#' @return the sum of the dice rolled\n  \nroll_d10 &lt;- function(n_sides, num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum_dice &lt;- sum(sample(1:10, num_dice, replace=TRUE)) #sample two numbers from one to 10 with replacement, return sum\n    \n    out &lt;- c(num_dice, sum_dice) #create a vector of what we want to return\n    \n    return(out)\n    \n}\n\nroll_d10(num_dice = 5)\n\n[1]  5 23\n\n\nLooks like we rolled 5 dice and the sum was 23.",
    "crumbs": [
      "Lecture 8a: Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec8a_functions.html#worksheet-b1",
    "href": "webpages/lectures_ii/lec8a_functions.html#worksheet-b1",
    "title": "Lecture 8a: Functions",
    "section": "Worksheet B1",
    "text": "Worksheet B1\nNow it‚Äôs your turn to explore functions. Working through Worksheet B1 is a great place to go from here to learn the basics of how to define your own functions and how to test it.",
    "crumbs": [
      "Lecture 8a: Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec8a_functions.html#resources",
    "href": "webpages/lectures_ii/lec8a_functions.html#resources",
    "title": "Lecture 8a: Functions",
    "section": "Resources",
    "text": "Resources\nVideo lecture:\n\nR Functions for Data Analysis\n\nWritten resources:\n\nBasic function syntax in R: https://swcarpentry.github.io/r-novice-inflammation/02-func-R/\nWhen to use functions in your data analysis:\n\nstat545.com Functions, Parts 1-3\nR4DS functions chapter\n\n\n\nAttribution\nContent created by Grace Tompkins based off of previous instructional teams and Vincenzo Coia.",
    "crumbs": [
      "Lecture 8a: Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1a_installation.html",
    "href": "webpages/lectures_i/lec1a_installation.html",
    "title": "Lecture 1A: Installation",
    "section": "",
    "text": "The goal of this lecture is to learn how to install and setup key software for use in the course.\nTAs are available in class on Imagine Day from 9am-10:30am on Tuesday September 2nd to aid with installation. I highly recommend you join if you haven‚Äôt used RStudio, Jupyter, or GitHub before.\n\n\nYou may encounter some material that implicitly assumes that you are using a Mac. For example, they might point you to a Terminal app, or ask you to use Unix commands like which or ls. Here is a cheatsheet that helps you convert between Windows command line (‚ÄúDOS‚Äù) and Mac command line (‚ÄúUNIX‚Äù). One thing that‚Äôs missing is the equivalent to Unix‚Äôs which; the closest equivalent in DOS is where.\n\n\n\nR and RStudio The main programming language used in the class is R and our main IDE (a text editor with helpful features for writing and running code) is RStudio. The following instructions are adapted from Chapter 5 of Jenny Bryan‚Äôs ‚Äúhappy git‚Äù book.\n\nInstall (or update to) the latest release R on your computer (4.5.1 currently):\n\nWindows: https://cran.r-project.org/bin/windows/base/\nMac: https://cran.r-project.org/bin/macosx/\n\nInstall RStudio\n\nhttps://posit.co/download/rstudio-desktop/\n\n\nEven if you already have R/RStudio, please update them to the most recent version!\n\n\n\nYou will need another IDE for R (Jupyter Notebook) and an R kernel called ‚ÄòIR Kernel‚Äô (needed to run R code within Jupyter) to work on the autograded worksheets. This is because the autograder we use plays well with Jupyter.\nThe following instructions are adapted from Rich Pauloo.\nPC Installation:\n\nInstall Anaconda from https://www.anaconda.com/download\n\nProvide your email and an installation link will be sent to you\nInstall the full version of Anaconda (not miniconda)\n\nInstall and setup the IR Kernel\n\nFind the location of R.exe on your computer (the location probably looks like C:\\Program Files\\R\\R-4.5.1\\bin). If you can‚Äôt find it, launch Command Prompt (CMD) and execute where R. The output should be the path to the file R.exe.\nOpen the Anaconda Prompt application. Enter the following command into Anaconda Prompt: cd file_path_here where file_path_here is replaced with the location of the R.exe that you found.\nRun R from within Anaconda Prompt by entering in R.exe. This opens an R session inside Anaconda Prompt. From here, enter the following commands in this order:\n\ninstall.packages(\"IRkernel\")\nIR:kernel::installspec()\n\nIf prompted to select a IR kernel mirror, select 12 (CANADA - MB).\n\nTo verify that everything is working, open Anaconda Prompt and type jupyter lab. Jupyter Lab should launch and display both a Python and R kernel.\n\nHaving trouble? Check the instructions here: https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/.\nMac OS Installation:\n\nInstall Anaconda from https://www.anaconda.com/download\n\nProvide your email and an installation link will be sent to you\nInstall the full version of Anaconda (not miniconda)\n\nInstall and setup the IR Kernel\n\nOpen R and navigate to the Console (see below).\n\n\n\nYour console may have a different appearance! Mine‚Äôs in dark mode.\n\n\nInstall the necessary packages by entering\ninstall.packages(c(\"repr\", \"IRdisplay\", \"evaluate\", \"crayon\", \"pbdZMQ\", \"devtools\", \"uuid\", \"digest\"))\ndevtools::install_github(\"IRkernel/IRkernel\")\nExit RStudio.\n\nConfigure the IRkernel from within R\n\nIt‚Äôs important that these next commands are done from within the version of R that you want to link to Jupyter Lab (R version 5.4.1, for example)\nLaunch R (NOT RSTUDIO! This is typically found in /usr/bin/R. If you can‚Äôt find it, open the Terminal application and type in which R. This will provide you with the path to R. Then, open a Finder window and at the top of your screen hit Go -&gt; go to folder and paste everything in the path except R (i.e., /usr/bin/). Scroll through and find R and open it.\nIn the R application, run IRkernel::installspec()\nIf prompted to choose a IRkernel mirror, select 12 (Canada - MB).\n\nLaunch Anaconda, and open a Jupyter Lab and you should see an R kernel available.\n\nHaving trouble? Check out https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/.\n\n\n\nGit is a version control software. Github is a cloud-based platform (built on Git) for sharing code.\n\nRegister a Github account at github.com (if you don‚Äôt already have one).\n\nCreate a username that uses your actual name. Shorter is better! For example, mine is grcetmpk. See this for more information.\nYou don‚Äôt need to download any apps.\n\nInstall Git (more info here)\n\nSee if Git is already installed. For Mac OS, on the Terminal (Mac) type which git. For Windows, go to Command Prompt and type where git. If you get an error of git: command not found, you do not have git installed yet.\nWindows:\n\nInstall Git for Windows (https://gitforwindows.org/)\nWhen asked about ‚ÄúAdjusting your PATH environment‚Äù, make sure to select ‚ÄúGit from the command line and also from 3rd-party software‚Äù. Otherwise, keep the defaults.\n\nMac OS:\n\nInstall XCode Command Line Tools by opening Terminal and typing xcode-select --install (more info here)\nIn Terminal, enter git config. Click install.\n\n\nConfigure Git: In RStudio, navigate to the Terminal or Shell (see below).\n\n\n\nIf using Windows, you will have a Shell, not a Terminal.\n\n\nwithin the Terminal (Mac) or Shell (Windows) (Tools &gt; Terminal/Shell) do:\ngit config --global user.name \"your_github_username\"\ngit config --global user.email \"your_email_you_used_for_github@example.com\"\ngit config --global --list\n\nIf you are having issues, you could use the usethis package in R. See here.\n\nGet your Personal Access Token (PAT)\n\nOption 1: Go to to https://github.com/settings/tokens and click ‚ÄúGenerate token‚Äù. Describe the token‚Äôs purpose in the Note field, e.g.¬†‚Äúpersonal-macbook‚Äù or ‚ÄúStat545Installation‚Äù. Select ‚Äúrepo‚Äù, ‚Äúuser‚Äù, and ‚Äúworkflow‚Äù for scopes. Save this token somewhere so you can use it again later, such as a password manager.\nOption 2: From R, execute usethis::create_github_token() (you may have to install the usethis package first by first running install.packages(\"usethis\")). Describe the token‚Äôs purpose in the Note field, e.g.¬†‚Äúpersonal-macbook‚Äù or ‚Äústat545installation‚Äù.\n\nFrom R (in the console), run install.packages(\"gitcreds\") if you haven‚Äôt already.\nExecute gitcreds::gitcreds_set() and enter the PAT that you just made when prompted.",
    "crumbs": [
      "Lecture 1A: Installation"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1a_installation.html#software-and-troubleshooting",
    "href": "webpages/lectures_i/lec1a_installation.html#software-and-troubleshooting",
    "title": "Lecture 1A: Installation",
    "section": "",
    "text": "The goal of this lecture is to learn how to install and setup key software for use in the course.\nTAs are available in class on Imagine Day from 9am-10:30am on Tuesday September 2nd to aid with installation. I highly recommend you join if you haven‚Äôt used RStudio, Jupyter, or GitHub before.\n\n\nYou may encounter some material that implicitly assumes that you are using a Mac. For example, they might point you to a Terminal app, or ask you to use Unix commands like which or ls. Here is a cheatsheet that helps you convert between Windows command line (‚ÄúDOS‚Äù) and Mac command line (‚ÄúUNIX‚Äù). One thing that‚Äôs missing is the equivalent to Unix‚Äôs which; the closest equivalent in DOS is where.\n\n\n\nR and RStudio The main programming language used in the class is R and our main IDE (a text editor with helpful features for writing and running code) is RStudio. The following instructions are adapted from Chapter 5 of Jenny Bryan‚Äôs ‚Äúhappy git‚Äù book.\n\nInstall (or update to) the latest release R on your computer (4.5.1 currently):\n\nWindows: https://cran.r-project.org/bin/windows/base/\nMac: https://cran.r-project.org/bin/macosx/\n\nInstall RStudio\n\nhttps://posit.co/download/rstudio-desktop/\n\n\nEven if you already have R/RStudio, please update them to the most recent version!\n\n\n\nYou will need another IDE for R (Jupyter Notebook) and an R kernel called ‚ÄòIR Kernel‚Äô (needed to run R code within Jupyter) to work on the autograded worksheets. This is because the autograder we use plays well with Jupyter.\nThe following instructions are adapted from Rich Pauloo.\nPC Installation:\n\nInstall Anaconda from https://www.anaconda.com/download\n\nProvide your email and an installation link will be sent to you\nInstall the full version of Anaconda (not miniconda)\n\nInstall and setup the IR Kernel\n\nFind the location of R.exe on your computer (the location probably looks like C:\\Program Files\\R\\R-4.5.1\\bin). If you can‚Äôt find it, launch Command Prompt (CMD) and execute where R. The output should be the path to the file R.exe.\nOpen the Anaconda Prompt application. Enter the following command into Anaconda Prompt: cd file_path_here where file_path_here is replaced with the location of the R.exe that you found.\nRun R from within Anaconda Prompt by entering in R.exe. This opens an R session inside Anaconda Prompt. From here, enter the following commands in this order:\n\ninstall.packages(\"IRkernel\")\nIR:kernel::installspec()\n\nIf prompted to select a IR kernel mirror, select 12 (CANADA - MB).\n\nTo verify that everything is working, open Anaconda Prompt and type jupyter lab. Jupyter Lab should launch and display both a Python and R kernel.\n\nHaving trouble? Check the instructions here: https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/.\nMac OS Installation:\n\nInstall Anaconda from https://www.anaconda.com/download\n\nProvide your email and an installation link will be sent to you\nInstall the full version of Anaconda (not miniconda)\n\nInstall and setup the IR Kernel\n\nOpen R and navigate to the Console (see below).\n\n\n\nYour console may have a different appearance! Mine‚Äôs in dark mode.\n\n\nInstall the necessary packages by entering\ninstall.packages(c(\"repr\", \"IRdisplay\", \"evaluate\", \"crayon\", \"pbdZMQ\", \"devtools\", \"uuid\", \"digest\"))\ndevtools::install_github(\"IRkernel/IRkernel\")\nExit RStudio.\n\nConfigure the IRkernel from within R\n\nIt‚Äôs important that these next commands are done from within the version of R that you want to link to Jupyter Lab (R version 5.4.1, for example)\nLaunch R (NOT RSTUDIO! This is typically found in /usr/bin/R. If you can‚Äôt find it, open the Terminal application and type in which R. This will provide you with the path to R. Then, open a Finder window and at the top of your screen hit Go -&gt; go to folder and paste everything in the path except R (i.e., /usr/bin/). Scroll through and find R and open it.\nIn the R application, run IRkernel::installspec()\nIf prompted to choose a IRkernel mirror, select 12 (Canada - MB).\n\nLaunch Anaconda, and open a Jupyter Lab and you should see an R kernel available.\n\nHaving trouble? Check out https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/.\n\n\n\nGit is a version control software. Github is a cloud-based platform (built on Git) for sharing code.\n\nRegister a Github account at github.com (if you don‚Äôt already have one).\n\nCreate a username that uses your actual name. Shorter is better! For example, mine is grcetmpk. See this for more information.\nYou don‚Äôt need to download any apps.\n\nInstall Git (more info here)\n\nSee if Git is already installed. For Mac OS, on the Terminal (Mac) type which git. For Windows, go to Command Prompt and type where git. If you get an error of git: command not found, you do not have git installed yet.\nWindows:\n\nInstall Git for Windows (https://gitforwindows.org/)\nWhen asked about ‚ÄúAdjusting your PATH environment‚Äù, make sure to select ‚ÄúGit from the command line and also from 3rd-party software‚Äù. Otherwise, keep the defaults.\n\nMac OS:\n\nInstall XCode Command Line Tools by opening Terminal and typing xcode-select --install (more info here)\nIn Terminal, enter git config. Click install.\n\n\nConfigure Git: In RStudio, navigate to the Terminal or Shell (see below).\n\n\n\nIf using Windows, you will have a Shell, not a Terminal.\n\n\nwithin the Terminal (Mac) or Shell (Windows) (Tools &gt; Terminal/Shell) do:\ngit config --global user.name \"your_github_username\"\ngit config --global user.email \"your_email_you_used_for_github@example.com\"\ngit config --global --list\n\nIf you are having issues, you could use the usethis package in R. See here.\n\nGet your Personal Access Token (PAT)\n\nOption 1: Go to to https://github.com/settings/tokens and click ‚ÄúGenerate token‚Äù. Describe the token‚Äôs purpose in the Note field, e.g.¬†‚Äúpersonal-macbook‚Äù or ‚ÄúStat545Installation‚Äù. Select ‚Äúrepo‚Äù, ‚Äúuser‚Äù, and ‚Äúworkflow‚Äù for scopes. Save this token somewhere so you can use it again later, such as a password manager.\nOption 2: From R, execute usethis::create_github_token() (you may have to install the usethis package first by first running install.packages(\"usethis\")). Describe the token‚Äôs purpose in the Note field, e.g.¬†‚Äúpersonal-macbook‚Äù or ‚Äústat545installation‚Äù.\n\nFrom R (in the console), run install.packages(\"gitcreds\") if you haven‚Äôt already.\nExecute gitcreds::gitcreds_set() and enter the PAT that you just made when prompted.",
    "crumbs": [
      "Lecture 1A: Installation"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html",
    "href": "webpages/lectures_i/lec1b_introR.html",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "",
    "text": "For today‚Äôs lecture, we are going to go through the some important information related to the course and jump right into some coding in R using an interactive worksheet and Jupyter Notebooks.\n\n\nWe will be using various technologies throughout this course which you should familiarize yourself with. The main platforms we‚Äôll be using are;\n\nThe course website (this one!),\nCanvas (for submitting assignments),\nSlack (for communications),\nRStudio (for writing R code),\nGitHub (for version control and collaboration), and\nJupyter notebooks (for interactive worksheets).\n\nIf you‚Äôve never used some of these before, that‚Äôs absolutely OK. This course is made to guide you through the basics of many of these platforms.\n\n\n\nAll of the important information is in the syllabus, which you can navigate to at the top of this page. There are a few items I‚Äôd like to emphasize:\n\nSTAT 545 A has frequent worksheets. These are graded based on completion. For example, if you complete all 15 questions, you will score 100% for that worksheet. Complete 14/15? You‚Äôll get a 93%. They are relatively straight forward and will guide you through the topics we talked about that week.\nEveryone gets one ‚Äúpass‚Äù for a late worksheet. After the first occurrence, a 0 will be awarded for any late worksheet.\nSTAT 545 A has a mini data analysis and collaborative project worth most of your marks. These are not graded on the basis of how sophisticated your statistical analysis is, but on the quality of your code and workflow. A grading rubric will be posted for each.\nThere is a zero tolerance policy for late projects and analyses.\nStay home if you‚Äôre sick. Fill out an Academic Concession Self Declaration form (linked on Canvas) if you miss an assessment due to illness. Accommodations will be given on a case-by-case basis.\nBring a charged laptop to class!\nAll communications are to be done on Slack - do not email me questions unless they are of a sensitive nature (i.e., an academic concession form).\nDon‚Äôt plagiarize code or assessments.\n\nBut please - read the syllabus :)\n\n\n\nLectures for STAT545 are designed to be more interactive than a traditional statistics lecture. The class will begin with a short summary of the previous class, followed by an introduction to that day‚Äôs topic. For most of the lectures, we will be going through the interactive worksheets (yes, the ones that you receive marks for and yes, prior to the deadline). This will give provide you with dedicated time to work on the assessments in class with access to the instructor and the TAs.\nLectures build on top of each other and it is crucial to stay on track as we progress through this course.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html#welcome-to-stat545",
    "href": "webpages/lectures_i/lec1b_introR.html#welcome-to-stat545",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "",
    "text": "For today‚Äôs lecture, we are going to go through the some important information related to the course and jump right into some coding in R using an interactive worksheet and Jupyter Notebooks.\n\n\nWe will be using various technologies throughout this course which you should familiarize yourself with. The main platforms we‚Äôll be using are;\n\nThe course website (this one!),\nCanvas (for submitting assignments),\nSlack (for communications),\nRStudio (for writing R code),\nGitHub (for version control and collaboration), and\nJupyter notebooks (for interactive worksheets).\n\nIf you‚Äôve never used some of these before, that‚Äôs absolutely OK. This course is made to guide you through the basics of many of these platforms.\n\n\n\nAll of the important information is in the syllabus, which you can navigate to at the top of this page. There are a few items I‚Äôd like to emphasize:\n\nSTAT 545 A has frequent worksheets. These are graded based on completion. For example, if you complete all 15 questions, you will score 100% for that worksheet. Complete 14/15? You‚Äôll get a 93%. They are relatively straight forward and will guide you through the topics we talked about that week.\nEveryone gets one ‚Äúpass‚Äù for a late worksheet. After the first occurrence, a 0 will be awarded for any late worksheet.\nSTAT 545 A has a mini data analysis and collaborative project worth most of your marks. These are not graded on the basis of how sophisticated your statistical analysis is, but on the quality of your code and workflow. A grading rubric will be posted for each.\nThere is a zero tolerance policy for late projects and analyses.\nStay home if you‚Äôre sick. Fill out an Academic Concession Self Declaration form (linked on Canvas) if you miss an assessment due to illness. Accommodations will be given on a case-by-case basis.\nBring a charged laptop to class!\nAll communications are to be done on Slack - do not email me questions unless they are of a sensitive nature (i.e., an academic concession form).\nDon‚Äôt plagiarize code or assessments.\n\nBut please - read the syllabus :)\n\n\n\nLectures for STAT545 are designed to be more interactive than a traditional statistics lecture. The class will begin with a short summary of the previous class, followed by an introduction to that day‚Äôs topic. For most of the lectures, we will be going through the interactive worksheets (yes, the ones that you receive marks for and yes, prior to the deadline). This will give provide you with dedicated time to work on the assessments in class with access to the instructor and the TAs.\nLectures build on top of each other and it is crucial to stay on track as we progress through this course.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html#coding-in-r-the-basics",
    "href": "webpages/lectures_i/lec1b_introR.html#coding-in-r-the-basics",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "Coding in R: The Basics",
    "text": "Coding in R: The Basics\nLet‚Äôs get started! By this point, I‚Äôm assuming you‚Äôve successfully installed R, RStudio, Github, and Jupyter notebooks. If you haven‚Äôt, check out the previous lecture for a guide to setting up this software.\nBefore diving into the worksheet, let‚Äôs talk about R. R is an open source programming language designed for statistical computing and data analysis. It is a commonly used programming language alongside Python and SAS, which we will not be covering in this course.\n\nCalculations\nIn its simplest form, R is a calculator. For example, we can type 1 + 2 in the console of R (we will be using RStudio) will spit out the answer of 3.\n\n1 + 2\n\n[1] 3\n\n\nThe [1] in the answer can be ignored for now.\nR can also be used to do more complex expressions, such as \\((450 - 15)^2/(5 + 7\\times4)\\), which we would write in R with:\n\n(450-15)^2/(5+7*4)\n\n[1] 5734.091\n\n\n\n\nVariables\nR can also be used to store values as a variable. To assign a value to a variable in R, we use the &lt;- symbol (the less than symbol followed by the minus sign). For example, if I wanted to store the number of apartments I‚Äôve lived in since moving out for university, I could assign this to a variable called apartments_lived_in by:\n\napartments_lived_in &lt;- 4\n\nThen, if I later wanted to use this value, I could simply execute\n\napartments_lived_in\n\n[1] 4\n\n\nwhich you can see stores the value of 4! I can also do math on this variable, for example multiplying it by 2:\n\napartments_lived_in*2\n\n[1] 8\n\n\nVariables can also store the results of expressions, which we will dive into in Worksheet 1.\n\n\nData Structures\nR isn‚Äôt just a calculator. R can handle different data structures (which are just objects that contain data) including strings, vectors, and data frames (just to name a few). We will go over the basics of these structures in this section.\n\nStrings\nA string is a R (often called character data) is a string of characters enclosed in quotations. For example, I could store my name in a variable called name:\n\nname &lt;- \"Grace\"\n\nand access it later by typing name\n\nname\n\n[1] \"Grace\"\n\n\nStrings can also have write space, such as\n\nmanifestation &lt;- \"I'm a great R coder!\"\nmanifestation\n\n[1] \"I'm a great R coder!\"\n\n\nYou can use single ' or double \" quotation marks to wrap around the string - just be consistent!\n\n\n\n\n\n\nTip\n\n\n\nIn some worksheets, questions are multiple choice. Ensure that you type your answer as a string, i.e., my_answer &lt;- \"A\".\n\n\n\n\nNumeric Vectors\nA vector is an ordered list of items of the same type. A numeric vector is an ordered list of numbers.\nVectors are created in R using the c() function, with elements separated by commas. For example, suppose someone wanted to store the number of roommates they lived with in their four apartments. They had 4 roommates in their first apartment, then 2 in their next, followed by 3, and finally lived alone with 0 roommates. We can save this information in a vector named roommates using the following code:\n\nroommates &lt;- c(4, 2, 3, 0)\n\nTo see the contents of a vector, simply type its name in the console and run the code\n\nroommates\n\n[1] 4 2 3 0\n\n\nWe can access each element of the vector by indexing it with []. In R, unlike some other programming languages, the index starts at 1. So if you‚Äôd like to access the first element of the vector, you can use [1]. For example, to see the number of roommates in my first apartment, I could use\n\nroommates[1]\n\n[1] 4\n\n\nOr view the number of roommates in my third apartment using:\n\nroommates[3]\n\n[1] 3\n\n\nWe can also perform functions on vectors! Suppose we wanted to calculate the total number of occupants in each apartment (including myself). I need to add one person to each apartment! To do so, I can make a new variable called totaloccupants which is equal to roommates plus one:\n\ntotaloccupants &lt;- roommates + 1\ntotaloccupants\n\n[1] 5 3 4 1\n\n\nWe will dive more into functions on vectors in Worksheet 1.\n\n\nLogical Vectors\nA logical vector is a vector where the elements are a logical statement containing TRUE or FALSE. Let‚Äôs see how we can create a vector indicating whether or not there were more than two roommates in a given apartment. We can store this as a variable, named more_than_two_roommates using\n\nmore_than_two_roommates &lt;- roommates &gt; 2\nmore_than_two_roommates\n\n[1]  TRUE FALSE  TRUE FALSE\n\n\nFrom the output, you can see that this statement is true for apartments 1 and 3, indicating there were more than two roommates for these apartments.\n\n\nOther useful functions on vectors\nR has a number of built in functions that are useful for exploring vectors. We can check the length (number of elements) of a vector using the length() function:\n\nlength(roommates)\n\n[1] 4\n\n\nThis answer makes sense as we had data for four apartments. We can also look at the types of data stored in vectors using the typeof function\n\ntypeof(roommates)\n\n[1] \"double\"\n\ntypeof(totaloccupants)\n\n[1] \"double\"\n\ntypeof(more_than_two_roommates)\n\n[1] \"logical\"\n\n\ndouble is a type of numeric data. logical is the type of data that stores TRUE/FALSE.\n\n\nDataframes\nDataframes are a powerful tool for storing multidimensional data. For example, we could have data on housing for multiple people, including the rent paid, number of roommates, city, etc. Dataframes are a convenient way to store such information. Suppose we have data on three individuals stored in the dataframe housingdata. To access it, type housingdata in the R Console.\n\nhousingdata\n\n   Name NumRooms NumOccupants Rent      City\n1 Grace        2            2 2700 Vancouver\n2   Mei        3            4 5000   Toronto\n3   Sam        1            1 1900   Halifax\n\n\nWe see that Grace rents a 2 bedroom apartment, with two total occupants, and the total rent is $2700 per month in Vancouver. Mei lives in Toronto and has a 3 bedroom apartment shared between 4 people, and the total rent is $5000. Sam lives alone in a one bedroom apartment in Halifax, and pays $1900.\nWe will focus more on dataframes in a coming lecture, but I wanted to mention them here.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html#worksheet-a1",
    "href": "webpages/lectures_i/lec1b_introR.html#worksheet-a1",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "Worksheet A1",
    "text": "Worksheet A1\nNow it‚Äôs your turn to use R! Work through Worksheet A1 on your own and reach out on Slack if you have any issues. Refer to the previous lecture if you need guidance on how to access Worksheets on Jupyter Notebooks.\n\n\n\n\n\n\nNote\n\n\n\nWorksheet A1 is NOT going to be graded. However, I highly recommend going through it to practice using Jupyter Notebooks and to get a handle on R. Future worksheets will be graded.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec1b_introR.html#what-to-do-when-youre-stuck",
    "href": "webpages/lectures_i/lec1b_introR.html#what-to-do-when-youre-stuck",
    "title": "Lecture 1B: Course Introduction and R",
    "section": "What to do when you‚Äôre stuck",
    "text": "What to do when you‚Äôre stuck\nWorking with technology can be hard. Coding can be especially hard. Getting stuck is very common in both cases.\nBefore running to Slack, try searching for the answer yourself. This is an extremely important real-world skill! When you‚Äôre conducting your own analyses down the road, you may not have anyone to directly ask for help.\nTry:\n\nGoogling your error codes (removing highly specific information like variable names)\nGoogling the problem (i.e., R dataframe can‚Äôt rename columns)\nSearch stackoverflow and include the [r] tag. Or the [ggplot2] tag. Or the [plyr] tag. You get the idea.\n\n\n\n\n\n\n\nCaution\n\n\n\nBeware of AI tools: sometimes they‚Äôre helpful, and sometimes they‚Äôre not.\n\n\nWhile I encourage you to search for answers on your own, don‚Äôt fret if you‚Äôre stuck. We‚Äôre here to help on Slack! Review the posting guidelines on the Syllabus so your questions go to the appropriate channel.\n\nAttribution\nExample created by Grace Tompkins. Notes originally created by Vincenzo Coia.",
    "crumbs": [
      "Lecture 1B: Course Introduction and R"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html",
    "href": "webpages/lectures_i/lec2A_reproducibility.html",
    "title": "Lecture 2A: Reproducibility",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nUse basic markdown features.\nWrite documents in markdown.\nChoose whether html or pdf is an appropriate output.\nStyle an .Rmd document by editing the YAML header.\nCustomize code chunk output using Rmd code chunk.\nRender your finalized document to HTML & PDF.",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html#learning-objectives",
    "href": "webpages/lectures_i/lec2A_reproducibility.html#learning-objectives",
    "title": "Lecture 2A: Reproducibility",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nUse basic markdown features.\nWrite documents in markdown.\nChoose whether html or pdf is an appropriate output.\nStyle an .Rmd document by editing the YAML header.\nCustomize code chunk output using Rmd code chunk.\nRender your finalized document to HTML & PDF.",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html#reproducibility",
    "href": "webpages/lectures_i/lec2A_reproducibility.html#reproducibility",
    "title": "Lecture 2A: Reproducibility",
    "section": "Reproducibility",
    "text": "Reproducibility\nReproducibility is the ability of an independent researcher to repeat an experiment using the same data and workflow to obtain the same results [1]. One way to ensure reproducible research is sharing clear details on the analysis and providing the code used to produce the results. Reproducibility is often confused with replication. However, replication is a separate concept where the results of a study should be validated on an independent study using new data. A ‚Äúgood‚Äù study is both replicable and reproducible.\nThere are also ethical benefits to reproducible research [1]. Performing open research can reduce the chance of data fabrication or other ethical issues such as p-hacking, where a researcher tests a number of hypotheses until they find one that is statistically significant. Open, transparent research poses a sense of accountability on the researcher(s). Of course, you can‚Äôt always share data (for example, health data containing personal identifying information), but you should share as much as is possible. Always check with your ethics board or principal investigator before sharing data online.\nReproducible studies can also advance research by providing the code used for analysis. Not only can we reproduce the study to make the findings more trustworthy, but we can learn more about how the analysis was performed and possibly apply it to other studies.\nReproducible research can also force you to have better, more automated workflows. The first analysis I ever did in R, I was manually changing things in excel documents, and then saving them in a certain place, and then using R to fit a model, and then exporting the data, and then changing the worksheet format, and so on. I had a sticky note of instructions on how to produce the results on my desk. This was neither reproducible nor productive for my time. While automating some steps and using tools like GitHub for version control can be more work upfront, it can save you a lot of headaches down the road. It is something I personally wish I learned to use earlier in my career.",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html#r-markdown",
    "href": "webpages/lectures_i/lec2A_reproducibility.html#r-markdown",
    "title": "Lecture 2A: Reproducibility",
    "section": "R Markdown",
    "text": "R Markdown\nUsing an editor like MS Word is like painting: you decorate the page with text, graphs, and tables, making sure things are positioned, sized, and coloured appropriately.\nThis is great for a letter to a friend, but is less great for scientific work, because it hampers reproducibility and shareability.\nR Markdown lets you write a single ‚Äúblueprint‚Äù for your analysis that includes everything - positioning/sizing/colouring/formatting, analysis/graph/table code and results, and text ‚Äì and then ‚Äúknit‚Äù all of those components together into a complete report with a single button press.\nThere is a large community of R Markdown users, making it easy to find tutorials and blog posts about a ton of different types of documents. We‚Äôre going to start simple and dive right into R Markdown.\n\nGetting Started with Markdown\nIn lecture, we are going to work through this online Markdown tutorial together in small groups. Challenge yourself to meet someone new in the class!\nAfter completing the tutorial, try making your own R Markdown document!\n\nIn RStudio, go to ‚ÄúFile‚Äù -&gt; ‚ÄúNew File‚Äù -&gt; ‚ÄúMarkdown File‚Äù\nWrite a Markdown document all about you that includes:\n\nA header\nA link to your GitHub profile\nA list of courses you‚Äôre taking this semester\n\nClick the ‚ÄúPreview‚Äù button to generate an output .html file from the source .md file.\n\n\n\nInstall RMarkdown\n\nOpen a new .Rmd file in RStudio (‚ÄúFile‚Äù &gt; ‚ÄúNew File‚Äù &gt; ‚ÄúRMarkdown‚Ä¶‚Äù). Add ‚ÄúSTAT545_Lecture_2‚Äù as your title and save the other default options.\nTo get started with using R Markdown, you‚Äôll need to install the rmarkdown R package. You might automatically be prompted to do this; accept, if so. If not, you will have to manually install the package.\ninstall.packages('rmarkdown')\nAfter installation, install the DT package:\ninstall.packages('DT')\nClick ‚Äúknit‚Äù.\n\nThings to notice:\n\nThe YAML header is contained between two ‚Äî at the top of the .Rmd source, and contains metadata on the document. This is where you specify the output type to be HTML.\nText is formatted using Markdown. There are three chunks of R code, and knitting executes the R code and displays the output in the output file.\n\nHow does it all work?\nThe key drivers under the hood are knitrand Pandoc! When you press ‚ÄúKnit‚Äù, R Markdown passes the .Rmdfile to knitr, which executes all of the code and creates a new .md file including the code and output. Then, that .md file is processed into the final output format (e.g.¬†.html) by pandoc.\n\n\n\n\n\n\nExercise: Edit Your YAML in Small Groups:\n\n\n\nRun ?html_document from your R console and/or check out Yihui Xie‚Äôs RMarkdown book to:\n\nAdd a floating table of contents\nAdd a theme.\n\nIf this was easy, then try to figure out how to knit to a pdf document!\n\n\n\n\n\n\n\n\nInstructor demo: mtcars Report\n\n\n\nTo follow along, download the demonstration.Rmd file from the STAT545 GitHub and open it in RStudio.\n\n\n\nExploring Code Chunks\n\nAdd a code chunk below the first paragraph in the ‚ÄúMotor Trend Car Road Tests data‚Äù section of the .Rmd file. Either select ‚ÄúCode‚Äù -&gt; ‚ÄúInsert Chunk‚Äù, or use a keyboard shortcut: cmd + option + I(MAC) / ctrl + alt + i(WINDOWS).\nIn this code chunk, print out the mtcars data frame to explore the output. (Yes, this object comes shipped with R.)\nRun that chunk interactively using the green ‚Äòplay‚Äô button.\nNow try out the DT::datatable() function on mtcars in this new chunk, and knit the file (to html, ideally).\nAdd an in-line code chunk specifying the number of rows of the mtcars dataset in place of the hardcoded number ‚Äú32 automobiles‚Äù. Hint: nrow().\nFill in the document with markdown commentary for each of the code chunks! A few notes go a long way towards improving the readability of the report.\n\n\n\nCode Chunk Options\n\n\n\n\n\n\nTip\n\n\n\nGot lost in the demonstration? No problem, just open a new .Rmd file in RStudio via ‚ÄúFile‚Äù -&gt; ‚ÄúNew File‚Äù -&gt; ‚ÄúR Markdown‚Ä¶‚Äù, and just press ‚ÄúOK‚Äù, and resume!)\n\n\nJust like YAML is metadata for the Rmd document, code chunk options are metadata for the code chunk. Specify them within the {r} at the top of a code chunk, separated by commas. For a list of chunk options, check out Yihui Xie‚Äôs knitr book. Let‚Äôs try some:\n\nHide the code from the output with echo = FALSE.\nChange the figure width and height with fig.width = 5 and fig.height = 3.\nKnit the results. Can you spot the differences?\n\n\n\n\n\n\n\nExercise 2\n\n\n\nIn the instructor demo, we prettied up a nice report about mtcars together. But suddenly, you receive an email from your collaborator who collected the mtcars data, who says that the data on Mazda RX4, the Valiant, and the Volvo 142E were transcribed wrong from the magazine! They‚Äôre going to work on correcting them, but in the mean time, they‚Äôd like to re-run the analysis with those three cars excluded.\nIn small groups, prepare an updated report by updating your .Rmd appropriately, then re-knitting it. Then discuss: in this case, how did using the RMarkdown workflow rather than copying and pasting R output to MS Word help prevent the creation of non-reproducible results?",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2A_reproducibility.html#resources",
    "href": "webpages/lectures_i/lec2A_reproducibility.html#resources",
    "title": "Lecture 2A: Reproducibility",
    "section": "Resources",
    "text": "Resources\nHere are a number of resources that may help supplement you with today‚Äôs lesson:\n\nSTAT 545 Episode 3-A: Reproducible Reports with R Markdown Some additional resources that you might find useful:\nThe Official R Markdown Tutorial from the ‚ÄúIntroduction‚Äù up to and including the ‚ÄúInline Code‚Äù section.\nR Markdown cheat sheet\n\n\n\n\n\n\n\nTip\n\n\n\nMany cheat sheets can be found from RStudio: go to ‚ÄúHelp‚Äù -&gt; ‚ÄúCheatsheets‚Äù.\n\n\n\nAttribution\nDemonstration by Ic√≠ar Fern√°ndez Boyano. Inspiration for activity ideas drawn from Nicholas Tierney‚Äôs R Markdown for Scientists book, the R Markdown for Medicine workshop materials, and the UBC MDS program.",
    "crumbs": [
      "Lecture 2A: Reproducibility"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html",
    "title": "Lecture 2B: Version Control",
    "section": "",
    "text": "From today‚Äôs topic, students are anticipated to be able to:\n\nuse git on their own computer (locally).\nconnect between a local git repository and that repository on GitHub, using RStudio.\nmake commits in git using RStudio.\nmake a branch in git using RStudio or GitHub.\nuse collaborative GitHub features such as Issues and pull requests.\n\nAfter this class, you should be able to start working on your Collaborative Project.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#learning-objectives",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#learning-objectives",
    "title": "Lecture 2B: Version Control",
    "section": "",
    "text": "From today‚Äôs topic, students are anticipated to be able to:\n\nuse git on their own computer (locally).\nconnect between a local git repository and that repository on GitHub, using RStudio.\nmake commits in git using RStudio.\nmake a branch in git using RStudio or GitHub.\nuse collaborative GitHub features such as Issues and pull requests.\n\nAfter this class, you should be able to start working on your Collaborative Project.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#get-acquainted-with-github",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#get-acquainted-with-github",
    "title": "Lecture 2B: Version Control",
    "section": "Get Acquainted with GitHub",
    "text": "Get Acquainted with GitHub\n\nRepositories, Organizations, and Personal Accounts\nA repository stores files and the history of the files; the usual convention is to use a single repository to organize a single project.\nGitHub is a place where repositories can live online. Being online provides us a way to share and collaborate on projects. It also serves as a backup for your project.\nExample 1: Grace‚Äôs GitHub page\nExample 1: The STAT 545 webpage\nThe first repository lives under Grace‚Äôs personal Github account. The second repository lives under the UBC-STAT organization. Organizations are useful if you have lots of different projects with a common theme which lots of people are collaborating on.\n\n\n\n\n\n\nInstructor Demo: GitHub\n\n\n\nWe will spend some time exploring some GitHub basics, with some real examples of repositories.\n\n\n\n\nUseful Github tips for the course\n\nAll of your projects in this class will live in the STAT 545 @ UBC Organization.\nWhen you watch a Github repo, you get notifications when things happen in them. So if you ‚ÄúWatch‚Äù the STAT 545 webpage repo, then you will get email notifications when I update the site!\nThe Issues page on a Github repo is a forum where Github users can bring up issues related to the repository. Our commmunication guidelines suggest that you post an Issue on your homework repo if you have concerns about your grade.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#create-your-own-repository",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#create-your-own-repository",
    "title": "Lecture 2B: Version Control",
    "section": "Create Your Own Repository",
    "text": "Create Your Own Repository\n\n\n\n\n\n\nExercise\n\n\n\nTry making your own Github repository and editing it on Github! (This exercise is slightly adapted from Data Carpentries.)\n\nGo to your GitHub profile. Eg. Mine is https://github.com/katieburak.\nCreate a new GitHub repository by clicking the + symbol in the top bar and using the dropdown menu to create a new repository.\nName your repository stat-545-demo-YOUR-NAME. In the description write ‚ÄúSTAT 545 Demo‚Äù. Check the box for initializing the repository for adding a README file.\nYou are now redirected to the repository main page. The repository page tells you you have 1 commit. Click on it to get to the history page. This tells you all the changes that have been tracked for the files in the repository so far.\nGo back to your repository main page. Click on README.md, then click ‚Äúedit this file‚Äù. Add the following information into the README.md file:\n\nYour name\nWhat kind of scientist do you tell people you are at dinner parties?\n\nCommit your changes: click the commit changes button, and briefly summarize the changes you‚Äôve made in the Commit message.\nCheck out the Github commit history again. Has anything changed?\n\n\n\n##Working Locally, and Synchronizing with Github\nWe will go through the Data Carpentries tutorial for this together. This demonstrates how to keep and work on the project files in a local repository on your machine, and how to keep it in sync with a remote Github repository.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#merging-conflicts",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#merging-conflicts",
    "title": "Lecture 2B: Version Control",
    "section": "Merging Conflicts",
    "text": "Merging Conflicts\nMerge conflicts happen when we‚Äôve created multiple versions of files that can‚Äôt be obviously combined into one definitive version.\nHere is an example of something that would not cause a merge conflict:\n\nAt 9am, my TA pulls from the STAT 545 repository, makes a local change to the course dashboard, and commits and pushes her changes.\nAt 10am, I forget to pull from the STAT 545 repository, and start working on the Day 1 notes locally.\nWhen I commit and push, Git is a bit confused, because I wasn‚Äôt working off of the ‚Äúfreshest‚Äù version of the STAT 545 repository - but since my TA and I were working on different lines of code, it will fairly seamlessly figure out that the right thing to do is to add my changes to the Day 1 notes to the current version of the STAT 545 repository online.\n\nHere is an example of something that WOULD cause a merge conflict:\n\nAt 9am, my TA and I both pull from the STAT 545 repository.\nAt 10am, my TA changes the front page to say ‚ÄúSTAT 555 @ UBC‚Äù, and commits/pushes those changes.\nAt 11am, I change the front page (without pulling!!!) to say ‚ÄúSTAT 777 @ UBC‚Äù.\nWhen I commit and push, Git doesn‚Äôt know what to do. Should it make the version that says ‚ÄúSTAT 555 @ UBC‚Äù or ‚ÄúSTAT 777 @ UBC‚Äù the definitive version? The push will fail, and Git will tell us we need to fix the conflict and then commit the result.\n\nHow do we fix this?\n\nPull.\nOpen the file that caused the merge conflict. You should see something like this:\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nSTAT 555 @ UBC\n=======\nSTAT 777 @ UBC\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; 526363991d21ed20e7e0c57b5e99d944ac5ce5aa\n\nThe stuff below the &lt;&lt;&lt;&lt;&lt;&lt;&lt; and above the ======= is what was in your local version; the stuff above the &gt;&gt;&gt;&gt;&gt;&gt;&gt; and below the ======= is what was in the remote conflicting version. Decide what you want to have on the offending line (e.g.¬†‚ÄúSTAT 555 @ UBC‚Äù), and replace the whole block of text above with that.\nSave and commit the file. (An informative message here might be ‚ÄúFixing a merge conflict.‚Äù) You should now be able to successfully push!\n\n\n\n\n\n\n\nExercise\n\n\n\nFind a partner. In this exercise, we will learn how to have different team members save their work separately on branches, and how to merge those changes to the main project branch.\n\nTeammate A adds Teammate B to their stat545-demo repository as a collaborator. (Go to Settings from the main repo page, then Access =&gt; Collaborators). This should send Teammate B an email with a collaboration invitation; accept that invitation.\nTeammate B clones Teammate A‚Äôs stat545-demo repository.\nOn their own computer, Teammate B will make a new branch in Teammate A‚Äôs stat545-demo repository. You can do this either on Github by clicking on ‚Äú1 branch‚Äù on the repo homepage then the green ‚ÄúNew branch‚Äù button, or on your own computer in R Studio with the ‚ÄúNew Branch‚Äù button.\nOn their own computer, Teammate B will create a new file in the newly created branch, then commit and push it.\nTeammate B will start a pull request (basically a request to merge content onto the main branch) on GitHub, by going to ‚ÄúPull Requests‚Äù -&gt; ‚ÄúNew Pull Request‚Äù, and selecting the branch you intend to merge to the main branch. In this pull request, include a comment and title indicating (at a high level) what the change made is about.\nTeammate A will follow the instructions here to merge the pull request.\n\nToo easy? Then either switch roles, or try creating a pull request that causes a merge conflict and resolving it!",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec2b_versioncontrol.html#resources",
    "href": "webpages/lectures_i/lec2b_versioncontrol.html#resources",
    "title": "Lecture 2B: Version Control",
    "section": "Resources",
    "text": "Resources\nToday‚Äôs class is a digest of the following resources:\n\nVideo lecture STAT 545 Episode 2-A: Git and GitHub for an Organized Project\nOnline tutorials:\n\nThe basic version control workflow (without branching): Happy git w R: Chapter 20.\nStarting with GitHub: Chapter 15: New project, GitHub first\nStarting with files on your computer, and didn‚Äôt set up git: Chapter 16: Existing project, GitHub first\nStarting with files on your computer, and did set up git: Chapter 17: Existing project, GitHub Last\n\n\nSome additional resources that you might find useful:\n\nRead the Understanding the GitHub flow to get a sense of branching.",
    "crumbs": [
      "Lecture 2B: Version Control"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html",
    "href": "webpages/lectures_i/lec3_dplyr.html",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nUse the five core dplyr verbs for data wrangling: select(), filter(), arrange(), mutate(), summarise().\nUse piping when implementing function chains.\nUse group_by() to operate within groups (of rows) with mutate() and summarise().\nUse across() to operate on multiple columns with summarise() and mutate().\n\nWe will spend two classes on this topic.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#learning-objectives",
    "href": "webpages/lectures_i/lec3_dplyr.html#learning-objectives",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nUse the five core dplyr verbs for data wrangling: select(), filter(), arrange(), mutate(), summarise().\nUse piping when implementing function chains.\nUse group_by() to operate within groups (of rows) with mutate() and summarise().\nUse across() to operate on multiple columns with summarise() and mutate().\n\nWe will spend two classes on this topic.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#why-data-manipulation",
    "href": "webpages/lectures_i/lec3_dplyr.html#why-data-manipulation",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Why Data Manipulation?",
    "text": "Why Data Manipulation?\nYou have a shiny new data set - great! You might be tempted to dive right in and start making pretty graphs and fitting cool models to your data. Not so fast! In practice, it‚Äôs very rare that you have the data in the exact right form to make the graph you want, or fit the model you want. You will need to start by manipulating your data into the right form: creating new variables, subsetting rows, renaming columns, etc.\nPlus, an important piece of data analysis output is tables that summarize the data in some way. For example, it is extremely standard practice in biomedical and public health studies to have the first table of any journal article summarize basic characteristics of the study population, possibly stratified by exposure. While these tables are less pretty than graphs, they can nevertheless be very insightful!\nAn even less exciting but perhaps even more important part of data analysis is simply checking the data for things like:\n\nPossible inconsistencies with your understanding of what the data set should contain\nPossible errors\nBasic info gathering: number of rows, number of columns, amount of missing data, etc.\n\nAll of these require data manipulation. We choose to use the dplyr (pronounced d-plier) package for this.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#tibbles",
    "href": "webpages/lectures_i/lec3_dplyr.html#tibbles",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Tibbles",
    "text": "Tibbles\nAs mentioned in Lecture 1A, data frames are useful tools for storing data. You can think of it as a spreadsheet of information, but in R. A tibble is a modern version of a basic data frame. To use tibbles, we first install the tibble package (if we haven‚Äôt already) and load it into R by:\n\n# install.packages(\"tibble\") # remove comment if not already installed\nlibrary(tibble)\n\nTibbles typically said to be more user friendly than standard R dataframes, and are easily used with tidyverse functions. More on that in a bit!\nWe can either load in pre-existing data frames (like from a .csv file or an R package), or create a tibble manually using the tibble() function. For example, we could use\n\ntibble(x = letters)\n\n# A tibble: 26 √ó 1\n   x    \n   &lt;chr&gt;\n 1 a    \n 2 b    \n 3 c    \n 4 d    \n 5 e    \n 6 f    \n 7 g    \n 8 h    \n 9 i    \n10 j    \n# ‚Ñπ 16 more rows\n\n\nto have a single column tibble of letters of the alphabet, or\n\nhousingdata &lt;- tibble(name = c(\"Grace\", \"Mei\", \"Steven\", \"Phuong\", \"Omar\", \"Richa\", \"Bruce\", \"David\"), \n                      numrooms = c(2, 3, 1, 4, 2, 1, 3, 2), \n                      rent_2024 = c(2665, 4900, 2900, 4950, 2400, 1000, 2800, 2350),\n                      rent_2025 = c(2700, 5000, 2900, 5000, 2500, 1000, 2800, 2400),\n                      city = c(\"Vancouver\", \"Toronto\", \"Halifax\", \"Vancouver\", \"Montreal\", \"Victoria\", \"Halifax\", \"Vancouver\"))\nhousingdata\n\n# A tibble: 8 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Mei           3      4900      5000 Toronto  \n3 Steven        1      2900      2900 Halifax  \n4 Phuong        4      4950      5000 Vancouver\n5 Omar          2      2400      2500 Montreal \n6 Richa         1      1000      1000 Victoria \n7 Bruce         3      2800      2800 Halifax  \n8 David         2      2350      2400 Vancouver\n\n\nWe can see that the tibble can store different data types (here we have both numeric data (‚Äúdbl‚Äù is short for double) and character data (‚Äúchr‚Äù is short for character).\nWe can also change an R data frame to a dibble. For example, the mtcars data set is available in the datasets package in R as a dataframe. We can load it as a tibble using:\n\nlibrary(datasets)\ntibble(mtcars)\n\n# A tibble: 32 √ó 11\n     mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n 2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n 3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n 4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n 5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n 6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n 7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n 8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n 9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n# ‚Ñπ 22 more rows",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#dplyr-functions",
    "href": "webpages/lectures_i/lec3_dplyr.html#dplyr-functions",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "dplyr Functions",
    "text": "dplyr Functions\nTo use the dplyr functions, we need to install (if necessary) and load the dplyr package:\n\n# install.packages(\"dplyr\") #remove comment if not installed yet\nlibrary(dplyr)\n\nOnce loaded, we will have a number of new tools at our disposal. Here are a few functions we are going to review in this lecture:\n\nselect(): keep or remove certain columns\n\n\nSubsetting with select()\nselect() allows you to keep or remove columns. For example, in the housingdata dataset, say we only want the columns name and city. We use the select function where the first argument is the name of the tibble, and the other arguments are the names of the columns we wish to keep:\n\nselect(housingdata, name, city)\n\n# A tibble: 8 √ó 2\n  name   city     \n  &lt;chr&gt;  &lt;chr&gt;    \n1 Grace  Vancouver\n2 Mei    Toronto  \n3 Steven Halifax  \n4 Phuong Vancouver\n5 Omar   Montreal \n6 Richa  Victoria \n7 Bruce  Halifax  \n8 David  Vancouver\n\n\nNow, this didn‚Äôt alter the original data frame! If we wanted to save this reduced dataframe, we can name it to a new variable, such as\n\nhousingdata2 &lt;- select(housingdata, name, city)\nhousingdata2\n\n# A tibble: 8 √ó 2\n  name   city     \n  &lt;chr&gt;  &lt;chr&gt;    \n1 Grace  Vancouver\n2 Mei    Toronto  \n3 Steven Halifax  \n4 Phuong Vancouver\n5 Omar   Montreal \n6 Richa  Victoria \n7 Bruce  Halifax  \n8 David  Vancouver\n\n\nNow, housingdata2 contains only the rows we were interested in keeping, without overriding the original housingdata tibble. We can see that housingdata still contains all of the information from the original data set.\n\nhousingdata\n\n# A tibble: 8 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Mei           3      4900      5000 Toronto  \n3 Steven        1      2900      2900 Halifax  \n4 Phuong        4      4950      5000 Vancouver\n5 Omar          2      2400      2500 Montreal \n6 Richa         1      1000      1000 Victoria \n7 Bruce         3      2800      2800 Halifax  \n8 David         2      2350      2400 Vancouver\n\n\nWe can also use select() to indicate which columns to remove. For example, if I wanted all variables except name in my data set, I could do:\n\nselect(housingdata, -name)\n\n# A tibble: 8 √ó 4\n  numrooms rent_2024 rent_2025 city     \n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1        2      2665      2700 Vancouver\n2        3      4900      5000 Toronto  \n3        1      2900      2900 Halifax  \n4        4      4950      5000 Vancouver\n5        2      2400      2500 Montreal \n6        1      1000      1000 Victoria \n7        3      2800      2800 Halifax  \n8        2      2350      2400 Vancouver\n\n\n\n\nSubsetting with filter()\nThe filter() function allows you to specify which rows to keep in the tibble. The filter() function takes conditional statements and allows us to remove or keep rows based on these conditions.\nFor example, let‚Äôs say we wanted to keep only data where the rent in 2025 (rent_2025) is strictly larger than 2500. Then, we could use:\n\nfilter(housingdata, rent_2025 &gt; 2500)\n\n# A tibble: 5 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Mei           3      4900      5000 Toronto  \n3 Steven        1      2900      2900 Halifax  \n4 Phuong        4      4950      5000 Vancouver\n5 Bruce         3      2800      2800 Halifax  \n\n\nNow, only rows with rent_2025 &gt; 2500 are kept in the data frame.\nWe can also use the == sign to indicate that something is equivalent. For example, we may only be interested in observations in Vancouver. To do so, we can use:\n\nfilter(housingdata, city == \"Vancouver\")\n\n# A tibble: 3 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Phuong        4      4950      5000 Vancouver\n3 David         2      2350      2400 Vancouver\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe double == in the statement to indicate ‚Äúis equal to‚Äù! Further, as the variable of interest is a string (or character type), we need to use quotations around the city name ‚ÄúVancouver‚Äù.\n\n\nWe can also filter on multiple variables at the same time, even if they are different types. for example:\n\nfilter(housingdata, rent_2025 &gt; 2500, city == \"Vancouver\")\n\n# A tibble: 2 √ó 5\n  name   numrooms rent_2024 rent_2025 city     \n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1 Grace         2      2665      2700 Vancouver\n2 Phuong        4      4950      5000 Vancouver\n\n\n\n\nLeveling Up with tidyselect()\nSometimes we will want to select columns that have something in common with their name. This is particularly useful when the number of columns is large (for example, think if we had historical rent data for many years). To do so, we can use helper functions in the tidyverse library. First, install (if necessary) and load in the tidyverse library\n\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)\n\nLet‚Äôs use the starts_with() function to select all columns that relate to rents. We can do this by:\n\nselect(housingdata, starts_with(\"rent\"))\n\n# A tibble: 8 √ó 2\n  rent_2024 rent_2025\n      &lt;dbl&gt;     &lt;dbl&gt;\n1      2665      2700\n2      4900      5000\n3      2900      2900\n4      4950      5000\n5      2400      2500\n6      1000      1000\n7      2800      2800\n8      2350      2400\n\n\nThis code returned a tibble where only the columns involving rents are included! Other useful helper functions include:\n\nstarts_with() finds variables that start with the given input\nends_with() finds variables that end with the given input\ncontains() finds variables that have the given input at any location in the name\n\nWhile for the example data set we are really only selecting two columns, using these functions allows your code to be more flexible as data may be added later for more years of rent, for example.\n\n\nCreating New Variables with mutate()\nSometimes we need to create another variable or column based on information already present in a tibble. For example, suppose we are interested in the cost per room, rather than total rent, in our data. We can create a new variable that is the rent divided by the number of rooms using mutate():\n\nmutate(housingdata, rent_per_room_2025 = rent_2025/numrooms)\n\n# A tibble: 8 √ó 6\n  name   numrooms rent_2024 rent_2025 city      rent_per_room_2025\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1 Grace         2      2665      2700 Vancouver              1350 \n2 Mei           3      4900      5000 Toronto                1667.\n3 Steven        1      2900      2900 Halifax                2900 \n4 Phuong        4      4950      5000 Vancouver              1250 \n5 Omar          2      2400      2500 Montreal               1250 \n6 Richa         1      1000      1000 Victoria               1000 \n7 Bruce         3      2800      2800 Halifax                 933.\n8 David         2      2350      2400 Vancouver              1200 \n\n\nWe can also clean this up by rounding our new variable to two decimal places using the round() function:\n\nmutate(housingdata, rent_per_room_2025 = round(rent_2025/numrooms,2))\n\n# A tibble: 8 √ó 6\n  name   numrooms rent_2024 rent_2025 city      rent_per_room_2025\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1 Grace         2      2665      2700 Vancouver              1350 \n2 Mei           3      4900      5000 Toronto                1667.\n3 Steven        1      2900      2900 Halifax                2900 \n4 Phuong        4      4950      5000 Vancouver              1250 \n5 Omar          2      2400      2500 Montreal               1250 \n6 Richa         1      1000      1000 Victoria               1000 \n7 Bruce         3      2800      2800 Halifax                 933.\n8 David         2      2350      2400 Vancouver              1200 \n\n\nAs we can see, the mutate() function took the data as the first argument, and then we listed the new variable name rent_per_room_2025 which we calculated by taking the rent in 2025 (rent_2025) and dividing it by the number of rooms in the house (numrooms). We wrapped round( x, 2) around the calculation to clean up the answer to two decimal places.\n\n\nThe Pipe Operator %&gt;%\nThe pipe operator (%&gt;%) is a convenient way to form a chain of commands on a tibble to perform multiple tasks at once.\nLet‚Äôs assume we want to modify a tibble using both select() and filter(). We can do so in one single line of code using the pipe operator. But for now, let‚Äôs start simple and use just one function using %&gt;%.\nLet‚Äôs say we want to subset our data and select only the rent and city columns on a tibble. We could use:\n\nselect(housingdata, starts_with(\"rent\"), city)\n\n# A tibble: 8 √ó 3\n  rent_2024 rent_2025 city     \n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1      2665      2700 Vancouver\n2      4900      5000 Toronto  \n3      2900      2900 Halifax  \n4      4950      5000 Vancouver\n5      2400      2500 Montreal \n6      1000      1000 Victoria \n7      2800      2800 Halifax  \n8      2350      2400 Vancouver\n\n\nwhich is a perfectly valid answer. However, we could also use the pipe operator, as:\n\nhousingdata %&gt;%\n  select(starts_with(\"rent\"), city)\n\n# A tibble: 8 √ó 3\n  rent_2024 rent_2025 city     \n      &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    \n1      2665      2700 Vancouver\n2      4900      5000 Toronto  \n3      2900      2900 Halifax  \n4      4950      5000 Vancouver\n5      2400      2500 Montreal \n6      1000      1000 Victoria \n7      2800      2800 Halifax  \n8      2350      2400 Vancouver\n\n\nHere, we tell dplyr the tibble we want to transform (housingdata), and then use the pipe operator (%&gt;%) to tell dplyr what functions we want to perform on it.\n\n\n\n\n\n\nNote\n\n\n\nWhen using the pipe operator, we no longer need to include the dataframe in the first argument of the function. Compare the previous two code chunks to see what I mean.\n\n\nWhile it may not be obvious from this first example why the pipe operator is commonly used, let‚Äôs consider that we want to\n\nfilter on rents for 2025 above $2500\nselect all columns aside from name\ncreate a new variable for the rent per room in 2025 (rounded to 2 decimal places)\nreorder the rows by descending order of 2025 rents\n\nThe arrange() function can change the order of rows.\narrange(desc(column_name)) will arrange the roms in descending order for the column_name given. See more here!\n\n\nTo do all of these tasks, the pipe operator allows us to write clear and readable code:\n\nhousingdata %&gt;% \n  filter(rent_2025 &gt; 2500) %&gt;%\n  select(-name) %&gt;%\n  mutate(rent_per_room_2025 = round(rent_2025/numrooms,2)) %&gt;%\n  arrange(desc(rent_2025))\n\n# A tibble: 5 √ó 5\n  numrooms rent_2024 rent_2025 city      rent_per_room_2025\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1        3      4900      5000 Toronto                1667.\n2        4      4950      5000 Vancouver              1250 \n3        1      2900      2900 Halifax                2900 \n4        3      2800      2800 Halifax                 933.\n5        2      2665      2700 Vancouver              1350 \n\n\n\n\n\n\n\n\nNote\n\n\n\nAfter each function call, we need to include the pipe operator to tell dplyr that we‚Äôre not done yet, and the chain of commands continues on the next line.\n\n\nAnother thing to note is that the pipe operator creates a new tibble and does not alter the original. So, housingdata still contains all of the original rows and columns in its unaltered form. If we wanted to alter it (or save the output to a new variable), we need to assign it using &lt;-. For example, the following code will overwrite the original tibble:\n\nhousingdata &lt;- housingdata %&gt;% \n    filter(rent_2025 &gt; 2500) %&gt;%\n    select(-name) %&gt;%\n    mutate(rent_per_room_2025 = round(rent_2025/numrooms,2)) %&gt;%\n    arrange(desc(rent_2025))\n\nhousingdata\n\n# A tibble: 5 √ó 5\n  numrooms rent_2024 rent_2025 city      rent_per_room_2025\n     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;                  &lt;dbl&gt;\n1        3      4900      5000 Toronto                1667.\n2        4      4950      5000 Vancouver              1250 \n3        1      2900      2900 Halifax                2900 \n4        3      2800      2800 Halifax                 933.\n5        2      2665      2700 Vancouver              1350",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#worksheet-a2",
    "href": "webpages/lectures_i/lec3_dplyr.html#worksheet-a2",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Worksheet A2",
    "text": "Worksheet A2\nWorksheet A2 will guide you through some of the basics of dplyr.\n\nHaven‚Äôt attempted all of the questions on Worksheet A2? Then spend this time completing the worksheet.\nFinished attempting all of the questions? Then do the optional R4DS Data Transformation reading, and maybe even do some of the exercises for extra practice.\n\nPut any questions you have about the worksheet questions or about data manipulation in Slack.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#next-class-fev-case-study",
    "href": "webpages/lectures_i/lec3_dplyr.html#next-class-fev-case-study",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Next Class: FEV Case Study",
    "text": "Next Class: FEV Case Study\nNext class we will be working through the first part of the FEV Case Study.\nBy yourself or in small groups, work through the exercises in the case study. The teaching team will walk around and answer questions and chat about anything data manipulation related.\nWe will conclude class by going over instructor solutions.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec3_dplyr.html#resources",
    "href": "webpages/lectures_i/lec3_dplyr.html#resources",
    "title": "Lecture 3: Data Manipulation with dplyr",
    "section": "Resources",
    "text": "Resources\n\nVideo lecture: dplyr Part 1: Basic Data Manipulation\nVideo lecture: dplyr Part 2: Calculations on tibbles\nChapter 6 and Chapter 7 of Jenny Bryan‚Äôs STAT 545 book follows along with what we will be covering in Day 1 and Day 2 of this topic (although you won‚Äôt find the across() function).\n‚ÄúR for Data Science‚Äù is another great resource for learning data wrangling. Take a look at:\ndplyr‚Äôs introductory vignette is useful for orienting you to the package.",
    "crumbs": [
      "Lecture 3: Data Manipulation with dplyr"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html",
    "href": "webpages/lectures_i/lec4_datavis.html",
    "title": "Lecture 4: Data Visualization",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nIdentify the seven components of the grammar of graphics underlying ggplot2.\nProduce plots with ggplot2 by implementing the components of the grammar of graphics.\nCustomize the look of ggplot2 graphs.\nChoose an appropriate plot type for analysis, based on an understanding of what makes a graph effective.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#learning-objectives",
    "href": "webpages/lectures_i/lec4_datavis.html#learning-objectives",
    "title": "Lecture 4: Data Visualization",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nIdentify the seven components of the grammar of graphics underlying ggplot2.\nProduce plots with ggplot2 by implementing the components of the grammar of graphics.\nCustomize the look of ggplot2 graphs.\nChoose an appropriate plot type for analysis, based on an understanding of what makes a graph effective.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#effective-data-visualization",
    "href": "webpages/lectures_i/lec4_datavis.html#effective-data-visualization",
    "title": "Lecture 4: Data Visualization",
    "section": "Effective Data Visualization",
    "text": "Effective Data Visualization\nPlots and other forms of data visualization are powerful tools for conveying complex relationships. While tables can be useful, data visualizations are often preferred to aid with identify patterns and relationships and emphasizing important findings in a research projects. This is especially true for presentations, where the audience may not have time to digest a large table of numbers. Jenny Bryan‚Äôs Challenger Example (https://speakerdeck.com/jennybc/ggplot2-tutorial) is a great example of why we may want to visualize data.\nNow the question is, what visualization should you use to convey an idea? Well, you need to first formulate the question you want the data visualization to answer. That is, you need to figure out what you want to convey before you start visualizing the data. From UBC‚Äôs A First Introduction to Data Science [1] book:\n\n‚ÄúA good visualization will clearly answer your question without distraction; a great visualization will suggest even what the question was itself without additional explanation. Imagine your visualization as part of a poster presentation for a project; even if you aren‚Äôt standing at the poster explaining things, an effective visualization will convey your message to the audience.‚Äù\n\nWe need to convey the message using a data visualization while removing as much unnecessary information as possible. Below is a direct quote from the A First Introduction to Data Science [1] containing their suggestions for effective data visualizations:\n‚ÄúConvey the message‚Äù\n\nMake sure the visualization answers the question you have asked most simply and plainly as possible.\nUse legends and labels so that your visualization is understandable without reading the surrounding text.\nEnsure the text, symbols, lines, etc., on your visualization are big enough to be easily read.\nEnsure the data are clearly visible; don‚Äôt hide the shape/distribution of the data behind other objects (e.g., a bar).√ü\nMake sure to use color schemes that are understandable by those with colorblindness (a surprisingly large fraction of the overall population‚Äîfrom about 1% to 10%, depending on sex and ancestry [2]). For example, ColorBrewer and the RColorBrewer R package [3] provide the ability to pick such color schemes, and you can check your visualizations after you have created them by uploading to online tools such as a color blindness simulator.\nRedundancy can be helpful; sometimes conveying the same message in multiple ways reinforces it for the audience.\n\n‚ÄúMinimize noise‚Äù\n\nUse colors sparingly. Too many different colors can be distracting, create false patterns, and detract from the message.\nBe wary of overplotting. Overplotting is when marks that represent the data overlap, and is problematic as it prevents you from seeing how many data points are represented in areas of the visualization where this occurs. If your plot has too many dots or lines and starts to look like a mess, you need to do something different.\nOnly make the plot area (where the dots, lines, bars are) as big as needed. Simple plots can be made small.\nDon‚Äôt adjust the axes to zoom in on small differences. If the difference is small, show that it‚Äôs small!",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#ggplot2-and-the-grammar-of-graphics",
    "href": "webpages/lectures_i/lec4_datavis.html#ggplot2-and-the-grammar-of-graphics",
    "title": "Lecture 4: Data Visualization",
    "section": "ggplot2 and the Grammar of Graphics",
    "text": "ggplot2 and the Grammar of Graphics\nIf you‚Äôve learned about data visualization in R before, you‚Äôve likely produced plots using ‚Äúbase R‚Äù methods (for example, the boxplot() function in R. It is a simple framework for making plots and is often ‚Äúenough‚Äù for producing basic plots. In this lecture, we are going to dive into ggplot2, a package R users often use to make more sophisticated plots! If you‚Äôve never used R to plot before, don‚Äôt worry. We aren‚Äôt assuming you have any experience with either method of plotting in R.\nWe will be utilising the ggplot2 and tidyverse packages throughout this lecture. To load them:\n\n# install.packages(\"tidyverse\") #uncomment if not already installed\n# install.packages(\"ggplot2\") #uncomment if not already installed\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\nggplot2 is based on the grammar of graphics, which is a systematic approach for describing different components or aspects of a graph. It involves seven components (required components are indicated with the *):\n\nData*\n\nthe data you‚Äôre feeding into the plot, perhaps a tibble or dataframe\n\nAesthetic mappings*\n\na specification of how you will connect variables (for example, horizontal or vertical positioning, grouping, size, colour, shape)\n\nGeometric objects*\n\na specification of what the object will be drawn as (for example, a scatter plot, line, bar chart)\n\nScales\n\na specification of how a variable is mapped to its aesthetic\n\nStatistical transformations\n\na specification of whether and how the data are combined or transformed. For example, is a bar chart plotting the values or a relative frequency?\n\nCoordinate system\n\na specification of how the position aesthetics (x and y) are depicted in the plot. We typically use cartesian coordinates, though polar coordinates are also possible.\n\nFacet\n\na specification of data variables that partition the data into smaller ‚Äúsub plots‚Äù or panels\n\n\nIt‚Äôs okay if you don‚Äôt quite understand all of these components yet. We will walk through examples of commonly used plots and discuss which components are necessary!\n\nExample: Scatterplot\nTo build our first ggplot, we will use the gapminder data from the gapminder package. To install and load it, we use:\n\n# install.packages(\"gapminder\") #uncomment if not already installed\nlibrary(gapminder)\ndata(gapminder) \n\nhead(gapminder) #view first few rows of the tibble\n\n# A tibble: 6 √ó 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n\n\nThe ggplot() function takes two arguments: data (the data frame or tibble containing your data that you‚Äôd like to plot) and mapping (aesthetic mappings applied to the entire plot. We use the aes() function inside of this argument.).\nLet‚Äôs start building the scatterplot! Let‚Äôs plot gdpPercap on the x axis and lifeExp on the y axis:\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp))\n\n\n\n\n\n\n\n\nNotice that we haven‚Äôt actually plotted anything! ggplot doesn‚Äôt know what type of plot we want to draw, only that we want gpdPercap on the x axis and lifeExp on the y axis from the gapminder data we provided. To tell ggplot that we want a scatterplot, we are going to add a layer to the plot using the + at the end of the previous line. geom_point() is the geometric object we‚Äôd like to add (i.e., a scatterplot):\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp)) +\n  geom_point()\n\n\n\n\n\n\n\n\nWe now have created a scatterplot! However, it‚Äôs a bit dense and difficult to see. We can specify an alpha transparency value within the geom_point() function to change the opacity:\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp)) +\n  geom_point(alpha = 0.2)\n\n\n\n\n\n\n\n\nThat‚Äôs already looking better! We can really tell now where there are a lot of observations.\nNow, let‚Äôs transform the scale of the x axis to see if there is a more linear relationship between life expectancy and the log transformation of GDP per capita. The transformation will be of the form scale_AES_TRANSFORMATION() where AES corresponds to which aesthetic value is being transformed, and the TRANSFORMATION is the transformation being completed (here it will be log10. We can also rename the x axis using the first argument. We also can change the labels on the x axis to be dollar format. Let‚Äôs add another layer to do so:\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp)) +\n  geom_point(alpha = 0.2) + \n  scale_x_log10(\"GDP per capita (log-scale)\", labels = scales::dollar_format())\n\n\n\n\n\n\n\n\nThe more translucent grey points are still a bit hard to see. Let‚Äôs change the background to a more minimalist theme using a theme() layer. While we‚Äôre at it, let‚Äôs also rename the y axis using a ylab() later:\n\nggplot(gapminder, aes(x = gdpPercap, lifeExp)) +\n  geom_point(alpha = 0.2) + \n  scale_x_log10(\"GDP per capita (log-scale)\", labels = scales::dollar_format()) +\n  theme_minimal() +\n  ylab(\"Life Expectancy (Years)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nNames of axes should have quotations ‚Äú‚Äù around them.\nThe order of the layers doesn‚Äôt matter after the geom_layer() layer.\n\n\n\n\nCommon Types of Plots\n\ngeom_point(): scatterplot\ngeom_line(): line plot\ngeom_bar(): bar chart\ngeom_histogram(): histogram\ngeom_boxplot(): box plot\ngeom_smooth(): adds a smooth trend line (various methods)\n\n\n\nAdvice for ggplot\nGoogle is absolutely your friend when building ggplots. I don‚Äôt think I‚Äôve ever made a plot without googling how to do it. ggplot is extremely powerful, flexible, and a bit scary to learn! If you need to build a plot, search it! Need to plot two histograms, separated by groups (say, gender), side by side? I‚Äôd google: ‚Äúggplot histogram grouped by variable‚Äù. This brings me to this blog post by R Charts that has a TON of different side by side histograms with code! ggplot is very much a ‚Äúlearn by doing‚Äù skill.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#worksheet-a3",
    "href": "webpages/lectures_i/lec4_datavis.html#worksheet-a3",
    "title": "Lecture 4: Data Visualization",
    "section": "Worksheet A3",
    "text": "Worksheet A3\n\nIt‚Äôs time to try ggplot1 yourself! Spend time working through Worksheet 3.\nFinished attempting all of the questions? Then do the optional R4DS Data Visualization reading, and maybe even do some of the exercises for extra practice.\n\nPost any questions you have on the Slack channel!",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#next-class-fev-case-study",
    "href": "webpages/lectures_i/lec4_datavis.html#next-class-fev-case-study",
    "title": "Lecture 4: Data Visualization",
    "section": "Next class: FEV Case Study",
    "text": "Next class: FEV Case Study\nWe will get a flavour for how you might use ggplot2 in the wild and get in even more practice by working through a continuation of our FEV case study from last week.\nBy yourself and in small groups, work through the exercises in the case study. We will also discuss instructor answers to each exercise.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec4_datavis.html#additional-resources",
    "href": "webpages/lectures_i/lec4_datavis.html#additional-resources",
    "title": "Lecture 4: Data Visualization",
    "section": "Additional Resources",
    "text": "Additional Resources\nVideo lectures for this topic (ignore the episode numbering):\n\nVideo Lecture: ggplot2 Part 1: Introduction to Plotting\nVideo Lecture: ggplot2 Part 2: Plotting for Exploratory Data Analysis\nThe R4DS Data Visualization chapter (provides an excellent overview of plotting in ggplot2 and the grammar of graphics. We especially recommend sections 3.1 to 3.4.)\nHadley Wickham‚Äôs ggplot2 book (a well-organized, approachable, and comprehensive coverage of ggplot2.)\nCheatsheets:\n\nThe ggplot2 cheatsheet (Also available through RStudio: ‚ÄúHelp‚Äù -&gt; ‚ÄúCheatsheets‚Äù -&gt; ‚ÄúData visualization with ggplot2‚Äù).\nR Cookbook Graphs\n\nCraig Hutton‚Äôs comprehensive blog post adopting a similar structure to our course notes, but with more explorations.\nResources about producing effective visualizations:\n\nFundamentals of Data Visualization by Claus Wilke is an excellent guide to designing effective visuals. If you only look at one resource, this should be it.\nVisualization Analysis and Design by Tamara Munzner is a gold-standard book for the theory of designing plots with a focus on human perception.\nBite-sized resources to help you produce effective visualizations:\n\nThe ‚Äúdo‚Äôs and don‚Äôts of effective graphics‚Äù in Jenny Bryan‚Äôs STAT 545 book provides some rules of thumb for producing effective visuals.\nVincenzo‚Äôs ‚ÄúCommunicating data‚Äù slides provide some rules of thumb.\nCallingbull.org‚Äôs entry on visualizations, by Carl T. Bergstrom and Jevin West, goes over several examples of improving ineffective visuals.",
    "crumbs": [
      "Lecture 4: Data Visualization"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html",
    "href": "webpages/lectures_i/lec5_tidydata.html",
    "title": "Lecture 5: Tidy Data",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nrecognize whether a given data set is ‚Äòtidy‚Äô or ‚Äòuntidy‚Äô for their analysis\nunderstand why ‚Äòtidy‚Äô data can be useful\nreshape a data set between ‚Äòlong‚Äô and ‚Äòwide‚Äô formats, using tidyr::pivot_longer() and tidyr::pivot_wider()\nunderstand how to grapple with explicit missing values created by pivoting",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#learning-objectives",
    "href": "webpages/lectures_i/lec5_tidydata.html#learning-objectives",
    "title": "Lecture 5: Tidy Data",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nrecognize whether a given data set is ‚Äòtidy‚Äô or ‚Äòuntidy‚Äô for their analysis\nunderstand why ‚Äòtidy‚Äô data can be useful\nreshape a data set between ‚Äòlong‚Äô and ‚Äòwide‚Äô formats, using tidyr::pivot_longer() and tidyr::pivot_wider()\nunderstand how to grapple with explicit missing values created by pivoting",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#tidy-data-and-the-tidyverse",
    "href": "webpages/lectures_i/lec5_tidydata.html#tidy-data-and-the-tidyverse",
    "title": "Lecture 5: Tidy Data",
    "section": "Tidy Data and the Tidyverse",
    "text": "Tidy Data and the Tidyverse\nIn the last two weeks, we learned about the dplyr package for data manipulation and the ggplot2 package for graphing. These two packages are part of the ‚Äútidyverse‚Äù: a collection of data science packages that are designed to have input data frames and output data frames that are tidy. In fact, we can load all packages in the tidyverse at once with the single command library(tidyverse).\nHere, we are using the word ‚Äútidy‚Äù in a technical sense - we‚Äôre not talking about how ‚Äúneat‚Äù or ‚Äúorganized‚Äù your data is. Instead, ‚Äútidy‚Äù is a very specific set of rules for storing data.\nTidy data is defined as data where\n\neach variables form a column,\neach observation forms a row, and\neach cell is a single measurement. [1]\n\nFor example, the following data set containing cat and dog names by family is not tidy. We have multiple observations per row (a cat, and a dog observation):\n\n\n\nFamily\nCat Name\nDog Name\n\n\n\n\nTompkins\nSumo\nMochi\n\n\nTruong\nMr.¬†Meow\nBowser\n\n\nMaclean\nGoose\n\n\n\n\nInstead, a tidy version of this data set may look like this:\n\n\n\nPet Name\nType\nFamily\n\n\n\n\nSumo\nCat\nTompkins\n\n\nMochi\nDog\nTompkins\n\n\nMr.¬†Meow\nCat\nTruong\n\n\nBowser\nDog\nTruong\n\n\nGoose\nCat\nMaclean\n\n\n\nEach row is an observation, each variable is a column, and each cell is a single measurement. Our data is tidy!\nAll of the data we used before this week were already tidy. This made it easy to use the tidyverse packages dplyr and ggplot2 to do what we needed to do. Oftentimes however, data is not collected in a tidy way. So, what happens do we do when we have untidy data? Let‚Äôs explore it!\n\nExample: Drinks\nThe fivethirtyeight R package contains a dataset called drinks. This dataset was compiled as part of a FiveThirtyEight article that explored (among other things) which countries consumes the most alcohol. Let‚Äôs look at a subset of the data:\n\n# install.packages(\"fivethirtyeight\") #uncomment if not installed\nlibrary(fivethirtyeight)\nlibrary(tibble)\nlibrary(tidyverse)\n\ndrinks_tbl1 &lt;- as_tibble(drinks) %&gt;% \n  select(-total_litres_of_pure_alcohol) #remove total liters variable\n\nhead(drinks_tbl1) #view the first few rows of the data\n\n# A tibble: 6 √ó 4\n  country           beer_servings spirit_servings wine_servings\n  &lt;chr&gt;                     &lt;int&gt;           &lt;int&gt;         &lt;int&gt;\n1 Afghanistan                   0               0             0\n2 Albania                      89             132            54\n3 Algeria                      25               0            14\n4 Andorra                     245             138           312\n5 Angola                      217              57            45\n6 Antigua & Barbuda           102             128            45\n\n\nThe following graphic was made from the drinks dataset.\n\n\n\n\n\n\n\n\n\n\n\nExercise 1\n\n\n\nWith a partner or a small group discuss the following questions think about if the data is tidy or untidy. If tidy, what would the ggplot code look like to reproduce this graph? If untidy, what would the tidy format look like? Sketch the first few rows of the data. Now, what would the ggplot code look like to reproduce this graph?\n\n\n\n\nExample: Bake-off\nIt‚Äôs clear from the definition that tidiness is an attribute of a dataset. But did you know that tidiness also depends on what you are planning to do with the data? That‚Äôs because what‚Äôs an observation and what‚Äôs a variable depends on the data analysis plan!\nWe will demonstrate using data from ‚ÄúThe Great British Bake Off‚Äù compiled by Allison Hill in the R package bakeoff. The graphics that follow (and the code to produce the graphics) were lightly adapted from Allison‚Äôs Plot Twist talk.\nFirst, let‚Äôs decide on some questions we can address with this data.\n\nHow did viewership change as new series came out?\nThe show moved channels after Series 7. Was viewership higher, lower, or about the same before and after the move?\n\nThese questions have implicitly defined our observations: they are individual units of the most granular populations we are trying to describe or compare. Here, the populations to be compared are series, and units within them are episodes. The variables now fall into place: they are measured attributes of our observations (episodes): episode number, viewership, series membership, etc. This means that the following representation of viewership data is tidy for the ‚Äúchange in viewership over series‚Äù analysis:\n\n# install.packages(\"bakeoff\") #uncomment if not yet installed\nlibrary(bakeoff)\nlibrary(tidyverse)\n\nratings_tbl1 &lt;- ratings %&gt;% #save output to new tibble called ratings_tbl1\n  mutate(ep_id = row_number()) %&gt;% # create variable for episode number\n  select(ep_id, viewers_7day, series, episode) #select specific columns\n\nhead(ratings_tbl1) #view first few rows of tibble\n\n# A tibble: 6 √ó 4\n  ep_id viewers_7day series episode\n  &lt;int&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1     1         2.24      1       1\n2     2         3         1       2\n3     3         3         1       3\n4     4         2.6       1       4\n5     5         3.03      1       5\n6     6         2.75      1       6\n\n\nEvery row is an observation (a unique episode), and the columns are variables (episode number across series, 7-day viewership, series, and episode number within series).\nThis is a typical example where the tidy format makes it easy to do our analysis. For example, to investigate these questions, we might make a bar plot of the number of viewers in millions within a 7-day window per episode, coloured by series. The following code uses the tidy tibble ratings_tbl1 to make this bar plot. Notice that it was easy to use our graphing environment of choice (ggplot2 in the tidyverse) to make the plot because our data is tidy, and the tidyverse is designed to work with tidy data.\n\nseries_labels &lt;- ratings_tbl1 %&gt;% #save output to series_labels\n  mutate(series=as.factor(series)) %&gt;% #ensure series variable is a factor (categorical variable)\n  group_by(series) %&gt;% #group by series\n  summarize(y_position = median(viewers_7day) + 1, # calculate positions for the bar charts\n            x_position = mean(ep_id)) #\n\n# make the plot\nratings_tbl1 %&gt;% \n  mutate(series=as.factor(series)) %&gt;% # ensure series is a factor variable\n  ggplot(aes(x = ep_id, y = viewers_7day, fill = series)) + #set x and y axes, tell ggplot that we want things coloured by series\n    geom_col(alpha = .9) + #tell ggplot we want a boxplot, change translucency with alpha\n    ggtitle(\"7-Day Viewership across Series 1-10\") + #add a title\n    geom_text(data = series_labels, aes(label = series, #add text for series numbers\n                                      x = x_position, \n                                      y = y_position)) +\n    theme_classic() +  #add a classic theme\n    scale_fill_manual(values = bakeoff_palette(),\n                    guide = \"none\") + #set the colours so they aren't rainbow\n    xlab(\"Episode Number\") +  #add x axis label\n    ylab(\"7-Day Viewership (millions)\") #add y axis label\n\n\n\n\n\n\n\n\nNow let‚Äôs consider a different set of questions:\n\nHow did viewership grow between premiere to final episode in each series?\nDoes the premiere-to-final-episode growth vary across series?\n\nTo investigate these questions, we might make a bar plot like the one below displaying percentage increase in the number of viewers in millions within a 7-day window from the premiere episode to finale episode for the first 10 series, using the tidy tibble ratings_tbl2:\n\nhead(ratings_tbl2)\n\n# A tibble: 6 √ó 3\n  series first  last\n  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 1       2.24  2.75\n2 2       3.1   5.06\n3 3       3.85  6.74\n4 4       6.6   9.45\n5 5       8.51 13.5 \n6 6      11.6  15.0 \n\n\nFirst, we can calculate the percentage change in viewership using mutate():\n\nratings_tbl2 &lt;- ratings_tbl2 %&gt;%  #overwrite original df so new variable saves\n   mutate(pct_change = (last - first)/first) #calculate percent change\n\nhead(ratings_tbl2) #view first few rows of tibble\n\n# A tibble: 6 √ó 4\n  series first  last pct_change\n  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;\n1 1       2.24  2.75      0.228\n2 2       3.1   5.06      0.632\n3 3       3.85  6.74      0.751\n4 4       6.6   9.45      0.432\n5 5       8.51 13.5       0.588\n6 6      11.6  15.0       0.295\n\n\nThen, we can visualize this using a bar chart:\n\nratings_tbl2 %&gt;% \n  ggplot(aes(x = fct_rev(series), y=pct_change)) + #initialize the plot\n  geom_col(fill = bakeoff::bakeoff_colors(\"baltic\"), alpha = .5) + #set bar chart with fill colours, semi-translucent \n  labs(x = \"Series\", y = \"% Increase in Viewers, First to Last Episode\") + #add x labels\n  ggtitle(\"% Increase in Viewers from Premiere to Finale\") + #add y labels\n  scale_y_continuous(labels = scales::percent) + #change y axis to percentage \n  theme_classic() + #add classic theme\n  coord_flip() #flip horizontally\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nWith a partner or a small group:\n\nWhat do you think ratings_tbl2 looks like?\nWhy is it tidy? (Hint: what are the observations and variables?)\nCould you have calculated the information in ratings_tbl2 using ratings_tbl1? (No need to write code - just discuss whether it‚Äôs possible.)",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#pivoting",
    "href": "webpages/lectures_i/lec5_tidydata.html#pivoting",
    "title": "Lecture 5: Tidy Data",
    "section": "Pivoting",
    "text": "Pivoting\nOnce you have figured out what‚Äôs tidy for you, you may come to realize that your data is not tidy. As we have discussed, it will typically save you time and frustration to tidy it before moving on in your analysis.\nVery often this will involve using ‚Äúpivoting‚Äù type functions. For example, the tidyr package in the tidyverse has two main pivoting functions:\n\npivot_longer() makes datasets longer: it moves some information in the columns into new rows, thereby increasing the number of rows of the dataset.\npivot_wider() makes datasets wider: it moves some information in the rows into new columns, thereby decreasing the number of rows of the dataset.\n\nBy now, you should have a sense for why this might be useful for tidying!\n\nPivoting Wider\nHere is some code to create a variable for whether an episode is the first or last episode of the season to ratings_tbl1 and subset to only the data from the first and last episodes of each season.\n\nratings_tbl1 &lt;- ratings_tbl1 %&gt;% #overwrite ratings_tbl1\n group_by(series) %&gt;% #group by series\n  filter(episode == 1 | episode == max(episode)) %&gt;% #get only the first and last episodes\n  ungroup() %&gt;% #ungroup the data\n  mutate(episode_fl = recode(episode, `1` = \"first\", .default = \"last\")) #add a new variable indicatign whether or not the episode was first or last, and recode the variable to \"first\" or \"last\"\n\nhead(ratings_tbl1)\n\n# A tibble: 6 √ó 5\n  ep_id viewers_7day series episode episode_fl\n  &lt;int&gt;        &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;     \n1     1         2.24      1       1 first     \n2     6         2.75      1       6 last      \n3     7         3.1       2       1 first     \n4    14         5.06      2       8 last      \n5    15         3.85      3       1 first     \n6    24         6.74      3      10 last      \n\n\nThis is not the same format as ratings_tbl2, which was the tidy format for our earlier ‚Äúviewership growth within series‚Äù analysis. But it does contain the same information. To finish converting ratings_tbl1 into ratings_tbl2, we need to make ratings_tbl1 wider: we need to move some information in the rows (the info about whether each episode is the first or last episode of each season) into new columns.\nWe can solve this problem using pivot_wider, which needs three pieces of information.\n\nWhat is a set of columns that uniquely identifies each observation? Put their names in the id_cols argument.\nWhere should the names for the new columns come from? Put the name of the column you want to take the new variable names from in the names_from argument.\nWhat values should the new columns contain? Put the name of the columns you want to take the values from to values_from in the values_from argument.\n\nNote that if you don‚Äôt specify an id_cols argument, pivot_wider will assume that you want it to be every column except those in names_from and values_from.\n\nratings_tbl2 &lt;- ratings_tbl1 %&gt;% #overwrite ratings_tbl2\n  pivot_wider(id_cols = series, #pivot with id as series\n              names_from=episode_fl, #get column names from episode_fl\n              values_from=viewers_7day) #fill in values form viewers_7day\n\nhead(ratings_tbl2)\n\n# A tibble: 6 √ó 3\n  series first  last\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1      1  2.24  2.75\n2      2  3.1   5.06\n3      3  3.85  6.74\n4      4  6.6   9.45\n5      5  8.51 13.5 \n6      6 11.6  15.0 \n\n\nAlso note that any columns not included in id_cols, names_from, and values_from (e.g.¬†ep_id) will simply be dropped.\nIf we wanted to keep the info in ep_id as well, we would add it to the values_from argument:\n\nratings_tbl1 %&gt;% \n  pivot_wider(id_cols = series, \n              names_from=episode_fl, \n              values_from=c(viewers_7day, ep_id)) #now including ep_id in the values_from call to include it in the output\n\n# A tibble: 10 √ó 5\n   series viewers_7day_first viewers_7day_last ep_id_first ep_id_last\n    &lt;dbl&gt;              &lt;dbl&gt;             &lt;dbl&gt;       &lt;int&gt;      &lt;int&gt;\n 1      1               2.24              2.75           1          6\n 2      2               3.1               5.06           7         14\n 3      3               3.85              6.74          15         24\n 4      4               6.6               9.45          25         34\n 5      5               8.51             13.5           35         44\n 6      6              11.6              15.0           45         54\n 7      7              13.6              15.9           55         64\n 8      8               9.46             10.0           65         74\n 9      9               9.55             10.3           75         84\n10     10               9.62             10.0           85         94\n\n\n\n\nPivoting Longer\n\nThe Basics: Column Names Contain Variable Values\nHere is a snippet of WHO data on the number of tuberculosis cases in different years in different countries.\n\n\n# A tibble: 3 √ó 3\n  country     `1999` `2000`\n  &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan    745   2666\n2 Brazil       37737  80488\n3 China       212258 213766\n\n\nIf we wanted to compare tuberculosis cases over time by country (e.g.¬†by plotting the year on the x-axis and case count on the y-axis with a line for each country), then this format is not tidy. We want to (graphically) compare years within countries, so there should be one observation per unit within each population (country-years). In this case, we do not observe units within each country-year, so each observation is a country-year. The variables then fall into place: the country and year labels, and the case counts.\n(Aside: if we had measured more data, then perhaps there would be more units within each population! Imagine if we had case-level information, like severity. Then we could view cases as observations within the country-year populations, and we would have variables like country, year, case ID, and severity.)\nSo the tidy format here puts the variables (the year, the country, and the case counts) on the columns. There are 6 rows, one for each unique country-year combination. In this example, the tidy format is longer. That means to produce it using table4a, we need to lengthen it by moving some information in the column names (the info about the measurement year) into new rows.\nWe can solve this problem using pivot_longer, which needs three pieces of information.\n\nWhich are the columns that we want to expand into more rows? Put their names in the cols argument.\nWe want to save the information in the names of those columns as values in new column(s) of our dataset. What should we name these new column(s)? This is the names_to argument.\nWe also want to preserve the information in the values of those columns - so we should save them as values in a new column of our dataset. What should we name it? This is the values_to argument.\n\n\ntable4a %&gt;% pivot_longer(cols = c(`1999`, `2000`), #pivot these columns\n                         names_to = \"year\", #new column name is year\n                         values_to = \"cases\") #use cases as the values of the column\n\n# A tibble: 6 √ó 3\n  country     year   cases\n  &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt;\n1 Afghanistan 1999     745\n2 Afghanistan 2000    2666\n3 Brazil      1999   37737\n4 Brazil      2000   80488\n5 China       1999  212258\n6 China       2000  213766\n\n\nNow our data is tidy!\n\n\nExample: Column Names Contain Multiple Variable Values\nHere‚Äôs a more realistic (but still simplified) look at the WHO Tuberculosis data.\n\nwho_demo &lt;- who2 %&gt;% \n  select(country, year, starts_with(\"sp\")) %&gt;%\n  rename_with(function(x) \n    str_remove(x, pattern=\"sp_\"), \n    starts_with(\"sp\")) %&gt;% \n  filter(year %in% c(1999, 2000)) %&gt;% \n  filter(country %in% c(\"Afghanistan\", \"Brazil\", \"China\"))\n\nhead(who_demo)\n\n# A tibble: 6 √ó 16\n  country      year m_014 m_1524 m_2534 m_3544 m_4554 m_5564  m_65 f_014 f_1524\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Afghanistan  1999     8     55     55     47     34     21     8    25    139\n2 Afghanistan  2000    52    228    183    149    129     94    80    93    414\n3 Brazil       1999   301   3662   5401   5827   4630   2634  2121   372   2909\n4 Brazil       2000  1894   7268  11568  11906   8623   5085  4494  1859   6719\n5 China        1999  1247  18961  29328  25095  24239  21564 21367  1431  15178\n6 China        2000  1131  19111  29399  25206  25593  21429 21771  1420  14536\n# ‚Ñπ 5 more variables: f_2534 &lt;dbl&gt;, f_3544 &lt;dbl&gt;, f_4554 &lt;dbl&gt;, f_5564 &lt;dbl&gt;,\n#   f_65 &lt;dbl&gt;\n\n\nThis time, cases are broken down by gender (f/m) and by age range (014\\1524\\2534\\3544\\4554\\5564\\65).\nSuppose now that we are interested in comparing tuberculosis rates over time across (potentially) gender, age, and country. Then the most granular population we are trying to describe is a country, gender, age, and year combination, and like in the last example, we have no measured sub-units within that population, so an observation is a unique combination of country, gender, age, and year. (What a mouthful!)\nOnce we‚Äôve sorted that out, the variables fall into place: country, year, gender, age range, and case count. Values for gender and age range are currently located in the column names of who_demo, and values for case count are currently spread across multiple columns. So to tidy who_demo up, we need to use pivot_longer() to move the info in the columns into new rows.\nConceptually, this is pretty similar to the last example: we want to use the information in m_014, m_1524, etc. to create new rows. So we should put those column names into the cols argument. But now, we want the information in their column names - the gender and age - to go into two new columns: gender and age. We can do this by specifying two column names in the names_to argument: gender and age.\nBut how is pivot_longer() to know which part of the column name m_014 corresponds to the gender, and which part corresponds to the age? You need to tell it that the pieces of information are separated by the ‚Äú_‚Äù character using the names_sep argument.\nFinally, we can specify the name of the new column we want the values in the m_014, m_1524, etc. columns to go into with the values_to argument.\n\nwho_demo %&gt;% pivot_longer(cols = !(country:year), # all columns aside from country to year\n                          names_to = c(\"gender\", \"age\"), #new columns named age and gender\n                          names_sep = \"_\",#current gender and age are a single variable separated by _\n                          values_to = \"cases\") #use the cases column for the values\n\n# A tibble: 84 √ó 5\n   country      year gender age   cases\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt;\n 1 Afghanistan  1999 m      014       8\n 2 Afghanistan  1999 m      1524     55\n 3 Afghanistan  1999 m      2534     55\n 4 Afghanistan  1999 m      3544     47\n 5 Afghanistan  1999 m      4554     34\n 6 Afghanistan  1999 m      5564     21\n 7 Afghanistan  1999 m      65        8\n 8 Afghanistan  1999 f      014      25\n 9 Afghanistan  1999 f      1524    139\n10 Afghanistan  1999 f      2534    160\n# ‚Ñπ 74 more rows\n\n\n\n\nExample: Column Names Contain Variable Names And Values\nSo far we have seen examples where the column names contain variable values. But what if they contain names AND values?\nLet‚Äôs have a look at the household dataset (loaded with the tidyr package), which has the date of birth and names of two children in families. Let‚Äôs say that we wanted to investigate how children names relate to their date of birth.\n\nhead(household)\n\n# A tibble: 5 √ó 5\n  family dob_child1 dob_child2 name_child1 name_child2\n   &lt;int&gt; &lt;date&gt;     &lt;date&gt;     &lt;chr&gt;       &lt;chr&gt;      \n1      1 1998-11-26 2000-01-29 Susan       Jose       \n2      2 1996-06-22 NA         Mark        &lt;NA&gt;       \n3      3 2002-07-11 2004-04-05 Sam         Seth       \n4      4 2004-10-10 2009-08-27 Craig       Khai       \n5      5 2000-12-05 2005-02-28 Parker      Gracie     \n\n\nWe are trying to learn about the population from which these children belong; it is hard to say precisely what that is without having more information about how this data was collected, but it is likely something like ‚Äúall children living in a particular place in a particular year‚Äù. The units in this population are children. So to tidy this data, we‚Äôd want ‚Äúdate of birth‚Äù and ‚Äúname‚Äù to be two variables/columns associated with an observation/row (a child). We know we want to use pivot_longer(), because we want to make household longer by creating new variables. But wait! The names of the ‚Äúdate of birth‚Äù/‚Äúname‚Äù variables AND the values of the ‚Äúchild‚Äù variable are BOTH in the column names of household!\nInspecting the documentation for pivot_longer() very carefully reveals that you can use a special specification of the names_to argument to resolve this problem.\n\nhousehold %&gt;% pivot_longer(cols = -family, # all columns except family\n                           names_to = c(\".value\", \"child\"), #change column names, .value is a placeholder\n                           names_sep = \"_\") # dob and child are currently separated by _ in one single variable\n\n# A tibble: 10 √ó 4\n   family child  dob        name  \n    &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt; \n 1      1 child1 1998-11-26 Susan \n 2      1 child2 2000-01-29 Jose  \n 3      2 child1 1996-06-22 Mark  \n 4      2 child2 NA         &lt;NA&gt;  \n 5      3 child1 2002-07-11 Sam   \n 6      3 child2 2004-04-05 Seth  \n 7      4 child1 2004-10-10 Craig \n 8      4 child2 2009-08-27 Khai  \n 9      5 child1 2000-12-05 Parker\n10      5 child2 2005-02-28 Gracie\n\n\nThe special \".value\" specification says that we want to use the first component of the pivoted column name as a variable name, and make a new column with values coming from the second component of the pivoted column name. The second thing we pass into names_to names that new column.\nThis process is best described by Figure 6.7 from R4DS.\nBut wait! Row 4 is a bunch of NAs! Does that mean this data isn‚Äôt tidy??\nThe fact that there is an NA does not necessarily mean that this data is untidy. To be clear: for the purpose of the tidy data definition, an indicator for a missing value is a value.\nWhether this data is untidy depends on the data context. Essentially, the question we should ask is: ‚ÄúIs row 4 an observation that we are missing information about? Or is it simply an artifact of our pivoting procedure?‚Äù\nSuppose this study was designed to only sample families with two children. Then, row 4 could be a real observation that we are missing information about: family 2 should have only been included if they had two children. Perhaps this reflects family 2 filling out a survey that asks them the number of children (in which they listed 2), but then getting distracted and forgetting to fill out the information for their second child. In this case, our data is tidy, and the tidy data format is a real advantage: it reveals missing information in our data set that was not obvious from the original untidy format.\nNow suppose this study just samples families at large. We know from experience about the world that some families have one children, some families have two, and some families have more. Then, it seems possible that row 4 is not a real observation: family 2 might just have a single child. In this case, we have a row for something that is not an observation, so we would like to tidy up by dropping it. We could actually have done this by altering our original pivot_wider() call as follows:\n\nhousehold %&gt;% pivot_longer(cols = -family, \n                           names_to = c(\".value\", \"child\"), \n                           names_sep = \"_\", \n                           values_drop_na = TRUE) #remove NAs\n\n# A tibble: 9 √ó 4\n  family child  dob        name  \n   &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt; \n1      1 child1 1998-11-26 Susan \n2      1 child2 2000-01-29 Jose  \n3      2 child1 1996-06-22 Mark  \n4      3 child1 2002-07-11 Sam   \n5      3 child2 2004-04-05 Seth  \n6      4 child1 2004-10-10 Craig \n7      4 child2 2009-08-27 Khai  \n8      5 child1 2000-12-05 Parker\n9      5 child2 2005-02-28 Gracie\n\n\nThis discussion highlights the importance of knowing the context in which your data is collected for tidying (and for your analysis at large). Here and elsewhere, it really pays to be in close contact with the people who generated your data.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#separating-and-uniting",
    "href": "webpages/lectures_i/lec5_tidydata.html#separating-and-uniting",
    "title": "Lecture 5: Tidy Data",
    "section": "Separating and Uniting",
    "text": "Separating and Uniting\nThe tidyr package has a function for gluing columns together (unite) and for cutting columns apart (separate). Why might this help us tidy? Here is another snippet of WHO Tuberculosis data.\n\ntable3 &lt;- tibble(country = c(\"Afghanistan\", \"Afghanistan\", \"Brazil\", \"Brazil\", \"China\", \"China\"),\n                 year = c(1999, 2000, 1999, 2000, 1999, 2000),\n                 rate = c(\"745/19987071\", \"2666/20595360\", \"37737/172006362\", \n                          \"80488/174504898\", \"212258/1272915272\", \"213766/1280428583\"))\n\ntable3\n\n# A tibble: 6 √ó 3\n  country      year rate             \n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;            \n1 Afghanistan  1999 745/19987071     \n2 Afghanistan  2000 2666/20595360    \n3 Brazil       1999 37737/172006362  \n4 Brazil       2000 80488/174504898  \n5 China        1999 212258/1272915272\n6 China        2000 213766/1280428583\n\n\nThe rate column contains the values of two variables: case counts and population counts. We would like to snip it apart at the ‚Äú/‚Äù character to create two columns:\n\ntable5 &lt;- table3 %&gt;% separate(col = rate, \n                    into = c(\"cases\", \"population\"))\ntable5\n\n# A tibble: 6 √ó 4\n  country      year cases  population\n  &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 Afghanistan  1999 745    19987071  \n2 Afghanistan  2000 2666   20595360  \n3 Brazil       1999 37737  172006362 \n4 Brazil       2000 80488  174504898 \n5 China        1999 212258 1272915272\n6 China        2000 213766 1280428583\n\n\nThe col argument specifies the column we want to separate, and the into argument specifies the names of the new columns. The sep argument (not specified here) specifies where we want to cut. The default is pretty clever - it separates at any non-alphanumeric value. (How this is accomplished involves regular expressions, which are very useful when working with character data. We will learn more about regular expressions in STAT 545B. )",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#the-merits-of-untidy-data",
    "href": "webpages/lectures_i/lec5_tidydata.html#the-merits-of-untidy-data",
    "title": "Lecture 5: Tidy Data",
    "section": "The Merits of Untidy Data",
    "text": "The Merits of Untidy Data\nAs we‚Äôve seen, tidy data is often very helpful. But there are also times when untidy data is good. Here are a few reasons:\n\nThe format that lends itself best to fast computations might not be tidy. Case Study: Tidy Genomics.\nUntidy data is often easier for humans to interpret and edit. See Untidy Data: The Unreasonable Effectiveness of Tables.\nWe could lose important information about the context in which the data was collected by cleaning and tidying raw data. This can have important ethical implications; see Chapter 5 of the book ‚ÄúData Feminism‚Äù by Catherine D‚ÄôIgnazio and Lauren F. Klein.\n\nIn summary, tidiness is a very useful concept, and tidying data is often useful. But we should remember that absolutes are few and far between in data science and statistics. Just because tidying data is often useful, doesn‚Äôt mean it‚Äôs always useful.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#worksheet-a4",
    "href": "webpages/lectures_i/lec5_tidydata.html#worksheet-a4",
    "title": "Lecture 5: Tidy Data",
    "section": "Worksheet A4",
    "text": "Worksheet A4\nSpend the rest of this class and next class working through Worksheet A4.\n\nFinished attempting all of the questions? Then do the optional R4DS Tidying reading, and maybe even do some of the exercises for extra practice.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#resources",
    "href": "webpages/lectures_i/lec5_tidydata.html#resources",
    "title": "Lecture 5: Tidy Data",
    "section": "Resources",
    "text": "Resources\n\nVideo Lecture: tidyr for Pivoting and Tidy Data\nTo learn how to use the pivot_*() functions, consult tidyr‚Äôs pivot vignette.\nTo get a better understanding of the concept of tidy data:\n\nHadley Wickham‚Äôs paper on Tidy Data is the gold standard treatment of tidy data.\nA ‚Äúcode heavy‚Äù version of the tidy data paper is tidyr‚Äôs ‚ÄúTidy Data‚Äù vignette.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec5_tidydata.html#attribution",
    "href": "webpages/lectures_i/lec5_tidydata.html#attribution",
    "title": "Lecture 5: Tidy Data",
    "section": "Attribution",
    "text": "Attribution\nAlbert Y. Kim inspired the in-class exercises using the drinks data set from fivethirtyeight. Allison Horst and Julia Lowndes created the illustrated tidy data series. Alison Hill inspired the Great British Bakeoff example. We are immensely grateful to these people for creating amazing educational materials!\nWe would also like to thank Samantha Tyner for pointing us towards the Data Feminism book during her week as the curator of the @WomenInStat Twitter account.",
    "crumbs": [
      "Lecture 5: Tidy Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html",
    "href": "webpages/lectures_i/lec6b_dates.html",
    "title": "Lecture 6B: Factors and Dates",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\nThroughout this lecture, we will be using functions from X packages, which we install and load through:\n# install.packages(c(\"tidyverse\", \"gapminder\", \"lubidate\"))\nlibrary(tidyverse)\nlibrary(gapminder)\nlibrary(lubridate)",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#factors",
    "href": "webpages/lectures_i/lec6b_dates.html#factors",
    "title": "Lecture 6B: Factors and Dates",
    "section": "Factors",
    "text": "Factors\n\n‚ÄúThere is no other object that creates as much trouble as factors.‚Äù - Patrick Burns, ‚ÄúThe R Inferno‚Äù.\n\nIn R, we use factors to represent categorical variables: variables that take on a fixed number of known values (i.e.¬†levels). For example, in the penguins data set, species is a factor with three levels: ‚ÄúAdelie‚Äù, ‚ÄúChinstrap‚Äù, and ‚ÄúGentoo‚Äù. We can see this by looking at the str() (structure) of the tibble:\n\nstr(penguins)\n\n'data.frame':   344 obs. of  8 variables:\n $ species    : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island     : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_len   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_dep   : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_len: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass  : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year       : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nor we can explicitly look at the class and levels of the variable of interest by:\n\nclass(penguins$species)\n\n[1] \"factor\"\n\nlevels(penguins$species)\n\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n\nUnder the hood, R stores a factor with (say) 3 levels as a numeric vector containing integers between 1 and 3, paired with a character vector of length 3 that identifies the mapping between the numbers 1, 2, and 3 and the levels.\nThis is not immediately obvious, because R will print factors using the character string levels rather than the numbers that it stores:\n\nset.seed(100) #make reproducible (more on this later)\n\npenguins %&gt;% \n  slice_sample(n=10) %&gt;% #take 10 random rows\n  pull(species) #output the species only\n\n [1] Gentoo    Adelie    Gentoo    Adelie    Chinstrap Chinstrap Adelie   \n [8] Adelie    Gentoo    Chinstrap\nLevels: Adelie Chinstrap Gentoo\n\n\nThis dual nature of factors creates a whole slew of hidden traps and headaches, especially for new R users!\n\n\n\n\n\n\nCaution\n\n\n\nSometimes factors are coded (i.e., written) in the data as integers. Without explicitly telling R, R will assume any numeric data are just regular old numbers.\nAlways ensure that factors are explicit in your code!\n\n\nFor example, suppose in the penguins data set than instead of their names, species had levels ‚Äú1‚Äù, ‚Äú2‚Äù, and ‚Äú3‚Äô where‚Äù1‚Äù could represent Gentoo, ‚Äú2‚Äù Adelie, and 3 ‚ÄúChinstrap‚Äù penguins. So, instead of having the names of penguin species as strings, they are coded as numeric values.\n\npenguins2 &lt;- penguins %&gt;%\n  mutate(species = recode(species, \"Gentoo\" = 1, \"Adelie\" = 2, \"Chinstrap\" = 3))\n\nstr(penguins2)\n\n'data.frame':   344 obs. of  8 variables:\n $ species    : num  2 2 2 2 2 2 2 2 2 2 ...\n $ island     : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_len   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_dep   : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_len: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass  : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year       : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nWe see here that R assumes that species is a numeric variable, not a categorical variable. To ensure R knows that species is categorical, we can use:\n\npenguins2 &lt;- penguins2 %&gt;% #overwrite existing tibble\n  mutate(species = as.factor(species)) #overwrite species to be a factor using as.factor\n\nstr(penguins2)\n\n'data.frame':   344 obs. of  8 variables:\n $ species    : Factor w/ 3 levels \"1\",\"2\",\"3\": 2 2 2 2 2 2 2 2 2 2 ...\n $ island     : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_len   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_dep   : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_len: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass  : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year       : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nNow we see that species is a factor with three levels!\nNevertheless, factors are important and worth the pain. Many functions throughout the R landscape expect categorical variables to be coded as factors. For example, when making plots in either ggplot2 or in base R, we need factors in order to map categorical variables to aesthetic elements like colour.\nTo make our lives easier, we will work with factors through the forcats package loaded as part of the tidyverse.\n\nReordering Factor Levels\nBy default, factors are ordered alphabetically or numerically. However, in many cases factors have a logical ordering they should follow. For example, you may have an education variable dictating the level of schooling a student is currently in (i.e., elementary, secondary, post-secondary, graduate). It is natural to order the factor in this way. In other cases, you may just want to reorder the levels of a factor so that it plots a certain way. Reordering data can be useful for both data visualization and model fitting.\nTo see the current ordering of a factor variable, we can call levels().\n\nlevels(penguins$species)\n\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n\nWe see here, the levels of the factor are ordered alphabetically.\n\nReordering Levels of a Factors Manually\nThere are many ways to reorder the levels of a factor in R. To reorder the levels of the factor, we can use built in R functions such as ordered():\n\npenguins3 &lt;- penguins %&gt;%\n  mutate(species = ordered(species, levels = c(\"Gentoo\", \"Chinstrap\", \"Adelie\"))) #change species to an ordered factor with the specified ordering\n\nlevels(penguins3$species) #see the levels of species\n\n[1] \"Gentoo\"    \"Chinstrap\" \"Adelie\"   \n\n\nNow, when we call str() on the penguins data, we see that the factor is explicitly ordered, with out new ordering:\n\nstr(penguins3)\n\n'data.frame':   344 obs. of  8 variables:\n $ species    : Ord.factor w/ 3 levels \"Gentoo\"&lt;\"Chinstrap\"&lt;..: 3 3 3 3 3 3 3 3 3 3 ...\n $ island     : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_len   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_dep   : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_len: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass  : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex        : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year       : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\n\n\nReordering Levels of a Factors Based on a Condition Using forcats\nPerhaps we want to reorder levels based on some condition, perhaps the ordering levels by frequency, or perhaps by the another summary statistic (which could be useful for effective data visualization!). We can easily do so using the forcats package. Let‚Äôs look again at the original penguins data set and look at the frequency of each species using ggplot:\n\nggplot(penguins, aes(x = species, fill = species)) + #use species variable (no y needed)\n  geom_bar() + #draw a bar chart \n  theme(legend.position = \"none\")  + #remove redundant legend\n  xlab(\"Species\") + #add x axis label\n  ylab(\"Count\") + # add y axis label\n  ggtitle(\"Penguin Species Frequencies\") #add a title\n\n\n\n\n\n\n\n\nThis data visualization is fine. But there‚Äôs one step we can do to make it even better: order bars by largest to smallest (or smallest to largest) so readers can easily spot which species is the most common. This is especially useful when the number of levels is large!\nWe can do this in two ways: edit the original tibble to have new factor ordering, or order the factors directly in the ggplot2 call so that the original tibble isn‚Äôt overwritted. We will show both ways. We will use the forcats package in both examples.\nOption A: Reorder Tibble Directly\nTo reorder the factor levels according to the frequency in the tibble, we can use fct_reorder():\n\npenguins4 &lt;- penguins #initialize a new dataset we will overwrite, save original\npenguins4$species &lt;- penguins$species %&gt;% #overwrite species in penguins4\n  fct_infreq() #relevel the factor by frequency\n\nlevels(penguins4$species)\n\n[1] \"Adelie\"    \"Gentoo\"    \"Chinstrap\"\n\n\nWe see the ordering is Adelie, Gentoo, and then Chinstrap. If you look at the previous plot, you‚Äôll see that these are ordered from smallest to largest frequencies. The original ordering was alphabetical.\nTo order from smallest to largest, we had fct_rev() to the chain:\n\npenguins4$species &lt;- penguins4$species %&gt;%\n  fct_infreq() %&gt;% #relevel the factor by frequency\n  fct_rev()\n\nlevels(penguins4$species)\n\n[1] \"Chinstrap\" \"Gentoo\"    \"Adelie\"   \n\n\nNow the levels are reversed!\nWe can then plot our data using penguins4:\n\nggplot(penguins4, aes(x = species, fill = species)) + #use species variable (no y needed)\n  geom_bar() + #draw a bar chart \n  theme(legend.position = \"none\")  + #remove redundant legend  \n  xlab(\"Species\") + #add x axis label\n  ylab(\"Count\") + # add y axis label\n  ggtitle(\"Penguin Species Frequencies\") #add a title\n\n\n\n\n\n\n\n\nOf course, an even better visualization would involve flipping the axes:\n\nggplot(penguins4, aes(x = species, fill = species)) + #use species variable (no y needed)\n  geom_bar() + #draw a bar chart \n  theme(legend.position = \"none\")  + #remove redundant legend  \n  xlab(\"Species\") + #add x axis label\n  ylab(\"Count\") + # add y axis label\n  ggtitle(\"Penguin Species Frequencies\") + #add a title\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt may look like they are ordered from largest to smallest, but they are actually ordered from smallest to largest. When flipped, ggplot puts the first level on the bottom.\n\n\nOption B: Reorder the Factor in the ggplot Call\nWe can do these steps directly in ggplot without overwriting or making a new tibble!\n\npenguins %&gt;% #this is the original data frame with alphabetical ordering\n  mutate(species = species %&gt;%\n           fct_infreq() %&gt;% #order by frequency\n           fct_rev()) %&gt;%  #reverse ordering\n  ggplot( aes(x = species, fill = species)) + #no longer specify the data set in ggplot() as this is passed in by the pipe %&gt;%\n    geom_bar() + \n    theme(legend.position = \"none\")  +\n    xlab(\"Species\") + \n    ylab(\"Count\") + \n    ggtitle(\"Penguin Species Frequencies\") + \n    coord_flip()\n\n\n\n\n\n\n\n\nWe get the exact same plot with a single chunk of code! And, the original tibble penguins remains unchanged with the alphabetical ordering of the species factors.\n\nlevels(penguins$species)\n\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n\n\n\n\n\n\n\nExercise\n\n\n\nThe gapminder dataset contains information on GDP per capita (gdpPercap) by country. Add to the following ggplot to visualize the GDP per capita, ordered by GDP per capita, for countries in Asia in 2007. Copy the code block to edit and run it in R.\nlibrary(gapminder)\nlibrary(tidyverse)\n\ngapminder %&gt;%\n  filter( ) %&gt;% #FILL THIS IN: filter by countries in Asia\n  mutate() %&gt;% #FILL THIS IN: change ordering of country by gdpPercap\n  ggplot(aes(country, gdpPercap)) + \n    geom_point() + \n    coord_flip() + \n    scale_y_continuous(\"GDP per Capita, 2007\", labels = scales::dollar_format()) + \n    xlab(\"Country\")\n  \n\n\nAnswer below! No peaking until you‚Äôve attempted this problem!\n\ngapminder %&gt;%\n  filter(continent == \"Asia\", year == 2007) %&gt;% #filter by countries in Asia\n  mutate(country = fct_reorder(country, gdpPercap)) %&gt;% #change ordering of country by gdpPercap\n  ggplot(aes(country, gdpPercap)) + \n    geom_point() + \n    coord_flip() + \n    scale_y_continuous(\"GDP per Capita, 2007\", labels = scales::dollar_format()) + \n    xlab(\"Country\")\n\n\n\n\n\n\n\n\n\n\n\nExpanding Factor Levels\nPerhaps we may want to visualize that in our data set, there are no Emperor or King penguins. To do so, we can add ‚ÄúEmperor‚Äù and ‚ÄúKing‚Äù as possible factor levels for species in our penguins data set. We do so by fct_expand()\n\npenguins %&gt;% #this is the original data frame with alphabetical ordering\n  mutate(species = species %&gt;%\n           fct_expand(\"King\", \"Emperor\") %&gt;% #NEW: expand levels to include king and emperor\n           fct_infreq() %&gt;% \n           fct_rev()\n           ) %&gt;%  \n  ggplot( aes(x = species, fill = species)) + \n    geom_bar() + \n    theme(legend.position = \"none\")  +\n    xlab(\"Species\") + \n    ylab(\"Count\") + \n    ggtitle(\"Penguin Species Frequencies\") + \n    coord_flip() + \n    scale_x_discrete(drop = FALSE) #NEW: do not drop empty factor levels\n\n\n\n\n\n\n\n\nNow we add to the visualization that there were no King or Emperor penguins collected in the data.\n\nRemoving Factor Levels\nLet‚Äôs suppose we were only interested in comparing Adelie and Chinstrap penguins. We could drop the Gentoo level using forcats by:\n\npenguins_no_gentoo &lt;- penguins %&gt;%\n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;%\n  droplevels()\n\nlevels(penguins_no_gentoo$species)\n\n[1] \"Adelie\"    \"Chinstrap\"\n\n\nWe can also do this along with the ggplot call by:\n\npenguins %&gt;% #this is the original data frame with alphabetical ordering\n  mutate(species = species %&gt;%\n\n           fct_infreq() %&gt;% \n           fct_rev()\n           ) %&gt;%  \n  filter(species %in% c(\"Adelie\", \"Chinstrap\")) %&gt;% #NEW: filter only these species\n  droplevels() %&gt;% #NEW: drop if not adelie or chinstrap species\n  ggplot( aes(x = species, fill = species)) + \n    geom_bar() + \n    theme(legend.position = \"none\")  +\n    xlab(\"Species\") + \n    ylab(\"Count\") + \n    ggtitle(\"Penguin Species Frequencies\") + \n    coord_flip() + \n    scale_x_discrete(drop = FALSE) #NEW: do not drop empty factor levels",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#dates-and-times",
    "href": "webpages/lectures_i/lec6b_dates.html#dates-and-times",
    "title": "Lecture 6B: Factors and Dates",
    "section": "Dates and Times",
    "text": "Dates and Times\nOften you will need to work with dates and times in your data. For example, we could have had a variable in the FEV data set that contains the date of each patient visit.\nDates and times seem simple, but they are actually one of the most complicated things you will encounter in data analysis. Why? Think about this:\n\nAre there 365 days in every year?\nAre there 30 days in every month?\nAre there 24 hours in every day?\n\nThe answer to all of these questions is NO. What a headache this can be when trying to compute how much time has elapsed between two date/times!\nThe lubridate package can help us with a lot of the headaches that dates and times cause. It can create date and time objects from different inputs, extract important pieces of information like year/month/day, do hard math with dates and times, and help you navigate time zones.",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#nyc-flights-case-study",
    "href": "webpages/lectures_i/lec6b_dates.html#nyc-flights-case-study",
    "title": "Lecture 6B: Factors and Dates",
    "section": "NYC Flights Case Study",
    "text": "NYC Flights Case Study\nWe‚Äôll show off how to use the lubridate package in the tidyverse to work with date variables in datasets in this NYC Flights case study.\nFor the sake of time, we‚Äôll just go over the solutions together, instead of having you attempt exercises on your own first. We think this will be sufficient to get a hang of the basics of lubridate. That being said, want extra practice? Then check out the R4DS Dates and Times Chapter!",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#worksheet-a5",
    "href": "webpages/lectures_i/lec6b_dates.html#worksheet-a5",
    "title": "Lecture 6B: Factors and Dates",
    "section": "Worksheet A5",
    "text": "Worksheet A5\nTry your hand at using factors by working through the factors portion of Worksheet A5.\nFinished attempting all of the questions? Then do the optional R4DS Factors reading, and maybe even do some of the exercises for extra practice.",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6b_dates.html#additional-resources",
    "href": "webpages/lectures_i/lec6b_dates.html#additional-resources",
    "title": "Lecture 6B: Factors and Dates",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nVideo lecture: Special Data Types in R: Dates, Times, and Factors\nChapter IV of https://stat545.com/\nThe forcats package page and reference guide on page.\nThe R4DS chapter on Dates and Times\nThe tsibble vignette to learn more about embedding a time series within a tibble.",
    "crumbs": [
      "Lecture 6B: Factors and Dates"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7a_readwritedata.html",
    "href": "webpages/lectures_i/lec7a_readwritedata.html",
    "title": "Lecture 7A: Reading and Writing Data",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nRead and write a delimited file, like a csv, from R using the readr package.\nMake relative paths using the here::here() function.\nRead data from a spreadsheet\nRead and write R binary files (rds files) from R.\n\nRequired packages:\n\nlibrary(tidyverse)\nlibrary(here)\n\n\n\n\n\n\n\nImportant\n\n\n\nIn some of the eariler examples, I will be demonstrating using absolute and relative file paths. On Mac OS, files are written with forward slashes (i.e., datasets/penguins.csv). On Windows, backslashes are used (i.e., datasets\\penguins.csv). My examples are writted for MacOS - the only thing you‚Äôd need to change in the examples are the direction of the slashes if you plan to reproduce my code!\nLater in the lecture, we discuss the here::here() function which solves this problem completely.\n\n\nCommon file formats include\n\nSpreadsheets: Excel, Google Sheets, Numbers\nDelimited files: Plaintext files containing data, e.g.¬†comma separated values (CSVs), tab separated values (TSVs)\nR binary: A serialization of an R object to a binary file. Basically, that means that it can be loaded in and out of R, but it can‚Äôt be opened by anything but R.\n\nCSVs are the most ‚Äúone-size-fits-all‚Äù: you can open them in spreadsheet software, but they are also plaintext, so are lightweight, can be opened in any text editor, and can be ‚Äúdiff‚Äùed.¬†Spreadsheets are nice for human interaction (like through Excel), but can be clunky in R. R binary is quite restrictive and we don‚Äôt tend to store data this way. Our lecture will focus on CSVs.\n\n\nJenny Bryan‚Äôs website has a fabulous section on reading and writing files in R. We‚Äôre going to summarize a few of the important functions here, but if you‚Äôd like to learn more then check out that website for more in-depth explorations!\nWe are going to focus on reading and writing data using the readr package, because we think it has the most ‚Äúwork right out of the box‚Äù experience.\nWe will start by talking about how to read and write Comma Separated Value (CSV) files (files that end in .csv). CSVs are often used to store data. When the penguins data set is stored as a .csv, the first few entries look like when opened as a text file:\nspecies,island,bill_len,bill_dep,flipper_len,body_mass,sex,year\nAdelie,Torgersen,39.1,18.7,181,3750,male,2007 Adelie,Torgersen,39.5,17.4,186,3800,female,2007 Adelie,Torgersen,40.3,18,195,3250,female,2007 Adelie,Torgersen,NA,NA,NA,NA,NA,2007 Adelie,Torgersen,36.7,19.3,193,3450,female,2007 Adelie,Torgersen,39.3,20.6,190,3650,male,2007 Adelie,Torgersen,38.9,17.8,181,3625,female,2007 Adelie,Torgersen,39.2,19.6,195,4675,male,2007\nNow, this isn‚Äôt exactly easy for humans to read, but saving data as CSVs has its advantages. The data is stored in a simple form (lightweight - files aren‚Äôt large) that has broad compatibility and can be used in a wide range of applications. And of course, we can use functions in R to make it more readable. A few main functions of note are\n\nread_csv(): tidyverse equivalent of read.csv() used to read from a CSV to a tibble\nwrite_csv(): tidyverse equivalent of write.csv() used to export a tibble into CSV format\n\nLet‚Äôs assume that a file called penguins.csv is saved in a dataset folder in our current directory. We can read in, and save the tibble as a variable called penguins using:\n\npenguins &lt;- read_csv(\"datasets/penguins.csv\")\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_len, bill_dep, flipper_len, body_mass, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins)\n\n# A tibble: 6 √ó 8\n  species island    bill_len bill_dep flipper_len body_mass sex     year\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie  Torgersen     39.1     18.7         181      3750 male    2007\n2 Adelie  Torgersen     39.5     17.4         186      3800 female  2007\n3 Adelie  Torgersen     40.3     18           195      3250 female  2007\n4 Adelie  Torgersen     NA       NA            NA        NA &lt;NA&gt;    2007\n5 Adelie  Torgersen     36.7     19.3         193      3450 female  2007\n6 Adelie  Torgersen     39.3     20.6         190      3650 male    2007\n\n\nPretty easy! Note that the file path needs to be a string, relative to where you are now in the directory (i.e., where the R script you‚Äôre working on is saved. You can always call getwd() to see what directory you‚Äôre working on currently, and we‚Äôll show more tools for dealing with directories later in this lecture.)\nWe can manipulate the data, and save the output as a new CSV. For example,\n\npenguins_2007 &lt;- penguins %&gt;%\n  filter(year == 2007) #filter only on year 2007\n\nwrite_csv(penguins_2007, \"datasets/penguins_2007.csv\") #save csv in datasets folder, name as penguins_2007.csv\n\nNow, in my datasets folder, I have penguins and penguins_2007.\n\n\n\n\n\n\nNote\n\n\n\nWant to read and write to an Excel file? The readxl package in the tidyverse is for you!\nFor the very niche option of R binary: read_rds() and write_rds().\n\n\n\n\n\nAs previously mentioned, we need to specify where we are reading/writing our data from/to. The best practice is to use a relative path. This helps with reproducibility and automation!\nI could always read in my penguins dataset using an absolute file path where the file path begins at the root of your computer (for me, it is a long chain of folders in /Users/......../STAT545/stat454.github.io/webpages/lectures_i/datasets/penguins.csv). This, however, is not best practice. As previously mentioned, this string telling me where the file path is can also differ for Windows users! I‚Äôd have to manually change all of the forward slashes to backslashes to make this run on Windows.\nWe will use the here package for relative file paths. Let‚Äôs (install, if necessary, and) load it and call the function here()\n\n\n# install.packages(\"here\")\nlibrary(here)\nhere()\n\n[1] \"/Users/gracetompkins/Library/CloudStorage/OneDrive-UBC/Teaching/STAT545/STAT545.github.io\"\n\n\nI get that long chain of folders where this R Project (which I used to build this website) is stored. The cool thing about here is that I can specify a file path relative to my project root (the above location) without using any operating system-specific strings.\nFor example, the penguins.csv data set is located in webpages &gt; lectures_i &gt; datasets within my R project folder. I can access it by:\n\npenguins &lt;- read_csv(here(\"webpages\", \"lectures_i\", \"datasets\", \"penguins.csv\"))\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_len, bill_dep, flipper_len, body_mass, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins) #view first few entries of the tibble\n\n# A tibble: 6 √ó 8\n  species island    bill_len bill_dep flipper_len body_mass sex     year\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie  Torgersen     39.1     18.7         181      3750 male    2007\n2 Adelie  Torgersen     39.5     17.4         186      3800 female  2007\n3 Adelie  Torgersen     40.3     18           195      3250 female  2007\n4 Adelie  Torgersen     NA       NA            NA        NA &lt;NA&gt;    2007\n5 Adelie  Torgersen     36.7     19.3         193      3450 female  2007\n6 Adelie  Torgersen     39.3     20.6         190      3650 male    2007\n\n\nThis is reproducible!",
    "crumbs": [
      "Lecture 7A: Reading and Writing Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7a_readwritedata.html#reading-and-writing-data-in-r",
    "href": "webpages/lectures_i/lec7a_readwritedata.html#reading-and-writing-data-in-r",
    "title": "Lecture 7A: Reading and Writing Data",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nRead and write a delimited file, like a csv, from R using the readr package.\nMake relative paths using the here::here() function.\nRead data from a spreadsheet\nRead and write R binary files (rds files) from R.\n\nRequired packages:\n\nlibrary(tidyverse)\nlibrary(here)\n\n\n\n\n\n\n\nImportant\n\n\n\nIn some of the eariler examples, I will be demonstrating using absolute and relative file paths. On Mac OS, files are written with forward slashes (i.e., datasets/penguins.csv). On Windows, backslashes are used (i.e., datasets\\penguins.csv). My examples are writted for MacOS - the only thing you‚Äôd need to change in the examples are the direction of the slashes if you plan to reproduce my code!\nLater in the lecture, we discuss the here::here() function which solves this problem completely.\n\n\nCommon file formats include\n\nSpreadsheets: Excel, Google Sheets, Numbers\nDelimited files: Plaintext files containing data, e.g.¬†comma separated values (CSVs), tab separated values (TSVs)\nR binary: A serialization of an R object to a binary file. Basically, that means that it can be loaded in and out of R, but it can‚Äôt be opened by anything but R.\n\nCSVs are the most ‚Äúone-size-fits-all‚Äù: you can open them in spreadsheet software, but they are also plaintext, so are lightweight, can be opened in any text editor, and can be ‚Äúdiff‚Äùed.¬†Spreadsheets are nice for human interaction (like through Excel), but can be clunky in R. R binary is quite restrictive and we don‚Äôt tend to store data this way. Our lecture will focus on CSVs.\n\n\nJenny Bryan‚Äôs website has a fabulous section on reading and writing files in R. We‚Äôre going to summarize a few of the important functions here, but if you‚Äôd like to learn more then check out that website for more in-depth explorations!\nWe are going to focus on reading and writing data using the readr package, because we think it has the most ‚Äúwork right out of the box‚Äù experience.\nWe will start by talking about how to read and write Comma Separated Value (CSV) files (files that end in .csv). CSVs are often used to store data. When the penguins data set is stored as a .csv, the first few entries look like when opened as a text file:\nspecies,island,bill_len,bill_dep,flipper_len,body_mass,sex,year\nAdelie,Torgersen,39.1,18.7,181,3750,male,2007 Adelie,Torgersen,39.5,17.4,186,3800,female,2007 Adelie,Torgersen,40.3,18,195,3250,female,2007 Adelie,Torgersen,NA,NA,NA,NA,NA,2007 Adelie,Torgersen,36.7,19.3,193,3450,female,2007 Adelie,Torgersen,39.3,20.6,190,3650,male,2007 Adelie,Torgersen,38.9,17.8,181,3625,female,2007 Adelie,Torgersen,39.2,19.6,195,4675,male,2007\nNow, this isn‚Äôt exactly easy for humans to read, but saving data as CSVs has its advantages. The data is stored in a simple form (lightweight - files aren‚Äôt large) that has broad compatibility and can be used in a wide range of applications. And of course, we can use functions in R to make it more readable. A few main functions of note are\n\nread_csv(): tidyverse equivalent of read.csv() used to read from a CSV to a tibble\nwrite_csv(): tidyverse equivalent of write.csv() used to export a tibble into CSV format\n\nLet‚Äôs assume that a file called penguins.csv is saved in a dataset folder in our current directory. We can read in, and save the tibble as a variable called penguins using:\n\npenguins &lt;- read_csv(\"datasets/penguins.csv\")\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_len, bill_dep, flipper_len, body_mass, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins)\n\n# A tibble: 6 √ó 8\n  species island    bill_len bill_dep flipper_len body_mass sex     year\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie  Torgersen     39.1     18.7         181      3750 male    2007\n2 Adelie  Torgersen     39.5     17.4         186      3800 female  2007\n3 Adelie  Torgersen     40.3     18           195      3250 female  2007\n4 Adelie  Torgersen     NA       NA            NA        NA &lt;NA&gt;    2007\n5 Adelie  Torgersen     36.7     19.3         193      3450 female  2007\n6 Adelie  Torgersen     39.3     20.6         190      3650 male    2007\n\n\nPretty easy! Note that the file path needs to be a string, relative to where you are now in the directory (i.e., where the R script you‚Äôre working on is saved. You can always call getwd() to see what directory you‚Äôre working on currently, and we‚Äôll show more tools for dealing with directories later in this lecture.)\nWe can manipulate the data, and save the output as a new CSV. For example,\n\npenguins_2007 &lt;- penguins %&gt;%\n  filter(year == 2007) #filter only on year 2007\n\nwrite_csv(penguins_2007, \"datasets/penguins_2007.csv\") #save csv in datasets folder, name as penguins_2007.csv\n\nNow, in my datasets folder, I have penguins and penguins_2007.\n\n\n\n\n\n\nNote\n\n\n\nWant to read and write to an Excel file? The readxl package in the tidyverse is for you!\nFor the very niche option of R binary: read_rds() and write_rds().\n\n\n\n\n\nAs previously mentioned, we need to specify where we are reading/writing our data from/to. The best practice is to use a relative path. This helps with reproducibility and automation!\nI could always read in my penguins dataset using an absolute file path where the file path begins at the root of your computer (for me, it is a long chain of folders in /Users/......../STAT545/stat454.github.io/webpages/lectures_i/datasets/penguins.csv). This, however, is not best practice. As previously mentioned, this string telling me where the file path is can also differ for Windows users! I‚Äôd have to manually change all of the forward slashes to backslashes to make this run on Windows.\nWe will use the here package for relative file paths. Let‚Äôs (install, if necessary, and) load it and call the function here()\n\n\n# install.packages(\"here\")\nlibrary(here)\nhere()\n\n[1] \"/Users/gracetompkins/Library/CloudStorage/OneDrive-UBC/Teaching/STAT545/STAT545.github.io\"\n\n\nI get that long chain of folders where this R Project (which I used to build this website) is stored. The cool thing about here is that I can specify a file path relative to my project root (the above location) without using any operating system-specific strings.\nFor example, the penguins.csv data set is located in webpages &gt; lectures_i &gt; datasets within my R project folder. I can access it by:\n\npenguins &lt;- read_csv(here(\"webpages\", \"lectures_i\", \"datasets\", \"penguins.csv\"))\n\nRows: 344 Columns: 8\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_len, bill_dep, flipper_len, body_mass, year\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(penguins) #view first few entries of the tibble\n\n# A tibble: 6 √ó 8\n  species island    bill_len bill_dep flipper_len body_mass sex     year\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 Adelie  Torgersen     39.1     18.7         181      3750 male    2007\n2 Adelie  Torgersen     39.5     17.4         186      3800 female  2007\n3 Adelie  Torgersen     40.3     18           195      3250 female  2007\n4 Adelie  Torgersen     NA       NA            NA        NA &lt;NA&gt;    2007\n5 Adelie  Torgersen     36.7     19.3         193      3450 female  2007\n6 Adelie  Torgersen     39.3     20.6         190      3650 male    2007\n\n\nThis is reproducible!",
    "crumbs": [
      "Lecture 7A: Reading and Writing Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7a_readwritedata.html#section",
    "href": "webpages/lectures_i/lec7a_readwritedata.html#section",
    "title": "Lecture 7A: Reading and Writing Data",
    "section": "",
    "text": "Exercise\n\n\n\nOpen RStudio. Go to Session =&gt; Set Working Directory =&gt; Choose Directory and then pick a folder you would like to read and write data into. Then, run the following piece of code in a new R Script:\nlibrary(tidyverse) \nlibrary(gapminder)\n\ngap_asia_2007 &lt;- gapminder %&gt;% \n  filter(year == 2007, continent == \"Asia\")\nhead(gap_asia_2007)\nWrite gap_asia_2007 to a comma-separated value (csv) file named exported_file.csv with just one command:\nwrite_csv(FILL_THIS_IN, \"exported_file.csv\")\nCheck out your files after executing this line!\nNow, let‚Äôs practice reading csvs by reading the file we just wrote back into R:\ngap_asia_2007_in &lt;- read_csv(\"FILL_THIS_IN\")\nCheck out your R environment after executing this line!\nAlso notice the output of running read_csv. This tells us about the types of variables that were read in. It‚Äôs a good habit to check this every time you run a read_ function. Sometimes we might want to change how these variable types are specified.",
    "crumbs": [
      "Lecture 7A: Reading and Writing Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7a_readwritedata.html#resources",
    "href": "webpages/lectures_i/lec7a_readwritedata.html#resources",
    "title": "Lecture 7A: Reading and Writing Data",
    "section": "Resources",
    "text": "Resources\n\nVideo lecture: Reading and Writing Data\nThe ‚ÄúWriting and Reading files‚Äù chapter of stat545.com.",
    "crumbs": [
      "Lecture 7A: Reading and Writing Data"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html",
    "title": "Lecture 7B: Tibble Joins",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\nWe will require the tidyverse functions for this chapter:\n# install.packages(\"tidyverse\")\nlibrary(tidyverse)",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#overview-of-join-functions",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#overview-of-join-functions",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Overview of join functions",
    "text": "Overview of join functions\nNote: In order to merge two tibbles, you need to have an identifier variable that has unique values for every row of observations in both tibbles.\nCreate two sample tibbles:\n\n# First tibble\ndf1 &lt;- tibble(ID = 1:3,                     \n              Name = c(\"Sophie\", \"Josh\",\"Alex\"))\n\n# Second tibble\ndf2 &lt;- tibble(ID = 2:4,                      \n              Age = c(20,50,31))",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#mutating-joins",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#mutating-joins",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Mutating joins",
    "text": "Mutating joins\n\nJoin matching rows from df2 to df1\n\n\n\n\n\n\nleft_join(df1, df2, by = \"ID\")\n\n# A tibble: 3 √ó 3\n     ID Name     Age\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 Sophie    NA\n2     2 Josh      20\n3     3 Alex      50\n\n\n\n\nJoin matching rows from df1 to df2\n\n\n\n\n\n\nright_join(df1, df2, by = \"ID\")\n\n# A tibble: 3 √ó 3\n     ID Name    Age\n  &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n1     2 Josh     20\n2     3 Alex     50\n3     4 &lt;NA&gt;     31\n\n\n\n\nRetain only rows present in both sets\n\n\n\n\n\n\ninner_join(df1, df2, by = \"ID\")\n\n# A tibble: 2 √ó 3\n     ID Name    Age\n  &lt;int&gt; &lt;chr&gt; &lt;dbl&gt;\n1     2 Josh     20\n2     3 Alex     50\n\n\n\n\nRetain all values, all rows\n\n\n\n\n\n\nfull_join(df1, df2, by = \"ID\")\n\n# A tibble: 4 √ó 3\n     ID Name     Age\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 Sophie    NA\n2     2 Josh      20\n3     3 Alex      50\n4     4 &lt;NA&gt;      31",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#filtering-joins",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#filtering-joins",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Filtering joins",
    "text": "Filtering joins\n\nRetain all rows in df1 that have a match in df2\n\n\n\n\n\n\nsemi_join(df1, df2, by = \"ID\")\n\n# A tibble: 2 √ó 2\n     ID Name \n  &lt;int&gt; &lt;chr&gt;\n1     2 Josh \n2     3 Alex \n\n\n\n\nRetain all rows in df1 that do not have a match in df2\n\n\n\n\n\n\nanti_join(df1, df2, by = \"ID\")\n\n# A tibble: 1 √ó 2\n     ID Name  \n  &lt;int&gt; &lt;chr&gt; \n1     1 Sophie",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#binding",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#binding",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Binding",
    "text": "Binding\n\nAppend df2 to df1 as new rows\n\n\n\n\n\n\nbind_rows(df1, df2)\n\n# A tibble: 6 √ó 3\n     ID Name     Age\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 Sophie    NA\n2     2 Josh      NA\n3     3 Alex      NA\n4     2 &lt;NA&gt;      20\n5     3 &lt;NA&gt;      50\n6     4 &lt;NA&gt;      31\n\n\n\n\nAppend df2 to df1 as new columns\n\n\n\n\n\n\nbind_cols(df1, df2)\n\nNew names:\n‚Ä¢ `ID` -&gt; `ID...1`\n‚Ä¢ `ID` -&gt; `ID...3`\n\n\n# A tibble: 3 √ó 4\n  ID...1 Name   ID...3   Age\n   &lt;int&gt; &lt;chr&gt;   &lt;int&gt; &lt;dbl&gt;\n1      1 Sophie      2    20\n2      2 Josh        3    50\n3      3 Alex        4    31",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-multiple-2-tibbles",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-multiple-2-tibbles",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Joining multiple (>2) tibbles",
    "text": "Joining multiple (&gt;2) tibbles\nCreate a third tibble\n\ndf3 &lt;- tibble(ID = 1:5,                      \n              Height = c(175,167,190,155,160))\n\n\n\n\n\n\nUse piping operator (%&gt;%) to layer multiple join functions\n\nfull_join(df1, df2, by = \"ID\") %&gt;%\n  full_join(df3, by = \"ID\") \n\n# A tibble: 5 √ó 4\n     ID Name     Age Height\n  &lt;int&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     1 Sophie    NA    175\n2     2 Josh      20    167\n3     3 Alex      50    190\n4     4 &lt;NA&gt;      31    155\n5     5 &lt;NA&gt;      NA    160",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-tibbles-on-multiple-conditions",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-tibbles-on-multiple-conditions",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Joining tibbles on multiple conditions",
    "text": "Joining tibbles on multiple conditions\n\n\n\n\n\nCreate two new tibbles df4 and df5\n\ndf4 &lt;- tibble(FirstName = c(\"Sophie\", \"Josh\",\"Alex\"),\n              LastName=c(\"Wang\",\"Smith\",\"Smith\"),\n              Age = c(42,20,50))\n\ndf5 &lt;- tibble(First_name = c(\"Josh\",\"Alex\",\"Sophie\"),        \n              Last_name=c(\"Smith\",\"Smith\",\"Jones\"),\n              Height = c(167,190,155))\n\n\n\n\n\n\n\nfull_join(df4, df5, by = c(\"FirstName\" = \"First_name\", \"LastName\" = \"Last_name\"))\n\n# A tibble: 4 √ó 4\n  FirstName LastName   Age Height\n  &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 Sophie    Wang        42     NA\n2 Josh      Smith       20    167\n3 Alex      Smith       50    190\n4 Sophie    Jones       NA    155",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#set-operations",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#set-operations",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Set operations",
    "text": "Set operations\nCreate sample tibbles\n\n\n\n\n\n\n# First tibble\ndf6 &lt;- tibble(Number = 1:3,                     \n              Letter = c(\"A\", \"B\",\"C\"))\n\n# Second tibble\ndf7 &lt;- tibble(Number = 2:4,                      \n              Letter = c(\"B\",\"C\",\"D\"))\n\n\nInclude rows that appear in both tibbles\n\n\n\n\n\n\n# First tibble\ndf6 &lt;- tibble(Number = 1:3,                     \n              Letter = c(\"A\", \"B\",\"C\"))\n\n# Second tibble\ndf7 &lt;- tibble(Number = 2:4,                      \n              Letter = c(\"B\",\"C\",\"D\"))\n\n\n\nInclude rows that appear in either or both tibbles\n\n\n\n\n\n\nunion(df6, df7)\n\n# A tibble: 4 √ó 2\n  Number Letter\n   &lt;int&gt; &lt;chr&gt; \n1      1 A     \n2      2 B     \n3      3 C     \n4      4 D     \n\n\n\n\nInclude rows that appear in one tibble/dataset but not another\n\n\n\n\n\nInclude rows that appear in df6 but not in df7\n\nsetdiff(df6, df7)\n\n# A tibble: 1 √ó 2\n  Number Letter\n   &lt;int&gt; &lt;chr&gt; \n1      1 A     \n\n\nInclude rows that appear in df7 but not in df6\n\nsetdiff(df7, df6)\n\n# A tibble: 1 √ó 2\n  Number Letter\n   &lt;int&gt; &lt;chr&gt; \n1      4 D",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-tibbles-with-different-types-of-variables",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#joining-tibbles-with-different-types-of-variables",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Joining tibbles with different types of variables",
    "text": "Joining tibbles with different types of variables\nYou can also join tibbles with sets of predictions:\n\nset.seed(1) #make reproducible\n\nx &lt;- rnorm(5) #randomly sample 5 times from a N(0,1) distribution\n\nmodel1 &lt;- tibble(x = x, yhat = 2.1 + 3.2 * x) #do prediction based on the linear function\nmodel2 &lt;- tibble(x = x, yhat = 1.5 + 2.9 * x)\n\nleft_join(model1, model2, by = \"x\")\n\n# A tibble: 5 √ó 3\n       x  yhat.x yhat.y\n   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 -0.626  0.0953 -0.317\n2  0.184  2.69    2.03 \n3 -0.836 -0.574  -0.923\n4  1.60   7.20    6.13 \n5  0.330  3.15    2.46",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#worksheet-a5",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#worksheet-a5",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Worksheet A5",
    "text": "Worksheet A5\nTry your hand at basics of tibble joins by working through the corresponding part of Worksheet A5.\nThere will be some class time to go over solutions if you got stuck on any questions.",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec7b_joiningtibbles.html#resources",
    "href": "webpages/lectures_i/lec7b_joiningtibbles.html#resources",
    "title": "Lecture 7B: Tibble Joins",
    "section": "Resources",
    "text": "Resources\n\nVideo lecture: Tibble Joins with dplyr\n‚ÄúRelational Data‚Äù chapter in ‚ÄúR for Data Science‚Äù.\n‚ÄúTwo-table verbs‚Äù vignette gives a concise overview of tibble joins with dplyr.\nJenny‚Äôs Join Cheatsheet for a quick reference to joins.\ndplyr cheatsheet for all these concepts packed onto a sheet of paper.",
    "crumbs": [
      "Lecture 7B: Tibble Joins"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec8b_advfunctions.html",
    "href": "webpages/lectures_ii/lec8b_advfunctions.html",
    "title": "Lecture 8b: Advanced Functions",
    "section": "",
    "text": "We will learn about a couple of advanced topics:\n\nData-masking and the curly-curly {{}}\nDefault values\nEllipses ...\nHandling NA‚Äôs\n\nThese topics are covered in the R4DS Functions book chapter as well. So if you miss this class, then the R4DS Functions reading is a good alternative.\nWe will be using the following packages throughout this lecture:\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\nlibrary(gapminder)\n\n\nExample: Counting Missing Values by Group\nHere‚Äôs some code that:\n\ngroups penguins by species, then summarizes the number of missing values in each variable.\ngroups gapminder by continent, then summarizes the number of missing values in each variable.\n\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarize(across(everything(), ~ sum(is.na(.x))))\n\n# A tibble: 3 √ó 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;      &lt;int&gt;          &lt;int&gt;         &lt;int&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie         0              1             1                 1           1\n2 Chinstrap      0              0             0                 0           0\n3 Gentoo         0              1             1                 1           1\n# ‚Ñπ 2 more variables: sex &lt;int&gt;, year &lt;int&gt;\n\n\n\ngapminder %&gt;% \n  group_by(continent) %&gt;% \n  summarize(across(everything(), ~ sum(is.na(.x))))\n\n# A tibble: 5 √ó 6\n  continent country  year lifeExp   pop gdpPercap\n  &lt;fct&gt;       &lt;int&gt; &lt;int&gt;   &lt;int&gt; &lt;int&gt;     &lt;int&gt;\n1 Africa          0     0       0     0         0\n2 Americas        0     0       0     0         0\n3 Asia            0     0       0     0         0\n4 Europe          0     0       0     0         0\n5 Oceania         0     0       0     0         0\n\n\nThese steps to summarize the data are quite similar! Instead of coding each step multiple times, let‚Äôs turn it into a function.\n\n\n\n\n\n\nExercise 1\n\n\n\nBy yourself or in small groups, try to turn the code above into a function called summarizeby_fun(). Document your code!\n\n\nWe will go over the solution in class.\n\n\nData-masking and the Curly-Curly {{}}\nSometimes your function needs to take in variable names without quotation marks and work with them that way.\nFor example, select(penguins, species) does not put quotation marks around lifeExp ‚Äì the reasoning being that lifeExp is like a variable in our workspace, if we were to include column names in our R Environment ‚Äì and select(\"penguins\", \"species\") will not do the same thing.\nIf your function needs to do this, then you need to work with the arguments with extra care inside the function definition. Whenever we use those arguments, we need to embrace them within two curly brackets ‚Äì an operator called ‚Äúcurly curly‚Äù.\nTake this function that produces a quick scatterplot between two columns in a dataset as an example.\nquick_scatter &lt;- function(data, x, y) {\n  ggplot(data, aes(x, y)) + #note curly brackets here!\n     geom_point()\n}\n\nquick_scatter(penguins, bill_length_mm, body_mass_g)\nError in `geom_point()`:\n! Problem while computing aesthetics.\n‚Ñπ Error occurred in the 1st layer.\nCaused by error:\n! object 'bill_length_mm' not found\nWhy doesn‚Äôt this work? The reason is that R is looking for variables named bill_len and body_mass in the workspace, and cannot find them. To fix the problem, we can change the function definition so that `x` and `y` are embraced within two curly brackets {{}} (‚Äúcurly curly‚Äù):\n\nquick_scatter &lt;- function(data, x, y) {\n  ggplot(data, aes({{ x }}, {{ y }})) + #note curly brackets here!\n     geom_point()\n}\n\nquick_scatter(penguins, bill_length_mm, body_mass_g)\n\n\n\n\n\n\n\n\nBut, you can only use curly-curly when passing your function‚Äôs argument to another function that‚Äôs anticipating a variable name without brackets.\n\n\n\n\n\n\nTip\n\n\n\nIn the `dplyr` documentation, if you spy the words ‚Äúdata masking‚Äù or ‚Äútidy selection‚Äù, then you will need to curly-curly your arguments when using those functions within your custom function.\n\n\n\n\n\n\n\n\nExercise 2\n\n\n\nMake a modification to our function summarizeby_fun(): allow the user to also pass in which variables they want to summarize. (Right now it just summarizes all of them.)\n\n\nWe will go over the solution in class.\n\n\nDefault Parameters\nRecall the dice-rolling example from the previous lecture. Sometimes you want to use a function frequently without re-writing the same parameters over and over again. Let‚Äôs make a more flexible function that allows us to change the number of faces on the dice being rolled.\n\n#' @details\n#' Simulates rolling `num_dice` number of dice with `n_sides` sides and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @param n_sides integer representing the number of sides of each dice\n#' @return the sum of the dice rolled\n  \nroll_dice &lt;- function(n_sides, num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum(sample(1:n_sides, num_dice, replace=TRUE)) #sample two numbers from one to n_sides with replacement, return sum\n}\n\nNotice now that in this function, there are two parameters (the new one is n_sides). We are also sampling from 1:nsides instead of 1:10 to make the function more flexible. I also renamed the function to roll_dice as we are not necessarily rolling d10 dice.\nSo to roll 2, 10-sided dice, I can call:\n\nroll_dice(n_sides = 10, num_dice = 2)\n\n[1] 9\n\n\nIf I wanted to make the default number of sides to 10, I can do that in the function()!\n\n#' @details\n#' Simulates rolling `num_dice` number of dice with `n_sides` sides and outputs the sum. Note: no seed is used so the function will return a dice combination each time it is run\n#'\n#' @param num_dice integer representing number of dice to be rolled\n#' @param n_sides integer representing the number of sides of each dice. Default is 10.\n#' @return the sum of the dice rolled\n  \nroll_dice &lt;- function(n_sides = 10, num_dice) { \n  \n    # throw an error if num_dice (the input) is not an integer\n  \n    if(num_dice %% 1 != 0){ #if num_dice mod 1 is NOT 0\n      stop(\"num_dice must be an integer\") #throw this error message and stop the function\n    }\n  \n    #if the num_dice is an integer, continue with the function:\n    sum(sample(1:n_sides, num_dice, replace=TRUE)) #sample two numbers from one to n_sides with replacement, return sum\n}\n\nWe have set n_sides = 10 as the default. This means the function will assume we have a 10 sided dice unless otherwise specified. Let‚Äôs roll 3 dice using 10 sided dice (the default):\n\nroll_dice(num_dice = 3)\n\n[1] 19\n\n\nI didn‚Äôt need to include n_sides = 10 in my function call! But I can if I want to change it to a number other than 10. Let‚Äôs roll 3 standard 6-sided dice\n\nroll_dice(n_sides = 6, num_dice = 3)\n\n[1] 12\n\n\n\n\n\n\n\n\nExercise 3\n\n\n\nMake a new argument for the summarizeby_fun() we made previously called .groups that makes it default to dropping the groups in the output.\n\n\n\n\nEllipses (...)\nThe ellipses allow a function to accept a variable number of additional unnamed arguments beyond what is explicitly written in the function. Many built-in functions have ... listed (check out c()!)\n\n\n\n\n\n\nInstructor Demo\n\n\n\nWe‚Äôll modify our function together using ellipses to get extra functionality: we‚Äôll allow the user to group by more than one variable.\n\n\n\n\nHandling NAs\nMissing data is essentially inevitable. Few studies are able to collect 100% of the data they intend to.\nMissing data can heavily complicate analyses and even lead to biased results when not handled properly. Missing data is a big research area in statistics! But for this class, we are going to focus on dealing with missing data using a simple example.\nLet‚Äôs look at the flipper length of penguins in the penguins data set and count how many missing values there are using the is.na() function in R. is.na(flipper_len) will return a vector full of TRUE or FALSE values indicating whether or not the observation was missing. As TRUE is coded as a 1 and FALSE as a 0, we can sum over these to count how many missing values there are.\n\nflipper_len &lt;- penguins$flipper_length_mm #save this data as its own vector\nsum(is.na(flipper_len)) # count how many NAs there are in the flipper data\n\n[1] 2\n\n\nWe see we have two missing values. Let‚Äôs see if we can summarize the quantiles of the lengths:\nquantile(flipper_len)\nError in quantile.default(flipper_length) :\nmissing values and NaN's not allowed if 'na.rm' is FALSE\nWe see here that missing values are not allowed unless we specify na.rm = TRUE. When na.rm = TRUE, we remove missing values from the data and then calculate the quantiles. This is also referred to as a complete case analysis.\n\nquantile(flipper_len, na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n 172  190  197  213  231 \n\n\nNow suppose we wanted to make our own function that utilized the quantile() built-in function:\n\n#' @details\n#' calculates the range of data by finding the 100th and 0th quantile and finding their difference\n#'\n#' @param vec a vector that we want to find the range of\n#' @return the difference in the maximum and minimum\n  \nget_range &lt;- function(vec){\n  quantiles &lt;- quantile(vec, na.rm = TRUE) #calc quantiles, remove NA's\n  return(max(quantiles) - min(quantiles)) #calculate and return the range\n}\n\nget_range(flipper_len)\n\n[1] 59\n\n\nWe could also include na.rm in our function parameters to allow the user to specify whether or not it should be set to TRUE or FALSE. We can use a default, as well.\n\n#' @details\n#' calculates the range of data by finding the 100th and 0th quantile and finding their difference\n#'\n#' @param vec a vector that we want to find the range of\n#' @param na.rm logical, whether or not to remove NAs. Default set to TRUE.\n#' @return the difference in the maximum and minimum\n  \nget_range &lt;- function(vec, na.rm = TRUE){\n  quantiles &lt;- quantile(vec, na.rm = na.rm) #calc quantiles, remove NA's\n  return(max(quantiles) - min(quantiles)) #calculate and return the range\n}\n\nget_range(flipper_len) #default to true\n\n[1] 59\n\n\n\n\nAttribution\nSome of these notes were originally compiled by previous iterations of the instructional staff, including Vincenzo Coia.",
    "crumbs": [
      "Lecture 8b: Advanced Functions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html",
    "href": "webpages/lectures_ii/lec9_rpackages.html",
    "title": "Lecture 9: R Packages",
    "section": "",
    "text": "From this topic, students are anticipated to be able to build a basic R package, especially using the devtools package.",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html#why-r-packages",
    "href": "webpages/lectures_ii/lec9_rpackages.html#why-r-packages",
    "title": "Lecture 9: R Packages",
    "section": "Why R Packages?",
    "text": "Why R Packages?\nAs mentioned in the ‚Äúfunctions‚Äù topic, your analysis will probably benefit from homemade functions: making functions forces you to think about your analysis in terms of its key computational parts, and makes for robust and readable code. Here are a few benefits that result by bundling these functions into an R package:\n\nOrganized documentation\nSharability\nBuilt-in checks to ensure your package is working\nTemplates for organizing your work\nEasy way to share datasets\n\nThe alternative is keeping the functions stored in separate files, and source()ing them into your analysis scripts, but this can become unwieldy. Plus, if your package becomes really nice, you might want to share it with the world!\nFor this topic, we‚Äôll be making an R package like the toy square package, by following along with ‚ÄúThe Whole Game‚Äù Chapter of ‚ÄúR packages‚Äù. Here‚Äôs a checklist based on that chapter. If you miss class, check out How to Make an R Package video lecture, then try following along using the book, and coming to office hours or asking questions on Slack if you get stuck.\n\n\n\n\n\n\nTip\n\n\n\nMany of the functions we call are from the devtools package in R. If you‚Äôre getting errors when trying to run some commands, try reloading devtools in the Console by running library(devtools).",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html#minimal-working-example",
    "href": "webpages/lectures_ii/lec9_rpackages.html#minimal-working-example",
    "title": "Lecture 9: R Packages",
    "section": "Minimal Working Example",
    "text": "Minimal Working Example\nFirst, make a minimal viable product:\n\nIn any R console, install (if necessary) and load the devtools package in the console (do this every time you go to work on your package).\n\nYou will create a new R Project in the next step, so don‚Äôt worry about the location now.\n\nRun create_package() in the console (NOTE: all devtools functions should be written in the console).\n\nBetter defaults than going through the File menu.\nSet the file path to be wherever you‚Äôd like the package to live. I‚Äôll be saving it on my desktop in a (not yet created) folder called ‚Äúpowers‚Äù by calling create_package(\"~/Desktop/powers\")\nAllow access if a pop-up appears, and RStudio will refresh to your new Project.\nIf you look at the new folder that was created (mine is on my desktop), you‚Äôll see an R Project, a DESCRIPTION file, a NAMESPACE file, and an R folder where all of your functions will be.\n\nCreate a simple function in a .R file, and save it in the R folder\n\nyou can do this by navigating to the R folder on the right hand pane of your R Project under ‚ÄúFiles‚Äù, opening the R folder, and selecting ‚ÄúNew File‚Äù &gt; ‚ÄúR Script‚Äù\n\n\n\n\n\nName the file ‚Äúsquare.R‚Äù. We will be adding a simple function to file with an #' @export command to ensure it works properly with our package\n\n#' @export\nsquare &lt;- function(x){\n  x^2\n}\n\n\nIn the console, reload devtools and run the document() function.\n\nAny function with the #' @export tag will be exported to the namespace file which contains a list of functions we want to make available in the R package.\n\nRun use_git() to start using version control and hosting your package on Github:\n\nPrefer to start your project on GitHub? Or locally? Either way, useful instructions for what to do can be found in ‚ÄúHappy Git with R‚Äù Part III.\n\nRun load_all() in the console to test your package out\n\nIf R Restarted, then you need to reload devtools before running load_all().\nsee if square(5) returns the correct answer\n\nCheck that the package is intact: run check() in the Console\nEdit the DESCRIPTION file\n\nFirst, run use_mit_license(\"Your Name\") in the Console.\nOpen the DESCRIPTION file and edit the Author information and Package Title.\nPackage: powers\nTitle: Easy computation of powers\nVersion: 0.0.0.9000\nAuthors@R: \n    person(\"YOUR FIRST NAME\", \"YOUR LAST NAME\", , \"YOUR EMAIL\", role = c(\"aut\", \"cre\"))\nDescription: Calculates various powers of numeric data (squares, cubics, etc)\nLicense: MIT + file LICENSE\nEncoding: UTF-8\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.3.2\nSuggests: \n    testthat (&gt;= 3.0.0)\nConfig/testthat/edition: 3\n\nAdd a README file\n\nRun use_readme_rmd() in the Console.\nOpen the RMD file and add some information for the package.\n---\noutput: github_document\n---\n\n&lt;!-- README.md is generated from README.Rmd. Please edit that file --&gt;\n\n\n\n\n\n\n\n\n\n\n\n# powers Package\n\nThis is a minimal working example of my first R Package for STAT545!\n\n## Installation\n\nPackage installation can be done directly by calling\n`devtools::install_github(\"YOUR_GITHUB_USERNAME/powers\")`\n\n## Example\n\nThis is a basic example which shows you how to solve a common problem:\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(powers)\n#&gt; \n#&gt; Attaching package: 'powers'\n#&gt; The following object is masked _by_ '.GlobalEnv':\n#&gt; \n#&gt;     square\nsquare(c(2,4,5))\n#&gt; [1]  4 16 25\n```\n:::\n\n\n\n\n\n\nRender the README every time with build_readme().\n\nDocument the function:\n\nNavigate back to the function square we made and click anywhere inside of the function. Select ‚ÄúCode‚Äù &gt; ‚ÄúInsert roxygen skeleton‚Äù\nEdit the documentation for param, returns, and examples. You can also add a @title and @description. Here‚Äôs what mine looks like:\n\n\n#' @title Square a single value or vector\n#' @description\n#' Squares a single numeric value or a numeric vector\n#'\n#' @param x, numeric\n#'\n#' @returns numeric, vector\n#'\n#' @examples\n#' square(5)\n#' square(c(4, 5, 6))\n#' @export\nsquare &lt;- function(x){\n  x^2\n}\n\nRun document() again in the Console.\nRun check() again to make sure your examples are working.\n\nInstall and Restart (Ctrl + Shift + B (Windows & Linux) or Cmd + Shift + B (macOS)) , or run install() in the console. Try loading the package and using it!",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html#expand-your-package",
    "href": "webpages/lectures_ii/lec9_rpackages.html#expand-your-package",
    "title": "Lecture 9: R Packages",
    "section": "Expand Your Package",
    "text": "Expand Your Package\nNow, let‚Äôs expand the R package that we just created:\n\nRun use_testthat() in the Console (re-load devtools if R recently restarted)\n\nThis will create a folder called tests and a testthat.R file which we will add our tests to.\nRun use_test(\"square\") in the Console. This will create a file called test-square.R\nUpdate it to include the following tests (and save the file!):\ntest_that(\"square works\", {\n  expect_equal(square(3), 9)\n  expect_equal(square(0), 0)\n  expect_equal(square(c(2,4)), c(4,16))\n  expect_equal(square(c(3, NA)), c(9, NA))\n})\nCheck all tests with test() in the Console. This also happens with check().\n\nWe don‚Äôt really need to use functions from another package here, but practice declaring your general intention to use some functions from the dplyr namespace by running use_package(\"dplyr\") in the Console only once. Now your package will be able to use the dplyr package functions.\nConnect your local package to Github with use_github(). Say yes to committing and publishing the changes. Now your package should be on GitHub!\nMake a vignett, a long-form document that serves as a detailed guide or tutorial for an R package:\n\nuse_vignette(\"powers\")\nbuild_vignettes().\n\nInclude data with the R package with use_data(R_OBJECT_HERE). Then document a string of its name in a new R script using a different collection of roxygen tags.\n\nI‚Äôll add the mtcars dataset using use_data(mtcars)\n\nRelease your package:\n\nMake a NEWS.md file with use_news_md() and add the main development notes.\nCommit changes (in Terminal on RStudio)\n\ngit add .\ngit commit -m \"Adding Vignette:\"\n\nPush Changes (in Terminal on RStudio)\n\ngit push origin main\n(If you get an error, try going to the Git section in the top right hand pane and push from there)\n\nTag a release on GitHub.\n\nRecall How to tag a release from the Collaborative Project Milestone 1:\n\nNavigate to the main page (root) of your GitHub repository.\nThere should be a small link on the right-hand-side of your page that says ‚ÄúCreate a new release‚Äù. Click that.\nFor the tag version/name, put 1.0.0\nChoose a release title and description (this is less important).\nDo not check off ‚ÄúThis is a pre-release‚Äù.\nClick ‚ÄúPublish Release‚Äù.\n\n\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTry installing the package that the person beside you just created. Restart RStudio, load devtools and see if you can use devtools::install_github(\"YOUR_GITHUB_USERNAME/powers\") to install their package. Load in the newly installed powers package and test out the square function and see if it works!",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec9_rpackages.html#resources",
    "href": "webpages/lectures_ii/lec9_rpackages.html#resources",
    "title": "Lecture 9: R Packages",
    "section": "Resources",
    "text": "Resources\nVideo Lecture:\n\nHow to Make an R Package\n\nWritten material:\n\nSee ‚ÄúThe Whole Game‚Äù Chapter of ‚ÄúR packages‚Äù for a concise overview of the entire process of making an R package.\n\nThe entire ‚ÄúR packages‚Äù book is overall a great resource to read if you‚Äôre wanting to learn more.\n\nSee Writing R Extensions, the authoritative and comprehensive (but dry) resource for writing R packages.\nPackage development cheat sheet\nTo learn more about using S3 object oriented functions in your package, see ‚ÄúAdvanced R‚Äù Chapter 13: S3.",
    "crumbs": [
      "Lecture 9: R Packages"
    ]
  },
  {
    "objectID": "webpages/casestudies/fev_datamanipulation.html",
    "href": "webpages/casestudies/fev_datamanipulation.html",
    "title": "Lecture 3 Case Study: Data Manipulation on FEV Dataset",
    "section": "",
    "text": "Copy the following code into a new RMarkdown Document:\n---\ntitle: 'FEV Case Study: Data Manipulation'\noutput: html_document\ndate: \"2025-07-31\"\n---\n\n\n\n## Introduction \n\nWe will perform exploratory data analysis of the `fev` data set. \nLet's start by getting the data set. Load the `readr` package (more on this later) and run `fev &lt;- read_tsv(\"https://raw.githubusercontent.com/GTPB/PSLS20/master/data/fev.txt\")` to get access to it. Let's also load `dplyr` while we're at it - we'll need it to do the exercises! \n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"dplyr\") #uncomment and run once, if needed\n#install.packages(\"readr\") #uncomment and run once, if needed\n\nlibrary(dplyr)\nlibrary(readr)\nfev &lt;- read_tsv(\"https://raw.githubusercontent.com/GTPB/PSLS20/master/data/fev.txt\")\nfev_tbl &lt;- as_tibble(fev) %&gt;% mutate(across(gender:smoking, ~ as.factor(.x))) #assign gender and smoking as factors (more on this later, too!)\n```\n:::\n\n## The `fev` data set \n\nIt is now widely believed that smoking tends to impair lung function. Much of the data to support this claim arises from studies of pulmonary function in adults who are long-time smokers. A question then arises whether such deleterious effects of smoking can be detected in children who smoke. To address this question, measures of lung function were made in about 600 children seen for a routine check up in a particular pediatric clinic. The children participating in this study were asked whether they were current smokers.\n\nA common measurement of lung function is the forced expiratory volume (FEV), which measures how much air you can blow out of your lungs in a short period of time. A higher FEV is usually associated with better respiratory function. It is well known that prolonged smoking diminishes FEV in adults, and those adults with diminished FEV also tend to have decreased pulmonary function as measured by other clinical variables, such as blood oxygen and carbon dioxide levels.\n\nData collected from the study on the relationship between smoking status and lung function (measured by FEV) in children are contained in the `fev_tbl` dataset. Here is a data dictionary:\n\n| Variable Name | Description | \n| :--: |:--: |\n| age           | subject age (years) | \n| fev           | measured forced exhalation volume (litres/second)| \n| height        | subject height (inches) | \n| gender        | subject gender (here, male or female) | \n| smoking         | smoking status (yes or no) | \n\n\nHere is a few rows of the data set:\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(fev_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 √ó 5\n    age   fev height gender smoking\n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  \n1     9  1.71   57   f      0      \n2     8  1.72   67.5 f      0      \n3     7  1.72   54.5 f      0      \n4     9  1.56   53   m      0      \n5     9  1.90   57   m      0      \n6     8  2.34   61   f      0      \n```\n\n\n:::\n:::\n\n\n## Understanding the data structure\n\n### Exercise 1\n\nAm I missing any variables compared to the data dictionary? Let's check. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\n### Exercise 2\n\nNext: are there any duplicate case numbers? Are there any duplicate subject IDs?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nNow we know that no cases were entered twice, and each case corresponds to a different patient. \n\n## Understanding the patients in the study\n\n### Exercise 3\n\nLet's summarize the age of the patients first, by computing the mean, standard deviation, min, and max of the patient ages. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nSomething's a little odd about these summaries. Remember: this is a smoking study on children.\n\n- Why would a 3 year old be enrolled in a smoking study?  \n- Why would a 19 year old be enrolled in a study on children? \n\n### Exercise 4\n\nI'm now a bit worried: what's the youngest patient who smokes in this dataset?\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE \n```\n:::\n\nLooks like the youngest patient who smokes is 9. Seems young to me, but much less far-fetched than (say) 3. \n\n### Exercise 5\n\nWhat about the 19 year olds? Should they be included? The definition of a \"child\" can vary from study to study. Possible definitions include &lt; 21 and &lt; 18.  Let's find out who the patients 18 or older are and what their case numbers are so that we can ask our point of contact for the study about them. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE \n```\n:::\n\n**Aside**: if it turns out that we need to exclude any of these odd-looking patients from our final data analysis, then we will need to re-run everything after this point with their data removed. Isn't it nice that we are preparing this report in R Markdown?  \n\n### Exercise 6\n\nThis is a smoking study, so it seems useful to know what proportion of the study participants are smokers. In fact, let's break it down by sex, and calculate the proportion of girls who are smokers and the proportion of boys who are smokers, as well as the number of girls and the number of boys in the study. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nThe proportion of girls who are smokers is higher than the proportion of boys that are smokers.\n\n### Exercise 7\n\nIs this because there are more smokers among teenage girls than teenage boys? Or is this a phenomenon that is uniform across age groups? To find out, let's calculate: \n\n- the proportion and number of girls aged 0-6 who are smokers\n- the proportion and number of girls aged 7-12 who are smokers \n- the proportion and number of girls aged 13-19 who are smokers\n- the proportion and number of boys aged 0-6 who are smokers\n- the proportion and number of boys aged 7-12 who are smokers \n- the proportion and number of boys aged 13-19 who are smokers\n\nHint: you will need to create a new variable that has three categories: age 0-6, age 7-12, and age 13-19. You can do so with `fev_tbl %&gt;% mutate(age_cat = cut(age, c(0, 6, 12, 19)))`.\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nThere are no smokers (female or male) in the 0-6 group. There is a higher proportion of girls in the 7-12 group who are smokers than boys in the 7-12 group. Ditto the 13-19 group. \n\n## Does smoking have an effect on lung function? \n\nLet's continue exploring the data set with a closer eye to our main research question: does smoking have an effect on lung function in children? \n\n### Exercise 8\n\nLet's start by summarizing the FEV of the smokers and non-smokers. Let's calculate the mean, standard deviation, and number of observations in each group. We will mainly be comparing the means to gather information about the question, but the standard deviation and number of observations are important to look at too. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\nWe see that the mean FEV in the smoking group seems to be substantially higher than the average FEV in the non-smoking group. That is, the smokers appear to have *better* lung function than the non-smokers. \n\nDoes this surprise you? Recall that this is an observational study - children were not randomly assigned to smoke or not smoke. We might then have reason to suspect that the association between FEV and smoking status is confounded by some other factors. For example, \nwe already know that the youngest smoker in our data set is 9, while the non-smokers are as young as 3. This suggests that the smokers in our data set are generally older than the non-smokers. Furthermore, we might expect older children to have higher FEV, because they are bigger and have bigger lungs. Could age be a confounder here? Maybe the smoking group has higher lung function simply because they are older and bigger.\n\nWe will investigate this point next week after we have learned about graphing tools.",
    "crumbs": [
      "Lecture 3 Case Study: Data Manipulation on FEV Dataset"
    ]
  },
  {
    "objectID": "webpages/casestudies/nycflights_dates.html",
    "href": "webpages/casestudies/nycflights_dates.html",
    "title": "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)",
    "section": "",
    "text": "The NYC Flights data set contains (among many other things) on-time performance data for all flights departing a New York City airport in 2013. Let‚Äôs load it from the package nycflights13. Let‚Äôs also load the tidyverse; the key package we will be using from it today is lubridate.\nThere‚Äôs lots to explore in this data set, and lots of variables! We‚Äôll work with a super pared down version.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.2     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(nycflights13)\n\nflights_demo &lt;- flights %&gt;% \n  select(year, month, day, hour, minute, flight, carrier)\n\nhead(flights_demo)\n\n# A tibble: 6 √ó 7\n   year month   day  hour minute flight carrier\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;int&gt; &lt;chr&gt;  \n1  2013     1     1     5     15   1545 UA     \n2  2013     1     1     5     29   1714 UA     \n3  2013     1     1     5     40   1141 AA     \n4  2013     1     1     5     45    725 B6     \n5  2013     1     1     6      0    461 DL     \n6  2013     1     1     5     58   1696 UA     \n\n\nThis currently contains the scheduled departure time of every flight, as well its carrier and flight code.",
    "crumbs": [
      "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)"
    ]
  },
  {
    "objectID": "webpages/casestudies/nycflights_dates.html#nyc-flights-data",
    "href": "webpages/casestudies/nycflights_dates.html#nyc-flights-data",
    "title": "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)",
    "section": "",
    "text": "The NYC Flights data set contains (among many other things) on-time performance data for all flights departing a New York City airport in 2013. Let‚Äôs load it from the package nycflights13. Let‚Äôs also load the tidyverse; the key package we will be using from it today is lubridate.\nThere‚Äôs lots to explore in this data set, and lots of variables! We‚Äôll work with a super pared down version.\n\nlibrary(tidyverse)\n\n‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 2.0.0 ‚îÄ‚îÄ\n‚úî dplyr     1.1.4     ‚úî readr     2.1.5\n‚úî forcats   1.0.0     ‚úî stringr   1.5.1\n‚úî ggplot2   3.5.2     ‚úî tibble    3.3.0\n‚úî lubridate 1.9.4     ‚úî tidyr     1.3.1\n‚úî purrr     1.1.0     \n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n‚úñ dplyr::filter() masks stats::filter()\n‚úñ dplyr::lag()    masks stats::lag()\n‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(nycflights13)\n\nflights_demo &lt;- flights %&gt;% \n  select(year, month, day, hour, minute, flight, carrier)\n\nhead(flights_demo)\n\n# A tibble: 6 √ó 7\n   year month   day  hour minute flight carrier\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;int&gt; &lt;chr&gt;  \n1  2013     1     1     5     15   1545 UA     \n2  2013     1     1     5     29   1714 UA     \n3  2013     1     1     5     40   1141 AA     \n4  2013     1     1     5     45    725 B6     \n5  2013     1     1     6      0    461 DL     \n6  2013     1     1     5     58   1696 UA     \n\n\nThis currently contains the scheduled departure time of every flight, as well its carrier and flight code.",
    "crumbs": [
      "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)"
    ]
  },
  {
    "objectID": "webpages/casestudies/nycflights_dates.html#exercises",
    "href": "webpages/casestudies/nycflights_dates.html#exercises",
    "title": "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)",
    "section": "Exercises",
    "text": "Exercises\n\nDate-Time Creation and Extraction\nI want to add a fake flight to this data set: AC 123, scheduled to depart at 9:00am on Oct 1 2013.\nWe can use a family of functions named as permutations of ‚Äúy‚Äù, ‚Äúm‚Äù, and ‚Äúd‚Äù to convert character input into special Date objects.\n\nmdy(\"Oct 1 2013\")\n\n[1] \"2013-10-01\"\n\n\n\nmdy(\"October 1st 2013\")\n\n[1] \"2013-10-01\"\n\n\nWe just need to get the order right in what‚Äôs passed in - lubridate does the rest!\nWe can use a similar family of functions to convert character input into special Date-Time objects. Let‚Äôs be careful to get the timezone right too, in case it turns out to be important later.\n\n(new_sched_dep_time &lt;- mdy_hm(\"Oct 1 2013 9:00\", tz = \"America/New_York\"))\n\n[1] \"2013-10-01 09:00:00 EDT\"\n\n\nNow let‚Äôs make a 1-row tibble with the components we need: year, month, day, hour, minute, carrier, and flight code. The key will be the year(), month(), etc. functions from the lubridate package.\n\n(new_flight &lt;- tribble(~year, ~month, ~day, ~hour, ~minute, ~flight, ~carrier, \n                      year(new_sched_dep_time), month(new_sched_dep_time), \n                      day(new_sched_dep_time), hour(new_sched_dep_time), \n                      minute(new_sched_dep_time), 123, \"AC\"))\n\n# A tibble: 1 √ó 7\n   year month   day  hour minute flight carrier\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;dbl&gt; &lt;chr&gt;  \n1  2013    10     1     9      0    123 AC     \n\n\nLike magic!!! We can then add it to the flights_demo dataset using bind_rows().\n\nflights_demo &lt;- bind_rows(flights_demo, new_flight)\n\n\n\nDate-Time Math\nThe full flights dataset has info about the departure delays of these flights. Let‚Äôs make another simplified version for demo purposes with that info.\n\nflights_demo2 &lt;- flights %&gt;% \n  select(year, month, day, dep_time, sched_dep_time, dep_delay)\n\nhead(flights_demo2)\n\n# A tibble: 6 √ó 6\n   year month   day dep_time sched_dep_time dep_delay\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n1  2013     1     1      517            515         2\n2  2013     1     1      533            529         4\n3  2013     1     1      542            540         2\n4  2013     1     1      544            545        -1\n5  2013     1     1      554            600        -6\n6  2013     1     1      554            558        -4\n\n\nThe dep_delay variable contains the number of minutes the flight departs either early or late, with a positive number if the flight departs late, and a negative number if the flight departs early. How was this variable made?\nLet‚Äôs see one way how. Let‚Äôs make two Date-Time objects corresponding to the departure and scheduled departure of our fake flight. If we subtract them, then we get a difftime object.\n\nnew_sched_dep_time &lt;- ymd_hm(\"2013 October 1 9:00\", tz = \"America/New_York\")\nnew_dep_time &lt;- ymd_hm(\"2013 Oct 1 9:15\", tz = \"America/New_York\")\n\nnew_dep_time - new_sched_dep_time \n\nTime difference of 15 mins\n\n\nBeautiful! In this case, this calculation was easy to do by hand, but it would‚Äôve been more annoying if we were calculating the time elapsed between (say) December 11th 2010 3:17am and March 24th 2011 11:51pm.\ndifftime objects produce human readable output, but can be a little annoying when you want output in consistent units. duration objects to the rescue - they always use seconds! Let‚Äôs do the math again but this time coerce the result to a duration object.\n\n(duration_delay &lt;- as.duration(new_dep_time - new_sched_dep_time))\n\n[1] \"900s (~15 minutes)\"\n\n\nFinally we can convert this to minutes by creating a duration object that spans a minute using the convenience function dminutes(), and doing date-time division.\n\nduration_delay/dminutes(1)\n\n[1] 15",
    "crumbs": [
      "Lecture 6b Case Study: Date and Times on NYC Flights (WITH SOLUTIONS)"
    ]
  },
  {
    "objectID": "webpages/collabproj/collabproj_deliverable1.html",
    "href": "webpages/collabproj/collabproj_deliverable1.html",
    "title": "Collaborative Project: Deliverable 1",
    "section": "",
    "text": "Due September 19th, 2025 at 11:59pm PT",
    "crumbs": [
      "Collaborative Project: Deliverable 1"
    ]
  },
  {
    "objectID": "webpages/collabproj/collabproj_deliverable2.html",
    "href": "webpages/collabproj/collabproj_deliverable2.html",
    "title": "Collaborative Project: Deliverable 2",
    "section": "",
    "text": "Due September 26th, 2025 at 11:59pm PT",
    "crumbs": [
      "Collaborative Project: Deliverable 2"
    ]
  },
  {
    "objectID": "webpages/faq.html",
    "href": "webpages/faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "September - December of each academic year. Typical format: STAT 545A 1.5 credits in September through mid October, followed by STAT 545B 1.5 credits from mid October through early December."
  },
  {
    "objectID": "webpages/faq.html#when-is-the-course-offered",
    "href": "webpages/faq.html#when-is-the-course-offered",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "September - December of each academic year. Typical format: STAT 545A 1.5 credits in September through mid October, followed by STAT 545B 1.5 credits from mid October through early December."
  },
  {
    "objectID": "webpages/faq.html#what-happened-to-stat-547m",
    "href": "webpages/faq.html#what-happened-to-stat-547m",
    "title": "Frequently Asked Questions",
    "section": "What happened to STAT 547M?",
    "text": "What happened to STAT 547M?\nSTAT 547M became STAT 545B in 2020, so that the course codes align. Otherwise, these are the same courses."
  },
  {
    "objectID": "webpages/faq.html#what-happened-to-the-guidebook",
    "href": "webpages/faq.html#what-happened-to-the-guidebook",
    "title": "Frequently Asked Questions",
    "section": "What happened to the guidebook?",
    "text": "What happened to the guidebook?\nWe used a guidebook in 2019/2020. It‚Äôs still available at https://stat545guidebook.netlify.app, but had become deprecated in place of worksheets and some tutorials."
  },
  {
    "objectID": "webpages/faq.html#why-are-there-two-courses-instead-of-a-single-stat-545-course",
    "href": "webpages/faq.html#why-are-there-two-courses-instead-of-a-single-stat-545-course",
    "title": "Frequently Asked Questions",
    "section": "Why are there two courses, instead of a single ‚ÄúSTAT 545‚Äù course?",
    "text": "Why are there two courses, instead of a single ‚ÄúSTAT 545‚Äù course?\nFor several years, Jenny Bryan taught STAT 545A as a 1.5 credit course. She ‚Äì and many students ‚Äì felt there was a lot of great, relevant content that could go into an additional 1.5 credits.\nA full semester of data exploration, visualization, and all-around data wrangling was piloted in 2014/2015. It was structured as two half courses primarily so that several year‚Äôs worth of STAT 545A alums could register for the second part (then STAT 547M) and get the ‚Äúmissing half‚Äù of the course. And now it‚Äôs hard to break the cycle."
  },
  {
    "objectID": "webpages/faq.html#i-have-taken-stat-545a-for-1.5-credits-in-the-past.-can-i-take-stat-545b",
    "href": "webpages/faq.html#i-have-taken-stat-545a-for-1.5-credits-in-the-past.-can-i-take-stat-545b",
    "title": "Frequently Asked Questions",
    "section": "I have taken STAT 545A for 1.5 credits in the past. Can I take STAT 545B?",
    "text": "I have taken STAT 545A for 1.5 credits in the past. Can I take STAT 545B?\nYES. But STAT 545 keeps changing to keep current with the R world. It is your responsibility to level up."
  },
  {
    "objectID": "webpages/faq.html#can-i-just-take-the-second-half-i.e.-stat-545b",
    "href": "webpages/faq.html#can-i-just-take-the-second-half-i.e.-stat-545b",
    "title": "Frequently Asked Questions",
    "section": "Can I just take the second half, i.e.¬†STAT 545B?",
    "text": "Can I just take the second half, i.e.¬†STAT 545B?\nNO, not unless you have taken STAT 545A previously."
  },
  {
    "objectID": "webpages/faq.html#can-i-just-take-the-second-half-i.e.-stat-545b-ill-do-a-self-study-for-stat-545a.",
    "href": "webpages/faq.html#can-i-just-take-the-second-half-i.e.-stat-545b-ill-do-a-self-study-for-stat-545a.",
    "title": "Frequently Asked Questions",
    "section": "Can I just take the second half, i.e.¬†STAT 545B? I‚Äôll do a self-study for STAT 545A.",
    "text": "Can I just take the second half, i.e.¬†STAT 545B? I‚Äôll do a self-study for STAT 545A.\nUnfortunately, the answer is still no. As much as we‚Äôd want to say yes to you, it just becomes too difficult for us to evaluate your level without having seen deliverables for STAT 545A."
  },
  {
    "objectID": "webpages/faq.html#i-am-an-undergraduate.-can-i-take-this-course",
    "href": "webpages/faq.html#i-am-an-undergraduate.-can-i-take-this-course",
    "title": "Frequently Asked Questions",
    "section": "I am an undergraduate. Can I take this course?",
    "text": "I am an undergraduate. Can I take this course?\nMaybe, if there‚Äôs room. Contact the instructor."
  },
  {
    "objectID": "webpages/faq.html#what-if-ive-never-had-a-stats-class",
    "href": "webpages/faq.html#what-if-ive-never-had-a-stats-class",
    "title": "Frequently Asked Questions",
    "section": "What if I‚Äôve never had a stats class?",
    "text": "What if I‚Äôve never had a stats class?\nThere are no official pre-requisites for STAT 545A but most students will have had at least one prior statistics course or comparable experience."
  },
  {
    "objectID": "webpages/faq.html#im-not-enrolled-can-i-sit-in-during-class",
    "href": "webpages/faq.html#im-not-enrolled-can-i-sit-in-during-class",
    "title": "Frequently Asked Questions",
    "section": "I‚Äôm not enrolled ‚Äì can I sit in during class?",
    "text": "I‚Äôm not enrolled ‚Äì can I sit in during class?\nUnfortunately not. The room is usually at capacity, and further, we‚Äôve allocated TA time for the specific number of students attending the class."
  },
  {
    "objectID": "webpages/faq.html#id-like-to-officially-audit-can-i",
    "href": "webpages/faq.html#id-like-to-officially-audit-can-i",
    "title": "Frequently Asked Questions",
    "section": "I‚Äôd like to officially audit ‚Äì can I?",
    "text": "I‚Äôd like to officially audit ‚Äì can I?\nAbsolutely! Please take a look at what is required of auditors so that you have an understanding of your expectations coming into the course; then, fill out the form (graduate version) and send it to the instructor to get signed."
  },
  {
    "objectID": "webpages/faq.html#the-course-is-full-can-i-audit-instead",
    "href": "webpages/faq.html#the-course-is-full-can-i-audit-instead",
    "title": "Frequently Asked Questions",
    "section": "The course is full ‚Äì can I audit instead?",
    "text": "The course is full ‚Äì can I audit instead?\nYou‚Äôll still have to join the waitlist ‚Äì auditing still counts as a seat in the class, so auditing is not a way around the course capacity.\nIn all cases, I encourage you to register! Or if the course is full, join the waitlist. Alternatively, you can engage in your own self-study using our online resources."
  },
  {
    "objectID": "webpages/faq.html#the-course-is-full.-is-there-a-chance-that-the-course-capacity-will-increase",
    "href": "webpages/faq.html#the-course-is-full.-is-there-a-chance-that-the-course-capacity-will-increase",
    "title": "Frequently Asked Questions",
    "section": "The course is full. Is there a chance that the course capacity will increase?",
    "text": "The course is full. Is there a chance that the course capacity will increase?\nUnfortunately, the course enrollment capacity will not increase. But, I encourage you to join the waitlist."
  },
  {
    "objectID": "webpages/faq.html#the-course-is-listed-as-restricted.-what-should-i-do",
    "href": "webpages/faq.html#the-course-is-listed-as-restricted.-what-should-i-do",
    "title": "Frequently Asked Questions",
    "section": "The course is listed as ‚Äúrestricted‚Äù. What should I do?",
    "text": "The course is listed as ‚Äúrestricted‚Äù. What should I do?\nWhen all the open seats are taken, the course is listed as ‚Äúrestricted‚Äù, as the remaining seats can only be taken by students of specific types. If you are a student of that type, then go ahead and register through SSC! Otherwise, I encourage you to join the waitlist."
  },
  {
    "objectID": "webpages/faq.html#can-i-take-this-course-if-im-not-a-statistics-student",
    "href": "webpages/faq.html#can-i-take-this-course-if-im-not-a-statistics-student",
    "title": "Frequently Asked Questions",
    "section": "Can I take this course if I‚Äôm not a Statistics student?",
    "text": "Can I take this course if I‚Äôm not a Statistics student?\nThis course is open to any graduate student at UBC. Students from other departments vastly outnumber those from Statistics. In fact, the most successful students are often grad students from other fields who need to analyze and visualize data for a thesis. They are highly motivated and excel.\nHowever, if you have never programmed or worked at the command line before, prepare for a shock. This will be a powerful, positive experience, but it‚Äôs a big adjustment. Come suffer through the worst part of the learning curve in good company!"
  },
  {
    "objectID": "webpages/faq.html#do-i-need-a-computer",
    "href": "webpages/faq.html#do-i-need-a-computer",
    "title": "Frequently Asked Questions",
    "section": "Do I need a computer?",
    "text": "Do I need a computer?\nYES. You absolutely must have access to a computer on which you can install software, download data, etc. In fact, class meetings will be a mix of lecture, discussion, and live coding. Students will get the most out of this if they can bring their own laptop to class every day. If this is not possible, we will try to help you work something out."
  },
  {
    "objectID": "webpages/faq.html#are-they-any-prerequisites",
    "href": "webpages/faq.html#are-they-any-prerequisites",
    "title": "Frequently Asked Questions",
    "section": "Are they any prerequisites?",
    "text": "Are they any prerequisites?\nThere are no official pre-requisites for STAT 545A, but most students will have had at least one prior statistics course or comparable experience.\nSTAT 545B requires STAT 545A."
  },
  {
    "objectID": "webpages/mda/mda_deliverable1.html#deliverable-1-will-be-due-on-friday-october-3rd-2025-at-1159pm-pt.",
    "href": "webpages/mda/mda_deliverable1.html#deliverable-1-will-be-due-on-friday-october-3rd-2025-at-1159pm-pt.",
    "title": "Mini Data Analysis: Deliverable 1",
    "section": "Deliverable 1 will be due on Friday October 3rd, 2025 at 11:59pm PT.",
    "text": "Deliverable 1 will be due on Friday October 3rd, 2025 at 11:59pm PT.",
    "crumbs": [
      "Mini Data Analysis: Deliverable 1"
    ]
  },
  {
    "objectID": "webpages/mda/mda_deliverable2.html#deliverable-2-will-be-due-on-wednesday-october-22nd-2025-at-1159pm-pt",
    "href": "webpages/mda/mda_deliverable2.html#deliverable-2-will-be-due-on-wednesday-october-22nd-2025-at-1159pm-pt",
    "title": "Mini Data Analysis: Deliverable 2",
    "section": "Deliverable 2 will be due on Wednesday October 22nd, 2025 at 11:59pm PT",
    "text": "Deliverable 2 will be due on Wednesday October 22nd, 2025 at 11:59pm PT",
    "crumbs": [
      "Mini Data Analysis: Deliverable 2"
    ]
  },
  {
    "objectID": "webpages/syllabus/syllabusA.html",
    "href": "webpages/syllabus/syllabusA.html",
    "title": "Syllabus: STAT 545 A (Part I)",
    "section": "",
    "text": "Acknowledgement\nUBC‚Äôs Point Grey Campus is located on the traditional, ancestral, and unceded territory of the xwm…ôŒ∏kw…ôy…ôm (Musqueam) people. The land it is situated on has always been a place of learning for the Musqueam people, who for millennia have passed on their culture, history, and traditions from one generation to the next on this site.\n\n\nCourse Information\n\n\n\n\n\n\n\n\n\n\nCourse Title\nCourse Code\nCredit Value\nClass Times\nClass Location\n\n\nExploratory Data Analysis Part I\nSTAT 545 A\n1.5\nMonday/Wednesday: 9:00am - 10:20am\nCEME 1202\n\n\n\n\n\nPrerequisites\nWhile there are no formal pre-requisites for STAT 545 A, students should be familiar with basic statistical analyses and have taken at least one introductory statistics course.\nSTAT545 A is a pre-requisite for STAT545 B. No exceptions.\n\n\nContact and Office Hours\n\n\n\n\n\n\n\n\n\nInstructor\nContact Details\nOffice Location\nOffice Hours\n\n\n\n\nGrace Tompkins\ngrace&lt;at&gt;stat.ubc.ca\nESB 3134\nTBD\n\n\n\n\n\n\nTeaching Assistants\n\n\n\n\nTBD\n\n\nTBD\n\n\nTBD\n\n\n\n\n\nCourse Structure\nThis course will feature short lectures and in-class demonstrations so students get hands-on experience with the help of their instructor and TAs. Dedicated time will be given in lecture for students to work through assigned worksheets.\nPlease bring a charged laptop to every class. If you do not have a personal laptop, one can be borrowed through the UBC library.\n\n\nSchedule of Topics\nSTAT 545 A (Part I):\n\n\n\nWeek\nDate\nTopic\nIn-class work\n\n\n\n\n1\nTuesday Sept 2\nInstallation\n\n\n\n\nThursday Sept 4\nIntro to STAT545 and R\nWorksheet A1\n\n\n\n\n\n\n\n\n2\nTuesday Sept 9\nAuthoring and Reproducibility\nEnsure you have completed the installation instructions from Sept 2*!\n\n\n\nThursday Sept 11\nVersion Control\n\n\n\n\n\n\n\n\n\n3\nTuesday Sept 16\nData Manipulation with dplyr\nWorksheet A2\n\n\n\nThursday Sept 18\n\nWorksheet A2\n\n\n\n\n\n\n\n\n4\nTuesday Sept 23\nData Visualization\nWorksheet A3\n\n\n\nThursday Sept 25\n\nWorksheet A3\n\n\n\n\n\n\n\n\n5\nTuesday Sept 30\n*** NO CLASS ***\n\n\n\n\nThursday Oct 2\nTidy Data\nWorksheet A4\n\n\n\n\n\n\n\n\n6\nTuesday Oct 7\nModel Fitting\nWorksheet A4\n\n\n\nThursday Oct 9\nFactors and Dates\nWorksheet A5\n\n\n\n\n\n\n\n\n7\nTuesday Oct 14\nReading and Writing Data, and Tibble Joins\nWorksheet A5\n\n\n\nThursday Oct 16\nReview and Work Session\nWorksheet A5, Mini Data Analysis (MDA)\n\n\n\nThis schedule is subject to change. Any changes will be announced via the #annoucements channel on Slack, and major changes will be sent out via email.\n\n\nAssessments\nThis course will have autograded, formative worksheets meant to guide you through a number of exercises.\n\n\n\n\n\n\n\n\nAssessment\nPercent Grade\nNote\n\n\n\n\nWorksheets\n20%\nGuided worksheets\n\n\nMini Data Analysis\n45%\nStudents write their own mini analysis\n\n\nCollaborative Project\n35%\nTeam project intended for practicing version control and collaboration\n\n\n\n\nWorksheets\nWorksheets are interactive assignments that allow students to get real-time feedback on their code. Your grade will be based on the number of correct answers provided. There are unlimited attempts for the worksheets, and time will be given in class to work through them.\nWorksheets are produced with Jupyter Notebooks, and will be submitted on Canvas.\n\n\n\nWorksheet\nRelease Date\nDue Date (11:59PM PT)\n\n\n\n\nWorksheet A1\nSeptember 2nd, 2025\nNA\n\n\nWorksheet A2\nSeptember 15th, 2025\nSeptember 22nd, 2025\n\n\nWorksheet A3\nSeptember 22nd, 2025\nSeptember 29th, 2025\n\n\nWorksheet A4\nSeptember 29th, 2025\nOctober 13th, 2025\n\n\nWorksheet A5\nOctober 13th, 2025\nOctober 20th, 2025\n\n\n\n\n\nCollaborative Project\nTeams will be randomly assigned. The idea behind the collaborative project is to practice using Version Control and collaborative tools on Github, troubleshoot broken R code, and rewrite code to address issues. There will be two deliverables for the project:\n\n\n\n\n\n\n\n\nCollaborative Project Milestone\nRelease Date\nDue Date (11:59pm PT)\n\n\n\n\nDeliverable 1 (100 points)\nSeptember 4th, 2025\nSeptember 19th, 2025\n\n\nDeliverable 2 (78 points)\nSeptember 4th, 2025\nSeptember 26th, 2025\n\n\n\nInstructions will be posted on the Course Website under ‚ÄúCollaborative Project‚Äù\n\n\nMini Data Analysis\nConduct your own mini data analysis! The goal of this assignment is to become more familiar with R and generate a reproducible report using RMarkdown and various packages, such as tibble. There are two equally weighted deliverables:\n\n\n\n\n\n\n\n\nMini Data Analysis Milestone\nRelease Date\nDue Date (11:59PM PT)\n\n\n\n\nDeliverable 1 (36 points)\nSeptember 26th, 2025\nOctober 3rd, 2025\n\n\nDeliverable 2 (36 points)\nSeptember 26th, 2025\nOctober 22nd, 2025\n\n\n\n\n\n\nAuditing Students\nAuditing students are expected to complete all assessments (see above). All assessments are graded on a pass/fail basis for those officially auditing.\nYou must be registered as an auditing student to attend lectures due to capacity limitations.\n\n\nCourse Communications\nWe will be using Slack as our primary platform of all course-related communications! Students will be emailed an invite to their class‚Äô Slack workspace.\nOfficial course communications will occur on the #announcements channel. You will receive an invite on the first day of classes. Please notify the instructor by email if you have not received your personal invite.\nOur STAT 545 team will be actively monitoring Slack during regular working hours (9am to 5pm PT, Monday to Friday). You are free to ask questions outside of this window but please keep in mind that there are no expectations for the team to answer questions outside of working hours or on weekends or holidays.\nTo make the most out of Slack, please\n\nUse the #general channel for clarifications, asking about course organization, or clarifying instructions. Things you post on the #general channel will be seen by everyone, so please do not provide information that gives away answers to assignments.\nMake a group chat with our TAs when you need more personalized help, or have an issue with grading. They may direct you to the #general channel when appropriate, or direct you to the instructor.\nDirect message the instructor if there is a concern that is more personal (i.e., you need to self declare an absense) or if you have already talked to the TAs about an issue and are unsatisfied. You can also direct message the instructor if you are having issues with a group member in any group-related assignments.\nPost in the #random channel if you find things related to the course that you‚Äôd like to share\n\n\n\nPrivacy\nSlack and GitHub are hosted on servers stored outside of Canada. Please keep this in mind.\n\n\nPolicies\n\nRegrade Requests\nRegrade requests must be sent to the TAs through Slack within one week of the assessment being returned. If required, regrade requests can be escalated to the instructor only if the request has already been brought up to the TA team and the student is unsatisfied. The instructor reserves the right to regrade the entire assessment, resulting in a higher or lower mark than originally provided.\n\n\nLate Policies\nWorksheets (and larger assignments, if applicable) are due at 11:59pm PT on the date indicated in the course schedule. For a late submission, a 24 hour extension will be provided for the first offense. Late submissions will be given a grade of 0 for subsequent occurrences.\nThere is a zero-tolerance policy for late projects, including the mini data analysis and the collaborative project. If you are having issues with a team member regarding any group work, reach out to the instructor directly through Slack or email.\n\n\nAcademic Concession\nUBC no longer requires a doctor‚Äôs note (or supporting documentation) for academic concession. A self-declaration will suffice ‚Äì here is a template you can use. The form is also posted on our Canvas page. Please submit this to the instructor via email.\nExamples of ‚Äúconflicting responsibility‚Äù are conference travel and time-sensitive field work.\nIf you arrange to have an assignment submitted late, you may not be able to receive feedback from your peers.\n\n\nPlagiarism\nPlagiarism, which is intellectual theft, occurs where an individual submits or presents the oral or written work of another person as his or her own and can include:\n\nmultiple students submitting the same response\ncopying from sources without citing them\ncopying verbatim (word-for-word) from source and citing, but failing to make it explicit that this is a quotation (quotations should be used only rarely, if at all)\n\nStudents are responsible for ensuring that any work submitted does not constitute plagiarism. Students who are in any doubt as to what constitutes plagiarism should consult their instructor before handing in any assignments.\nFor more information see the UBC Academic Misconduct policies.\n\n\nCode Plagiarism\nStudents must correctly cite any code that has been authored by someone else or by the student themselves for other assignments. Cases of code plagiarism may include, but are not limited to:\n\nthe reproduction (copying and pasting) of code with none or minimal reformatting (e.g., changing the name of the variables)\nthe translation of an algorithm or a script from a language to another\nthe generation of code by automatic code-generations software\n\nAn ‚Äúadequate acknowledgement‚Äù requires a detailed identification of the (parts of the) code reused and a full citation of the original source code that has been reused.\n\n\nUBC‚Äôs Policies and Resources to Support Student Success\nUBC provides resources to support student learning and to maintain healthy lifestyles but recognizes that sometimes crises arise and so there are additional resources to access including those for survivors of sexual violence. UBC values respect for the person and ideas of all members of the academic community. Harassment and discrimination are not tolerated nor is suppression of academic freedom. UBC provides appropriate accommodation for students with disabilities and for religious, spiritual and cultural observances. UBC values academic honesty and students are expected to acknowledge the ideas generated by others and to uphold the highest academic standards in all of their actions. Details of the policies and how to access support are available here.\n\n\nYour personal health\nIf you‚Äôre sick, it‚Äôs important that you stay home ‚Äì no matter what you think you may be sick with (e.g., cold, flu, other). Your precautions will help reduce risk and keep everyone safer. The structure of this class is intended to provide flexibility so that you can prioritize your health and still be able to succeed.\nIf you do miss class because of illness:\n\nConsult the class resources on the course website\nCome to office hours on Zoom.\nUse Slack to carry out discussions.\n\nIf you miss an assessment due to illness, see the above section on Academic Concessions, and review the UBC policy here: http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,329,0,0\nAbove all, please take care of yourself and be kind to yourself and your classmates. If you or anyone you know experiences any academic stress, difficult life events, or feelings like anxiety or depression, I strongly encourage you to seek support. UBC Counseling Services is here to help: call 604 822 3811 or visit their website. Consider also reaching out to a friend, faculty member, or family member you trust to help get you the support you need.\n\n\nInstructor health\nIf I am ill, then I will not come to class. If that happens, here‚Äôs what you can expect:\n\nIf I am well enough to teach, I will conduct virtual lectures through Zoom until I am well. If this happens, you will be tagged in an announcement via Slack with information. You can anticipate that this would very likely be a last minute announcement. Our classroom will still be available for you to sit and attend an online session, although it is recommended that you bring headphones.\nIf I am not well enough to teach, it is possible that one or more teaching assistants will take my place. But if not, we will either try to make up for lost time, make new resources to aid in your learning, or make accommodations regarding the assessments.\n\n\n\n\nCopyright\nCourse materials are licensed under Creative Commons 4.0.",
    "crumbs": [
      "Syllabus: STAT 545 A (Part I)"
    ]
  },
  {
    "objectID": "webpages/syllabus/syllabusB.html",
    "href": "webpages/syllabus/syllabusB.html",
    "title": "Syllabus: STAT 545 B (Part II)",
    "section": "",
    "text": "Acknowledgement\nUBC‚Äôs Point Grey Campus is located on the traditional, ancestral, and unceded territory of the xwm…ôŒ∏kw…ôy…ôm (Musqueam) people. The land it is situated on has always been a place of learning for the Musqueam people, who for millennia have passed on their culture, history, and traditions from one generation to the next on this site.\n\n\nCourse Information\n\n\n\n\n\n\n\n\n\n\nCourse Title\nCourse Code\nCredit Value\nClass Times\nClass Location\n\n\nExploratory Data Analysis Part II\nSTAT 545 B\n1.5\nMonday/Wednesday: 9:30am - 10:50am\nCEME 1202\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSTAT545 B starts half an hour later than STAT545 A!\n\n\n\n\nPrerequisites\nSTAT545 A is a pre-requisite for STAT545 B. No exceptions.\n\n\nContact and Office Hours\n\n\n\n\n\n\n\n\n\nInstructor\nContact Details\nOffice Location\nOffice Hours\n\n\n\n\nGrace Tompkins\ngrace&lt;at&gt;stat.ubc.ca\nESB 3134\nTBD\n\n\n\n\n\n\nTeaching Assistants\n\n\n\n\nTBD\n\n\nTBD\n\n\nTBD\n\n\n\n\n\nCourse Structure\nThis course will feature short lectures and in-class demonstrations so students get hands-on experience with the help of their instructor and TAs. Dedicated time will be given in lecture for students to work through assigned worksheets.\nPlease bring a charged laptop to every class. If you do not have a personal laptop, one can be borrowed through the UBC library.\n\n\nSchedule of Topics\nSTAT 545 A (Part I):\n\n\n\nWeek\nDate\nTopic\nIn-class work\n\n\n\n\n8\nTuesday Oct 21\nFunctions\nWorksheet B1\n\n\n\nThursday Oct 23\nAdvanced Functions\nWorksheet B1, Assignment 1\n\n\n\n\n\n\n\n\n9\nTuesday Oct 28\nR Packages\n\n\n\n\nThursday Oct 30\n\nAssignment 2\n\n\n\n\n\n\n\n\n10\nTuesday Nov 4\nDashboards with R Shiny\n\n\n\n\nThursday Nov 6\n\nAssignment 3\n\n\n\n\n\n\n\n\n11\nTuesday Nov 11\nNO LECTURE: REMEMBRANCE DAY\n\n\n\n\nThursday Nov 13\nAutomation\n\n\n\n\n\n\n\n\n\n12\nTuesday Nov 18\nStringR and Regular Expressions\nWorksheet B2\n\n\n\nThursday Nov 20\n\nWorksheet B2\n\n\n\n\n\n\n\n\n13\nTuesday Nov 25\nList Columns\nWorksheet B3\n\n\n\nThursday Nov 27\n\nWorksheet B3\n\n\n\n\n\n\n\n\n14\nTuesday Dec 2\nQuarto Websites and Slides\n\n\n\n\nThursday Dec 4\nReview and Work Session\nAssignment 4\n\n\n\nThis schedule is subject to change. Any changes will be announced via the #annoucements channel on Slack, and major changes will be sent out via email.\n\n\nAssessments\nThis course will have autograded, formative worksheets meant to guide you through a number of exercises.\n\n\n\n\n\n\n\n\nAssessment\nPercent Grade\nNote\n\n\n\n\nWorksheets (3)\n20%\nGuided worksheets\n\n\nAssignments (4)\n80%\nMore independent analyses and tasks\n\n\n\n\nWorksheets\nWorksheets are interactive assignments that allow students to get real-time feedback on their code. Your grade will be based on the number of correct answers provided. There are unlimited attempts for the worksheets, and time will be given in class to work through them.\nWorksheets are produced with Jupyter Notebooks, and will be submitted on Canvas.\n\n\n\nWorksheet\nRelease Date\nDue Date (11:59PM PT)\n\n\n\n\nWorksheet B1\nMonday Oct 20, 2025\nMonday Oct 27, 2025\n\n\nWorksheet B2\nFriday Nov 14, 2025\nThursday Nov 27, 2025\n\n\nWorksheet B3\nThursday Nov 27, 2025\nThursday Dec 4, 2025\n\n\n\n\n\nAssignments\nThere are four formal assignments for this course:\n\n\n\nAssignment\nRelease Date\nDue Date (11:59pm PT)\n\n\n\n\nAssignment 1\nTuesday Oct 21, 2025\nFriday Oct 31, 2025\n\n\nAssignment 2\nFriday Oct 31, 2025\nFriday Nov 7, 2025\n\n\nAssignment 3\nFriday Nov 7, 2025\nFriday Nov 21, 2025\n\n\nAssignment 4\nFriday Nov 21, 2025\nThursday Dec 4, 2025\n\n\n\nInstructions will be posted on the Course Website under ‚ÄúAssignments‚Äù\n\n\n\nAuditing Students\nAuditing students are expected to complete all assessments (see above). All assessments are graded on a pass/fail basis for those officially auditing.\nYou must be registered as an auditing student to attend lectures due to capacity limitations.\n\n\nCourse Communications\nWe will be using Slack as our primary platform of all course-related communications! Students will be emailed an invite to their class‚Äô Slack workspace.\nOfficial course communications will occur on the #announcements channel. You will receive an invite on the first day of classes. Please notify the instructor by email if you have not received your personal invite.\nOur STAT 545 team will be actively monitoring Slack during regular working hours (9am to 5pm PT, Monday to Friday). You are free to ask questions outside of this window but please keep in mind that there are no expectations for the team to answer questions outside of working hours or on weekends or holidays.\nTo make the most out of Slack, please\n\nUse the #general channel for clarifications, asking about course organization, or clarifying instructions. Things you post on the #general channel will be seen by everyone, so please do not provide information that gives away answers to assignments.\nMake a group chat with our TAs when you need more personalized help, or have an issue with grading. They may direct you to the #general channel when appropriate, or direct you to the instructor.\nDirect message the instructor if there is a concern that is more personal (i.e., you need to self declare an absense) or if you have already talked to the TAs about an issue and are unsatisfied. You can also direct message the instructor if you are having issues with a group member in any group-related assignments.\nPost in the #random channel if you find things related to the course that you‚Äôd like to share\n\n\n\nPrivacy\nSlack and GitHub are hosted on servers stored outside of Canada. Please keep this in mind.\n\n\nPolicies\n\nRegrade Requests\nRegrade requests must be sent to the TAs through Slack within one week of the assessment being returned. If required, regrade requests can be escalated to the instructor only if the request has already been brought up to the TA team and the student is unsatisfied. The instructor reserves the right to regrade the entire assessment, resulting in a higher or lower mark than originally provided.\n\n\nLate Policies\nWorksheets (and larger assignments, if applicable) are due at 11:59pm PT on the date indicated in the course schedule. For a late submission, a 24 hour extension will be provided for the first offense. Late submissions will be given a grade of 0 for subsequent occurrences.\nThere is a zero-tolerance policy for late projects, including the mini data analysis and the collaborative project. If you are having issues with a team member regarding any group work, reach out to the instructor directly through Slack or email.\n\n\nAcademic Concession\nUBC no longer requires a doctor‚Äôs note (or supporting documentation) for academic concession. A self-declaration will suffice ‚Äì here is a template you can use. The form is also posted on our Canvas page. Please submit this to the instructor via email.\nExamples of ‚Äúconflicting responsibility‚Äù are conference travel and time-sensitive field work.\nIf you arrange to have an assignment submitted late, you may not be able to receive feedback from your peers.\n\n\nPlagiarism\nPlagiarism, which is intellectual theft, occurs where an individual submits or presents the oral or written work of another person as his or her own and can include:\n\nmultiple students submitting the same response\ncopying from sources without citing them\ncopying verbatim (word-for-word) from source and citing, but failing to make it explicit that this is a quotation (quotations should be used only rarely, if at all)\n\nStudents are responsible for ensuring that any work submitted does not constitute plagiarism. Students who are in any doubt as to what constitutes plagiarism should consult their instructor before handing in any assignments.\nFor more information see the UBC Academic Misconduct policies.\n\n\nCode Plagiarism\nStudents must correctly cite any code that has been authored by someone else or by the student themselves for other assignments. Cases of code plagiarism may include, but are not limited to:\n\nthe reproduction (copying and pasting) of code with none or minimal reformatting (e.g., changing the name of the variables)\nthe translation of an algorithm or a script from a language to another\nthe generation of code by automatic code-generations software\n\nAn ‚Äúadequate acknowledgement‚Äù requires a detailed identification of the (parts of the) code reused and a full citation of the original source code that has been reused.\n\n\nUBC‚Äôs Policies and Resources to Support Student Success\nUBC provides resources to support student learning and to maintain healthy lifestyles but recognizes that sometimes crises arise and so there are additional resources to access including those for survivors of sexual violence. UBC values respect for the person and ideas of all members of the academic community. Harassment and discrimination are not tolerated nor is suppression of academic freedom. UBC provides appropriate accommodation for students with disabilities and for religious, spiritual and cultural observances. UBC values academic honesty and students are expected to acknowledge the ideas generated by others and to uphold the highest academic standards in all of their actions. Details of the policies and how to access support are available here.\n\n\nYour personal health\nIf you‚Äôre sick, it‚Äôs important that you stay home ‚Äì no matter what you think you may be sick with (e.g., cold, flu, other). Your precautions will help reduce risk and keep everyone safer. The structure of this class is intended to provide flexibility so that you can prioritize your health and still be able to succeed.\nIf you do miss class because of illness:\n\nConsult the class resources on the course website\nCome to office hours on Zoom.\nUse Slack to carry out discussions.\n\nIf you miss an assessment due to illness, see the above section on Academic Concessions, and review the UBC policy here: http://www.calendar.ubc.ca/vancouver/index.cfm?tree=3,329,0,0\nAbove all, please take care of yourself and be kind to yourself and your classmates. If you or anyone you know experiences any academic stress, difficult life events, or feelings like anxiety or depression, I strongly encourage you to seek support. UBC Counseling Services is here to help: call 604 822 3811 or visit their website. Consider also reaching out to a friend, faculty member, or family member you trust to help get you the support you need.\n\n\nInstructor health\nIf I am ill, then I will not come to class. If that happens, here‚Äôs what you can expect:\n\nIf I am well enough to teach, I will conduct virtual lectures through Zoom until I am well. If this happens, you will be tagged in an announcement via Slack with information. You can anticipate that this would very likely be a last minute announcement. Our classroom will still be available for you to sit and attend an online session, although it is recommended that you bring headphones.\nIf I am not well enough to teach, it is possible that one or more teaching assistants will take my place. But if not, we will either try to make up for lost time, make new resources to aid in your learning, or make accommodations regarding the assessments.\n\n\n\n\nCopyright\nCourse materials are licensed under Creative Commons 4.0.",
    "crumbs": [
      "Syllabus: STAT 545 B (Part II)"
    ]
  },
  {
    "objectID": "webpages/worksheets.html",
    "href": "webpages/worksheets.html",
    "title": "Worksheets",
    "section": "",
    "text": "Links to worksheets go here"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT545 A/B: Exploratory Data Analysis (Fall 2025)",
    "section": "",
    "text": "This Week at a Glance\n\n\n\nLectures:\n\nTuesday September 2: Get in-person help with installing course software\nThursday September 4th: Intro to R lecture, begin working through Worksheet A1\n\nAssessments Due:\n\nNothing! Ensure you have completed all installation instructions by next week!"
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "STAT545 A/B: Exploratory Data Analysis (Fall 2025)",
    "section": "üëã Welcome!",
    "text": "üëã Welcome!\n\n\nWelcome to STAT 545 at the University of British Columbia! Whether you‚Äôre a student enrolled in STAT 545 or simply someone looking to learn how to write reproducible and collaborative data analyses, it is our hope that this website will serve as a great resource for learning these new skills!\nIn short, this course will enable you to confidently write clean and modern data analyses in R using version control software (GitHub), and creating reports using R Markdown. The primary focus will be on using these technologies to conduct analyses with daily workflow, rather than the statistical theory and methods for analysis.\n\n\n\n\n\n\n\n\nThis course is divided into two parts. In Part I (STAT545 A), we will introduce\n\nR and RStudio,\nReport generation with R Markdown,\nProject organization, workflow, and coding style,\nData management with dataframes and tibbles using tidyverse,\nData visualization with ggplot2, and\nVersion control using Git and Github.\n\nIn Part II (STAT545 B), we will dive deeper into\n\nWriting functions in R,\nAdvanced computations on data,\nFunctional programming with purrr,\nR packages,\nInteractive pages, apps, and graphics with RShiny, and\nWebsite development using Quarto.\n\nIf you are a student enrolling in this course for credit at UBC, you MUST take STAT 545 A to enroll in STAT545 B. There are no exceptions to this rule."
  },
  {
    "objectID": "index.html#your-teaching-team-2025",
    "href": "index.html#your-teaching-team-2025",
    "title": "STAT545 A/B: Exploratory Data Analysis (Fall 2025)",
    "section": "üë©‚Äçüè´ Your Teaching Team (2025)",
    "text": "üë©‚Äçüè´ Your Teaching Team (2025)\nMy name is Grace Tompkins (she/her) and I‚Äôll be your course instructor. I‚Äôm a Biostatistician and recent PhD graduate passionate about teaching! I‚Äôm excited to be guiding you throughout this course.\n\n\n\nInstructor: Grace Tompkins\n\n\nI am joined by a wonderful group of TAs, including:\n‚Ä¶.\nPlease reach out if you have any concerns or questions at grace&lt;at&gt;stat.ubc.ca, or through our Slack channel."
  },
  {
    "objectID": "webpages/casestudies/fev_datavis.html",
    "href": "webpages/casestudies/fev_datavis.html",
    "title": "Lecture 4 Case Study: Data Visualization with FEV Dataset",
    "section": "",
    "text": "Copy and paste the following code into a new RMarkdown Document.\n---\ntitle: 'FEV Case Study: Graphing'\nauthor: \"Lucy\"\ndate: \"2023-08-28\"\noutput: html_document\n---\n\n\n\n## Review \n\nWe'll continue exploring the FEV data set from last week. Let's start by loading the data and required packages.\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"dplyr\") #uncomment and run once, if needed\n#install.packages(\"readr\") #uncomment and run once, if needed\n#install.packages(\"ggplot2\") #uncomment and run once, if needed\n\nlibrary(dplyr)\nlibrary(readr)\nlibrary(ggplot2)\n\nfev &lt;- read_tsv(\"https://raw.githubusercontent.com/GTPB/PSLS20/master/data/fev.txt\")\nfev_tbl &lt;- as_tibble(fev) %&gt;% mutate(across(gender:smoking, ~ as.factor(.x))) #assign gender and smoking as factors (more on this later, too!)\n```\n:::\n\nLast week, we found that the mean FEV in the smoking group was substantially higher than the average FEV in the non-smoking group. That is, the smokers appear to have *better* lung function than the non-smokers. \n\nWe also had a theory as to why: the association between FEV and smoking status may be confounded, eg. by age/size.\n\nWe'll investigate further this week with our newly acquired plotting skills! \n\nHere are some helpful resources for making plots, now that we are moving towards less \"guided\" exercises: \n\n- [ggplot2 package webpage](https://ggplot2.tidyverse.org/index.html)\n- [ggplot2 Book](https://ggplot2-book.org/)\n- [R Graphics Cookbook](https://r-graphics.org/)\n\n## Smoking and FEV (unadjusted)\n\n### Exercise 1 \n\nNow that we have plotting tools, let's make a plot that compares the FEV of smokers to the FEV of non-smokers. \n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nThis broadly tells the same story as the summaries we calculated last week, but conveys more information and is more visually engaging. \n\n## Searching for potential confounders \n\nLet's do some digging to see if we can root out some potential confounders.\n\n### Exercise 2\n\nLast week, we found that the youngest patient who smokes is 9, suggesting that there is a difference in the age distribution among smokers and non-smokers. Make a plot that compares these two distributions.\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nAgain, we see that the smokers are overall older than the non-smokers. \n\n### Exercise 3\n\nWe think that age should be related to height, which in turn should be related to FEV. Let's investigate that more systematically now with plotting. \n\nHow would you like to investigate that with plotting? Here's one suggestion, though you don't have to take it: make a plot with two panels, one that has a scatterplot of height versus age for the female patients, and one that has a scatterplot of height versus age for the male patients. \n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nWe see that the within-sex trend is similar: height is linear-ish at younger ages, and flat-ish at older ages. Boys wind up taller at older ages. \n\nWe will then make a scatterplot of FEV versus height.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(fev_tbl, aes(x = height, y = fev)) + \n  geom_jitter(width=0.2, alpha = 0.75) + \n  ggtitle(\"FEV versus height\") +\n  ylab(\"FEV (l/s)\") +\n  xlab(\"Height (inches)\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](fev_datavis_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nWe see that taller participants generally have higher FEV. \n\n## Smoking and lung function: a more nuanced look\n\nNow that we know that the smokers are older and bigger and have higher FEV, let's look at the relationship between FEV and smoking status *adjusted* for height. \n\n### Exercise 4\n\nMake a scatterplot of FEV versus height, with points marked by smoking status.\n\n::: {.cell}\n\n```{.r .cell-code}\n# FILL IN HERE\n```\n:::\n\nBased on this plot, it seems like the FEV of smokers and non-smokers *of the same height* is pretty similar.",
    "crumbs": [
      "Lecture 4 Case Study: Data Visualization with FEV Dataset"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html",
    "href": "webpages/lectures_i/lec6a_modelfitting.html",
    "title": "Lecture 6A: Model Fitting",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nmake a model object in R, using lm() as an example.\nwrite a formula in R.\npredict on a model object with the broom::augment() and predict() functions.\nextract information from a model object using broom::tidy(), broom::glance(), and traditional means.\n\nNote that there is a new tidyverse-like framework of packages to help with modelling. It‚Äôs called tidymodels.",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#learning-objectives",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#learning-objectives",
    "title": "Lecture 6A: Model Fitting",
    "section": "",
    "text": "From today‚Äôs class, students are anticipated to be able to:\n\nmake a model object in R, using lm() as an example.\nwrite a formula in R.\npredict on a model object with the broom::augment() and predict() functions.\nextract information from a model object using broom::tidy(), broom::glance(), and traditional means.\n\nNote that there is a new tidyverse-like framework of packages to help with modelling. It‚Äôs called tidymodels.",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#model-fitting-in-r",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#model-fitting-in-r",
    "title": "Lecture 6A: Model Fitting",
    "section": "Model Fitting in R",
    "text": "Model Fitting in R\nData wrangling and plotting can get you pretty far when it comes to drawing insight from your data. But, sometimes you need to go further. For example:\n\nInvestigate the relationship between two or more variables\nPredict the outcome of a variable given information about other variables\n\nThese typically involve fitting models, as opposed to simple computations than can be done with tidyverse packages like dplyr.\nThis tutorial is not about the specifics of fitting a model. Even though a few references to statistical concepts are made, just take these for face value.\nThe following packages will be used throughout this lecture:\n\n# install.packages(c(\"tidyverse\", \"tidymodels\", \"gapminder\")) #uncomment if not already installed\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gapminder)",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#example-linear-model",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#example-linear-model",
    "title": "Lecture 6A: Model Fitting",
    "section": "Example: Linear Model",
    "text": "Example: Linear Model\nA linear model describes a relationship between an outcome y and a variable(s) (or covariate(s), predictor(s), dependent variable(s)) x. In the case where only one variable is included in the model, alinear model (or linear regression) is a ‚Äú(straight) line of best fit‚Äù. This line describes the linear relationship between x and y, and can be used for both inference and prediction.\nHere are a couple tasks that a linear model would be useful to address:\n\nA car weighs 4000 lbs. Provide a numerical prediction on its mpg (miles per gallon).\nDoes the weight of a car influence its mpg?\nHow many more miles per gallon can we expect of a car that weighs 1000 lbs less than another car?\n\nA simple scatterplot will give us a general idea, but can‚Äôt give us specifics. Here, we use the mtcars dataset in the datasets package. A linear model is one example of a model that can attempt to answer all three ‚Äì the line corresponding to the fitted model has been added to the scatterplot.\n\nggplot(mtcars, aes(wt, mpg)) + #initialise plot\n  geom_point() + #scatterplot\n  labs(x = \"Weight (1000's of lbs)\") + #x axis label\n  geom_smooth(method = \"lm\", se = FALSE) + #add a smooth trend line\n  theme_minimal() \n\n\n\n\n\n\n\n\nA simple scatterplot will give us a general idea, but can‚Äôt give us specifics. Here, we use the mtcars dataset in the datasets package. A linear model is one example of a model that can attempt to answer all three ‚Äì the line corresponding to the fitted model has been added to the scatterplot.\nWhile you can plot a linear model using ggplot2‚Äôs geom_smooth() layer, you can‚Äôt really do much else in terms of the linear model, like inference. Because of this, we will explicitly fit linear models outside of ggplot.",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#fitting-a-model-in-r",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#fitting-a-model-in-r",
    "title": "Lecture 6A: Model Fitting",
    "section": "Fitting a Model in R",
    "text": "Fitting a Model in R\nFitting a model in R typically involves using a function in the following format:\nmethod(formula, data, options)\nMethod: A function such as:\n\nLinear Regression: lm\nGeneralized Linear Regression: glm\nLocal regression: loess\nQuantile regression: quantreg::rq\n‚Ä¶\n\nFormula: In R, takes the form y ~ x1 + x2 + ... + xp (use column names in your data frame), where y here means the outcome variable you‚Äôre interested in viewing in relation to other variables x1, x2, ‚Ä¶\nData: The data frame or tibble. Can omit, if variables in the formula are defined in environment\nOptions: Specific to the method, and include ways to customize the model.\nRunning the code returns an object ‚Äì usually a special type of list ‚Äì that you can then work with to extract results.\nFor example, let‚Äôs fit a linear regression model on a car‚Äôs mileage per gallon (mpg, ‚ÄúY‚Äù variable) from the car‚Äôs weight (wt, ‚ÄúX‚Äù variable). Notice that no special options are needed for lm().\n\nmy_lm &lt;- lm(mpg ~ wt, data = mtcars)\n\nmy_lm\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\n\nPrinting the model to the screen might lead you to incorrectly conclude that the model object my_lm only contains the above text. The reality is, my_lm contains a lot more, but special instructions have been given to R to only print out a special digested version of the object. This behaviour tends to be true with model objects in general, not just for lm(). Let‚Äôs",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#summarizing-the-model-with-broom",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#summarizing-the-model-with-broom",
    "title": "Lecture 6A: Model Fitting",
    "section": "Summarizing the Model with broom",
    "text": "Summarizing the Model with broom\nNow that you have the model object, there are typically three ways in which it‚Äôs useful to probe and use the model object. The broom package has three crown functions that make it easy to extract each piece of information by converting your model into a tibble:\n\ntidy: extract statistical summaries about each ‚Äúcomponent‚Äù of the model.\naugment: add columns to the original data frame containing predictions.\nglance: extract statistical summaries about the model as a whole (a 1-row tibble).\n\n\ntidy()\nUse the tidy() function for a statistical summary of each component of your model, where each component gets a row in the output tibble. For lm(), tidy() gives one row per regression coefficient (slope and intercept).\n\ntidy(my_lm)\n\n# A tibble: 2 √ó 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    37.3      1.88      19.9  8.24e-19\n2 wt             -5.34     0.559     -9.56 1.29e-10\n\n\ntidy() only works if it makes sense to talk about model ‚Äúcomponents‚Äù.\n\n\naugment()\nUse the augment() function to make predictions on a dataset by augmenting predictions as a new column to your data. By default, augment() uses the dataset that was used to fit the model.\n\naugment(my_lm) %&gt;%\n  print(n = 5)\n\n# A tibble: 32 √ó 9\n  .rownames           mpg    wt .fitted .resid   .hat .sigma  .cooksd .std.resid\n  &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1 Mazda RX4          21    2.62    23.3 -2.28  0.0433   3.07  1.33e-2    -0.766 \n2 Mazda RX4 Wag      21    2.88    21.9 -0.920 0.0352   3.09  1.72e-3    -0.307 \n3 Datsun 710         22.8  2.32    24.9 -2.09  0.0584   3.07  1.54e-2    -0.706 \n4 Hornet 4 Drive     21.4  3.22    20.1  1.30  0.0313   3.09  3.02e-3     0.433 \n5 Hornet Sportabout  18.7  3.44    18.9 -0.200 0.0329   3.10  7.60e-5    -0.0668\n# ‚Ñπ 27 more rows\n\n\nWe can also predict on new datasets. Here are predictions of mpg for cars weighing 3, 4, and 5 thousand lbs. In the following code, we make a predictor for wt = 3, 4, and 5.\n\naugment(my_lm, newdata = tibble(wt = 3:5))\n\n# A tibble: 3 √ó 2\n     wt .fitted\n  &lt;int&gt;   &lt;dbl&gt;\n1     3    21.3\n2     4    15.9\n3     5    10.6\n\n\nNotice that only the ‚ÄúX‚Äù variables are needed in the input tibble (wt), and that since the ‚ÄúY‚Äù variable (mpg) wasn‚Äôt provided, augment() couldn‚Äôt calculate anything besides a prediction\n\n\nglance()\nUse the glance() function to extract a summary of the model as a whole, in the form of a one-row tibble. This will give you information related to the model fit.\n\nglance(my_lm)\n\n# A tibble: 1 √ó 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.753         0.745  3.05      91.4 1.29e-10     1  -80.0  166.  170.\n# ‚Ñπ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#summarizing-the-model-without-broom",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#summarizing-the-model-without-broom",
    "title": "Lecture 6A: Model Fitting",
    "section": "Summarizing the Model Without broom",
    "text": "Summarizing the Model Without broom\nIn order for a model to work with the broom package, someone has to go out of their way to contribute to the broom package for that model. While this has happened for many common models, many others remain without broom compatibility.\nHere‚Äôs how to work with these model objects in that case.\n\nPrediction\nIf broom::augment() doesn‚Äôt work, then the developer of the model almost surely made it so that the predict() function works (not part of the broom package). The predict() function typically takes the same format of the augment() function, but usually doesn‚Äôt return a tibble.\nHere are the first 5 predictions of mpg on the my_lm object, defaulting to predictions made on the original data:\n\npredict(my_lm) %&gt;% #do prediction on all values in the original dataset\n  unname() %&gt;% #remove colnames\n  head(5) #look at first 5 values\n\n[1] 23.28261 21.91977 24.88595 20.10265 18.90014\n\n\nHere are the predictions of mpg made for cars with a weight of 3, 4, and 5 thousand lbs:\n\npredict(my_lm, newdata = tibble(wt = 3:5)) %&gt;% \n  unname()\n\n[1] 21.25171 15.90724 10.56277\n\n\nChecking the documentation of the predict() function for your model isn‚Äôt obvious, because the predict() function is a ‚Äúgeneric‚Äù function. Your best bet is to append the model name after a dot. For example:\n\nFor a model fit with lm(), try ?predict.lm\nFor a model fit with rq(), try ?predict.rq (from the quantreg package)\n\nIf that doesn‚Äôt work, just google it: \"Predict function for rq\"\n\n\nInference\nWe can extract model information using summary() on the linear model:\n\nsummary(my_lm)\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.5432 -2.3647 -0.1252  1.4096  6.8727 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***\nwt           -5.3445     0.5591  -9.559 1.29e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.046 on 30 degrees of freedom\nMultiple R-squared:  0.7528,    Adjusted R-squared:  0.7446 \nF-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10\n\n\nThere‚Äôs a lot of information here. To extract a specific piece, we use $. For example,\n\nsummary(my_lm)$coefficients\n\n             Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 37.285126   1.877627 19.857575 8.241799e-19\nwt          -5.344472   0.559101 -9.559044 1.293959e-10\n\n\nThis outputs a data frame of some of the model output regarding the regression coefficients. There are a ton of other items we can access, and to see them we can call names()\n\nnames(summary(my_lm))\n\n [1] \"call\"          \"terms\"         \"residuals\"     \"coefficients\" \n [5] \"aliased\"       \"sigma\"         \"df\"            \"r.squared\"    \n [9] \"adj.r.squared\" \"fstatistic\"    \"cov.unscaled\" \n\n\nFor another example, wo see the adjusted R-squared valued of the model we can use\n\nsummary(my_lm)$adj.r.squared\n\n[1] 0.7445939",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#plotting-models-in-ggplot2",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#plotting-models-in-ggplot2",
    "title": "Lecture 6A: Model Fitting",
    "section": "Plotting Models in ggplot2",
    "text": "Plotting Models in ggplot2\nWe can plot models (with one predictor/ X variable) using ggplot2 through the geom_smooth() layer. Specifying method=\"lm\" gives us the linear regression fit (but only visually ‚Äì very difficult to extract model components!):\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = F) #se = F removes the confidence interval bands\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nExample: gapminder\nLet‚Äôs visualize some relationships in the gapminder dataset.\nLet‚Äôs inspect Zimbabwe, which has a unique behavior in the lifeExp and year relationship.\n\ngapminder_Zimbabwe &lt;- gapminder %&gt;% \n  filter(country == \"Zimbabwe\")\n\ngapminder_Zimbabwe %&gt;% \n  ggplot(aes(year, lifeExp)) + \n  geom_point() #add scatter plot\n\n\n\n\n\n\n\n\nNow, let‚Äôs try fitting a linear model to this relationship\n\nggplot(gapminder_Zimbabwe, aes(year,lifeExp)) +\n  geom_point() + #add the scatter plots\n  geom_smooth(method = \"lm\", se = F) #add a linear regression line\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nNot a great fit. Now we will try to fit a second degree polynomial and see what would that look like.\n\nggplot(gapminder_Zimbabwe, aes(year,lifeExp)) +\n  geom_point() +\n  geom_smooth(method = \"lm\",\n              formula = y ~ poly(x,2), #second degree polynomial (quadratic)\n              se = F)\n\n\n\n\n\n\n\n\nThat‚Äôs a better fit. Visualizing data is a really good way to inform what types of models we should use in our analysis.\nWhile this lecture only focused on two-dimensonal data (one y and one x), more sophisticaed statistical models can certainly handle more complexity and higher-dimensional data. If you‚Äôre interested, head to the Resources section at the end of this page to learn more.",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#summary",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#summary",
    "title": "Lecture 6A: Model Fitting",
    "section": "Summary",
    "text": "Summary\n\nfunction(formula, data, options) - most models in R follow this structure.\nbroom::augment() - uses a fitted model to obtain predictions. Puts this in a new column in existing tibble. Equivalent base-r function is predict().\nbroom::tidy() - used to extract statistical information on each component of a model. Equivalent is coef(summary(lm_object)).\nbroom::glance() - used to extract statistical summaries on the whole model. Always returns a 1-row tibble.\ngeom_smooth() - used to add geom_layer that shows a fitted line to the data. method and formula arguments can be used to customize model.",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#fev-case-study",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#fev-case-study",
    "title": "Lecture 6A: Model Fitting",
    "section": "FEV Case study",
    "text": "FEV Case study\nWhile this is not a modelling class, let‚Äôs get a sense of where modelling would fit into a real data analysis by working through the final part of the FEV case study.",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#worksheet-a4",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#worksheet-a4",
    "title": "Lecture 6A: Model Fitting",
    "section": "Worksheet A4",
    "text": "Worksheet A4\nWe will now spend some time attempting questions on the last part of Worksheet A4.",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_i/lec6a_modelfitting.html#resources",
    "href": "webpages/lectures_i/lec6a_modelfitting.html#resources",
    "title": "Lecture 6A: Model Fitting",
    "section": "Resources",
    "text": "Resources\n\nVideo Lecture: The Model-Fitting Paradigm in R\nThe broom vignette\nU Chicago Tutorial on model fitting in R (just the linear regression part).\nAn Introduction to Statistical Learning\nMike Marin‚Äôs R playlist on YouTube",
    "crumbs": [
      "Lecture 6A: Model Fitting"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec10_shiny.html",
    "href": "webpages/lectures_ii/lec10_shiny.html",
    "title": "Lecture 10: Dashboards with R Shiny",
    "section": "",
    "text": "This topic aims to provide you with a foundation for making a shiny app. From this topic, students are anticipated to be able to:\nAnd possibly:",
    "crumbs": [
      "Lecture 10: Dashboards with R Shiny"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec10_shiny.html#why-dashboards",
    "href": "webpages/lectures_ii/lec10_shiny.html#why-dashboards",
    "title": "Lecture 10: Dashboards with R Shiny",
    "section": "Why Dashboards?",
    "text": "Why Dashboards?\nDashboards allow users to get real time (and often customizable) overviews of information. Dashboards can be used for monitoring, measuring, analyzing, and presenting data.",
    "crumbs": [
      "Lecture 10: Dashboards with R Shiny"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec10_shiny.html#r-shiny",
    "href": "webpages/lectures_ii/lec10_shiny.html#r-shiny",
    "title": "Lecture 10: Dashboards with R Shiny",
    "section": "R Shiny",
    "text": "R Shiny\nShiny is an open-source R package that allows users to create interactive web applications directly from R without needing to learn traditional web development languages like HTML, CSS, or JavaScript.\nHere are some examples of R Shiny Dashboards:\n\nhttp://ShowMeShiny.com\n\n\n\nhttp://letsrun.com/shoes\nhttp://daattali.com/shiny/cancer-data/\n\n\nToday, we‚Äôll be replicating this dashboard to explore BS Liquor Store prices:\n\nhttp://daattali.com/shiny/bcl/",
    "crumbs": [
      "Lecture 10: Dashboards with R Shiny"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec10_shiny.html#agenda",
    "href": "webpages/lectures_ii/lec10_shiny.html#agenda",
    "title": "Lecture 10: Dashboards with R Shiny",
    "section": "Agenda",
    "text": "Agenda\nWe are going to be working off of this slide deck and tutorial written by Dean Attali. This should take two classes.",
    "crumbs": [
      "Lecture 10: Dashboards with R Shiny"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec10_shiny.html#resources",
    "href": "webpages/lectures_ii/lec10_shiny.html#resources",
    "title": "Lecture 10: Dashboards with R Shiny",
    "section": "Resources",
    "text": "Resources\n\nVideo lecture: How to Make a Shiny App in R\n\n\n\n‚ÄúMastering Shiny‚Äù by Hadley Wickham gives a more comprehensive treatment.\nThe official shiny site has tutorials, a gallery, and other goodies.\nFor deploying shiny apps, check out https://www.shinyapps.io/\nFor shiny documents (= R Markdown + shiny), see Chapter 19 of Yihui‚Äôs R Markdown book.\nFor testing your shiny app, check out the shinytest and reactlog packages.\nFor further cutting down on code repetition by ‚Äúfunctionizing‚Äù your shiny app, check out Emily Riederer‚Äôs beginner‚Äôs guide to Shiny modules for a gentle introduction and Chapter 19 of the ‚ÄúMastering Shiny‚Äù book for a full treatment.\n\nOther dashboard tools besides shiny (but not in R):\n\nWith python: plotly dash. Check out the main website, or this Medium post introducing the tool.\nWith javascript: D3, a tremendously powerful tool with a steep learning curve (esp.¬†if you don‚Äôt know javascript)."
  },
  {
    "objectID": "webpages/lectures_ii/lec10_shiny.html#additional-resources",
    "href": "webpages/lectures_ii/lec10_shiny.html#additional-resources",
    "title": "Lecture 10: Dashboards with R Shiny",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nVideo lecture: How to Make a Shiny App in R\n\n\n\n‚ÄúMastering Shiny‚Äù by Hadley Wickham gives a more comprehensive treatment.\nThe official shiny site has tutorials, a gallery, and other goodies.\nFor deploying shiny apps, check out https://www.shinyapps.io/\nFor shiny documents (= R Markdown + shiny), see Chapter 19 of Yihui‚Äôs R Markdown book.\nFor testing your shiny app, check out the shinytest and reactlog packages.\nFor further cutting down on code repetition by ‚Äúfunctionizing‚Äù your shiny app, check out Emily Riederer‚Äôs beginner‚Äôs guide to Shiny modules for a gentle introduction and Chapter 19 of the ‚ÄúMastering Shiny‚Äù book for a full treatment.\n\nOther dashboard tools besides shiny (but not in R):\n\nWith python: plotly dash. Check out the main website, or this Medium post introducing the tool.\nWith javascript: D3, a tremendously powerful tool with a steep learning curve (esp.¬†if you don‚Äôt know javascript).",
    "crumbs": [
      "Lecture 10: Dashboards with R Shiny"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec11_automation.html",
    "href": "webpages/lectures_ii/lec11_automation.html",
    "title": "Lecture 11: Automation",
    "section": "",
    "text": "Note: This is an optional topic.\nFrom today‚Äôs class, students are anticipated to be able to:\nOther tools aside from make (We won‚Äôt be covering these):",
    "crumbs": [
      "Lecture 11: Automation"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec11_automation.html#why-automation",
    "href": "webpages/lectures_ii/lec11_automation.html#why-automation",
    "title": "Lecture 11: Automation",
    "section": "Why Automation",
    "text": "Why Automation\nIt often makes sense to break up a task (e.g.¬†‚Äúanalyze data and turn it into publication ready figures and tables‚Äù) into smaller chunks, e.g.¬†‚Äúdata cleaning‚Äù vs ‚Äúsummarizing and plotting‚Äù vs ‚Äúmodel fitting‚Äù. This leads to a pipeline: a system where the code for some tasks (e.g.¬†summarizing and plotting) depend on the output of others (e.g.¬†data cleaning).\nOne of the major advantages to this paradigm: you no longer have to re-run all of the code every time you make a change. You only need to run the parts downstream from what you changed.\nBut how do we keep track of what needs to be re-run when we make changes in this system? We could do it by hand, but this is likely to cause human error (recall the reproducibility principle!). It‚Äôs much safer to automate. We will be learning how to use Makefiles for this purpose.\nThis will be challenging! But the payoff is huge for larger projects. Shaun Jackman gives an example of a Bioinformatics paper that is generated with a single Makefile that:\n\nDownloads the data\nRuns command-line programs\nPerforms the statistical analyses using R\nGenerates TSV tables\nRenders figures using ggplot2\nRenders supplementary material using RMarkdown\nRenders the manuscript using Pandoc\n\nAnd critically, knows which parts need to be run and which parts do not. Amazing, right?",
    "crumbs": [
      "Lecture 11: Automation"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec11_automation.html#agenda",
    "href": "webpages/lectures_ii/lec11_automation.html#agenda",
    "title": "Lecture 11: Automation",
    "section": "Agenda",
    "text": "Agenda\nWe will first work through stat545.com Chapter 35 to make sure that we all have make installed and that we can access it.\nOnce we get there, we‚Äôll work through the activity in stat545.com Chapter 36 together.",
    "crumbs": [
      "Lecture 11: Automation"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec11_automation.html#additional-resources",
    "href": "webpages/lectures_ii/lec11_automation.html#additional-resources",
    "title": "Lecture 11: Automation",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nShaun Jackman and Jenny Bryan‚Äôs automation notes for getting familiar with the command line.\nThe entire Part IX: All the Automation Things from the stat545.com book contains further elaborations on this topic.\n\n\nAttribution\nWritten by Vincenzo Coia, with inspiration from Tiffany Timbers for the explanation of Makefiles, as well as the make activity from Shaun Jackman and Jenny Bryan created for this course prior to 2017.",
    "crumbs": [
      "Lecture 11: Automation"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec12_characterdata.html",
    "href": "webpages/lectures_ii/lec12_characterdata.html",
    "title": "Lecture 12: StringR and Regular Expressions",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:",
    "crumbs": [
      "Lecture 12: StringR and Regular Expressions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec12_characterdata.html#strings",
    "href": "webpages/lectures_ii/lec12_characterdata.html#strings",
    "title": "Lecture 12: StringR and Regular Expressions",
    "section": "Strings",
    "text": "Strings\nYou‚Äôve used a bunch of strings at this point without knowing explicitly what they are: any time you surround text by \", you‚Äôve been making a string: a storage format for text. In R, they are of type ‚Äúcharacter‚Äù.\n\nsample_string &lt;- \"This is a string\" \ntypeof(sample_string)\n\n[1] \"character\"\n\n\nTwo places where you‚Äôll often want to manipulate these in data analysis:\n\nCleaning up column/variable names\nCleaning up character column values\n\nGood to know: Constructing strings out of characters and numbers is intuitive, but there‚Äôs a gotcha involving particular symbols with special meaning in R. For example, try running quote &lt;- \"\"\" in R; it won‚Äôt work, because the \" symbol is interpreted as you trying to make a string! To literally include a quote in a string, you can use the \\ character to ‚Äúescape‚Äù it:\n\nsingle_quote &lt;- \"\\\"\"\ncat(single_quote)\n\n\"\n\n\nYou can see more examples of special characters and how to escape them in R4DS Chapter 15.2.",
    "crumbs": [
      "Lecture 12: StringR and Regular Expressions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec12_characterdata.html#working-with-strings",
    "href": "webpages/lectures_ii/lec12_characterdata.html#working-with-strings",
    "title": "Lecture 12: StringR and Regular Expressions",
    "section": "Working with strings",
    "text": "Working with strings\nOur main tools for working with strings will be the powerful stringr package in the tidyverse paired with regular expressions.",
    "crumbs": [
      "Lecture 12: StringR and Regular Expressions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec12_characterdata.html#agenda",
    "href": "webpages/lectures_ii/lec12_characterdata.html#agenda",
    "title": "Lecture 12: StringR and Regular Expressions",
    "section": "Agenda",
    "text": "Agenda\n\nClass 1\n\nBefore class, start working on parts I and II of Worksheet B2.\nClass will be dedicated to getting your questions answered.\nDone early? Then do the optional R4DS Strings and R4DS Regular expressions readings (linked above), and do exercises for extra practice.\n\n\n\nClass 2\n\nBefore class, start working on parts II and III of Worksheet B2.\nClass will be dedicated to getting your questions answered.\nDone early? Then do the optional R4DS Strings and R4DS Regular expressions readings (linked above), and do exercises for extra practice. Or, start Assignment B4.",
    "crumbs": [
      "Lecture 12: StringR and Regular Expressions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec12_characterdata.html#resources",
    "href": "webpages/lectures_ii/lec12_characterdata.html#resources",
    "title": "Lecture 12: StringR and Regular Expressions",
    "section": "Resources",
    "text": "Resources\nVideo lecture:\n\nRegular Expressions and stringr for Text Data (only labelled as ‚Äúage restricted‚Äù because it looks at real emails within the Enron company.)\n\nWritten material:\n\nOverview tutorials similar to our worksheet:\n\nstat545.com Chapter 11: character vectors\nR4DS Chapter 15: strings.\nR4DS Chapter 16: regular expressions.\n\nThe stat545.com Chapter 11 on character vectors has an elaborate discussion on useful resources for learning more about strings.",
    "crumbs": [
      "Lecture 12: StringR and Regular Expressions"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html",
    "href": "webpages/lectures_ii/lec13_listcolumns.html",
    "title": "Lecture 13: List Columns",
    "section": "",
    "text": "From this topic, students are anticipated to be able to:\n\nUse the map family of functions from the purrr package to iteratively apply a function.\nCreate and operate on list columns in a tibble using nest(), unnest(), and the map() family of functions.\nDefine functions on-the-fly within a map function using shortcuts.\nApply list columns to cases in data analysis: columns of models, columns of nested lists (JSON-style data), and operating on entire groups within a tibble.\n\nClass 1 will be dedicated to purrr while Class 2 will be dedicated to list-columns.\nWe will need to load in the tidyverse package for this lecture:\n\nlibrary(tidyverse)",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html#vectors-vs-lists",
    "href": "webpages/lectures_ii/lec13_listcolumns.html#vectors-vs-lists",
    "title": "Lecture 13: List Columns",
    "section": "Vectors vs Lists",
    "text": "Vectors vs Lists\nHere is a list in R; it holds multiple items.\n\nsample_list &lt;- list(1:3, c(\"a\", \"b\", \"c\"))\nsample_list\n\n[[1]]\n[1] 1 2 3\n\n[[2]]\n[1] \"a\" \"b\" \"c\"\n\n\nA list might sound like a vector, which we have worked with before ‚Äì remember, we construct them using the c() function. Indeed, vectors and lists can both hold multiple items. But there are key differences.\n\n\n\n\n\n\n\nVectors\nLists\n\n\n\n\nAccess elements with square brackets []\nAccess elements with [[]]\n\n\nEach element must be an atomic data type (i.e.¬†a single value)\nElements can be anything, even another list or another vector\n\n\nEach element has to be of the same type\nElements can be as different as you like",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html#the-secret-life-of-tibbles",
    "href": "webpages/lectures_ii/lec13_listcolumns.html#the-secret-life-of-tibbles",
    "title": "Lecture 13: List Columns",
    "section": "The Secret Life of Tibbles",
    "text": "The Secret Life of Tibbles\nDid you know that data frames (and tibbles) are actually a special type of list? It‚Äôs true!\n\ntypeof(mtcars) \n\n[1] \"list\"\n\n\n\ntypeof(palmerpenguins::penguins)\n\n[1] \"list\"\n\n\nIt turns out that they are actually lists, where each element of the list stores a column, which is either a list with the same number of entries as the tibble has rows, or a vector with the same number of entries as the tibble has rows.\nThis has an important implication: we can efficiently apply a function to each column of a tibble by learning how to apply a function to each entry of a list. This is yet another way (beyond functions themselves) of avoiding duplicating code, which you will recall (from the functions topic) has many advantages.",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html#iteration",
    "href": "webpages/lectures_ii/lec13_listcolumns.html#iteration",
    "title": "Lecture 13: List Columns",
    "section": "Iteration",
    "text": "Iteration\nIf you programmed before, you probably have an idea of how to do this with a for loop. Here‚Äôs an example of a for loop in R that iterates over the entries of a numeric vector x, squares each entry, and stores the result in a numeric vector output:\n\nx &lt;- 1:10 \noutput &lt;- vector(\"double\", length(x))\n\nfor(i in seq_along(x)) { \n    output[i] &lt;- x[i]^2  \n}\n\noutput\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\nOften, you can replace loops with a compact call to a function in the purrr package. This has the advantage of making our code even more readable and compact, since we‚Äôre expressing the same logic with less space. Here‚Äôs an example using purrr::map_dbl() and a custom function:\n\npurrr::map_dbl(1:10, function(x) x^2)\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\nThe first argument specifies the list/vector we want to iterate over, and the second argument specifies a function that we want to apply to each entry. Options for specifying functions include the name of a function, a fully specified custom function (as demonstrated above), or one of the ‚Äúshortcuts‚Äù the purrr developers have provided.\nHere are two examples of ‚Äúshortcuts‚Äù:\n\npurrr::map_dbl(1:10, ~ (.x)^2)\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\n\npurrr::map_dbl(1:10, \\(x) x^2)\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\n\nThe second one is easier to remember and appears to be the one that purrr developers are recommending now; see the purrr cheatsheat. But this change in recommendation appears to have happened around 2022/2023, so you may still see the first type of shortcut in many places in the wild.",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html#worksheet-b3-part-i",
    "href": "webpages/lectures_ii/lec13_listcolumns.html#worksheet-b3-part-i",
    "title": "Lecture 13: List Columns",
    "section": "Worksheet B3, Part I",
    "text": "Worksheet B3, Part I\nWe think the best way to get your bearings with purrr is to jump into Worksheet B3. Class 1 will be dedicated to getting your questions about Part 1 and about any concepts up to this point answered.",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html#list-columns",
    "href": "webpages/lectures_ii/lec13_listcolumns.html#list-columns",
    "title": "Lecture 13: List Columns",
    "section": "List Columns",
    "text": "List Columns\nDid you know columns in a tibble can have type ‚Äúlist‚Äù? We call these types of columns ‚Äúlist columns‚Äù.\nConsider the following example: a snippet of the Game of Thrones data from An API of Ice and Fire.\n## # A tibble: 6 √ó 3\n##   name              gender titles   \n##   &lt;chr&gt;             &lt;chr&gt;  &lt;list&gt;   \n## 1 Theon Greyjoy     Male   &lt;chr [2]&gt;\n## 2 Tyrion Lannister  Male   &lt;chr [2]&gt;\n## 3 Victarion Greyjoy Male   &lt;chr [2]&gt;\n## 4 Will              Male   &lt;chr [1]&gt;\n## 5 Areo Hotah        Male   &lt;chr [1]&gt;\n## 6 Chett             Male   &lt;chr [1]&gt;\nSome characters have one title (e.g.¬†Will); others have more than one title (e.g.¬†Theon Greyjoy). Consequently, the titles column is a list column, where each entry is a list that contains as many or as few strings as we like.",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html#worksheet-b3-parts-2-and-3",
    "href": "webpages/lectures_ii/lec13_listcolumns.html#worksheet-b3-parts-2-and-3",
    "title": "Lecture 13: List Columns",
    "section": "Worksheet B3, Parts 2 and 3",
    "text": "Worksheet B3, Parts 2 and 3\nClass 2 will be dedicated to getting your questions about Parts 2 and 3 and about any concepts involving list columns and nested lists answered.",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html#resources",
    "href": "webpages/lectures_ii/lec13_listcolumns.html#resources",
    "title": "Lecture 13: List Columns",
    "section": "Resources",
    "text": "Resources\nVideo lectures:\n\nVectors and Lists in R\nR List Columns: purrr map and nesting\n\nWritten material:\n\nR4DS Chapter 21: Iteration for purrr\n\n21.1 for an intro\n21.5 for the map family of functions\nThe intro of 21.7 for the map2 and pmap families.\n\n‚ÄúList Columns‚Äù from Jenny‚Äôs purrr tutorial\n‚ÄúNested data‚Äù article on tidyr‚Äôs website.\n\nWant to dig deeper? These resources can help.\n\nAdvanced R Chapter 9: Functionals ‚Äì looking at purrr and map() from a programming perspective.\ntidyr‚Äôs rectangling vignette ‚Äì for handling deeply nested lists (JSON-style data), similar to tidyr‚Äôs pivot_ functions.",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec13_listcolumns.html#agenda",
    "href": "webpages/lectures_ii/lec13_listcolumns.html#agenda",
    "title": "Lecture 13: List Columns",
    "section": "Agenda",
    "text": "Agenda\n\nClass 1: Worksheet B3, Part I\nWe think the best way to get your bearings with purrr is to jump into Worksheet B3. Class 1 will be dedicated to getting your questions about Part 1 and about any concepts up to this point answered.\n\n\nClass 2: Worksheet B3, Parts 2 and 3\nClass 2 will be dedicated to getting your questions about Parts 2 and 3 and about any concepts involving list columns and nested lists answered.",
    "crumbs": [
      "Lecture 13: List Columns"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec14_quarto.html",
    "href": "webpages/lectures_ii/lec14_quarto.html",
    "title": "Lecture 14: Websites and Slides with Quarto",
    "section": "",
    "text": "One great thing about having html files output from Rmd? We can use Rmd as a framework for creating websites, because websites are often just html.\nSimilarly, we can use Rmd as a framework for creating pdf slides (through the Beamer LaTeX document class) or html slides (through reveal.js).\nThis is especially powerful when you move to the next generation version of Rmd, Quarto.\nNote that Quarto was released in 2022, so there are still some growing pains. But it seems to be the way of the future for websites and slides, so it‚Äôs what we‚Äôll cover.\nThis topic is optional.",
    "crumbs": [
      "Lecture 14: Websites and Slides with Quarto"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec14_quarto.html#quarto-installation-and-basics",
    "href": "webpages/lectures_ii/lec14_quarto.html#quarto-installation-and-basics",
    "title": "Lecture 14: Websites and Slides with Quarto",
    "section": "Quarto Installation and Basics",
    "text": "Quarto Installation and Basics\nOfficial tutorial here. It‚Äôs very straightforward to pick up if you already know Rmd. (Which we do!)",
    "crumbs": [
      "Lecture 14: Websites and Slides with Quarto"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec14_quarto.html#quarto-websites",
    "href": "webpages/lectures_ii/lec14_quarto.html#quarto-websites",
    "title": "Lecture 14: Websites and Slides with Quarto",
    "section": "Quarto Websites",
    "text": "Quarto Websites\nTurns out, you‚Äôve been using a Quarto website this whole semester! Our STAT545 webpage (the one you‚Äôre on right now) was build entirely using Quarto. And, this was build using no prior Quarto knowledge or fancy tools - this was actually my first website build ever.\nLet‚Äôs ‚Äúlearn by doing‚Äù and build a webpage together! This is a great opportunity to build a professional website (like mine) using Quarto. We will host our website on Github to make things easy!\nBefore continuing, ensure that you‚Äôve installed Quarto using the tutorial in the previous sections.\nIn RStudio, create a New Project. Select ‚ÄúNew Directory‚Äù and then find ‚ÄúQuarto Website‚Äù. A simple build of a two paged website will generate.\nIn Terminal, use touch .nojekyll (mac) or copy NUL .nojekyll to disable Jekyll.\nNavigate to the _quarto.yml file in your files on the right-hand side of RStudio. Under the project: preamble, addoutput-dir: docs under the project preamble.\nClick the Render button. A local version of this simple website will appear.\nNow, we should send this to GitHub so we can host our website on GitHub and make changes both locally and through GitHub. To do so, we need to connect this R Project with Github.\nWhen you made this project, you should have selected to use Git as a version control. If not, head to Tools &gt; Version control &gt; Project Setup and select Git as your version control. At this time, origin should be set to none.\nOn GitHub, make a new EMPTY repository. This should be named with the same name as your website (i.e., yourname.github.io). Ensure you UNSELECT to make a README file.\nNow back to RStudio. We will be working in the terminal to give commands to our computer to connect with Github. SAVE ALL FILES. In the Terminal (beside the Console in RStudio), type git init. Then, git add .. Then, commit the changes of our website to Git. Type `git commit -m ‚Äúinitial commit‚Äù.``\nThe -m \"xxx\" part adds a description of your changes. After, tell github where we are pushing the changes to (i.e., the repository you just created!) using git remote add origin https://github.com/yourusername/yourreponame%60 and filling in your username and repository name. Then, push the changes using git push -u origin main. Head back to github to see new files added to your repository.\nOn Github in your repository, click the three dots and head to settings. Navigate to pages on the lefthand side menu. Under branch, select main as your branch and /docs as the folder. Select save. Give it a few minutes and refresh if you dont see a success message pointing to the website. Head to yourreponame.github.io to see if it worked!\nDo steps from git add . onward to push changes each time.",
    "crumbs": [
      "Lecture 14: Websites and Slides with Quarto"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec14_quarto.html#quarto-slides",
    "href": "webpages/lectures_ii/lec14_quarto.html#quarto-slides",
    "title": "Lecture 14: Websites and Slides with Quarto",
    "section": "Quarto Slides",
    "text": "Quarto Slides\nOfficial tutorial here.\nAn example of a Quarto slide deck is Lucy‚Äôs guest lecture in STAT 540. This uses our preferred format, reveal.js. You can download the slide deck WITH the source here. This is a great way to make your slide deck reproducible.",
    "crumbs": [
      "Lecture 14: Websites and Slides with Quarto"
    ]
  },
  {
    "objectID": "webpages/lectures_ii/lec14_quarto.html#resources",
    "href": "webpages/lectures_ii/lec14_quarto.html#resources",
    "title": "Lecture 14: Websites and Slides with Quarto",
    "section": "Resources",
    "text": "Resources\n\nOfficial tutorial for Quarto website building here.",
    "crumbs": [
      "Lecture 14: Websites and Slides with Quarto"
    ]
  },
  {
    "objectID": "index.html#attributions",
    "href": "index.html#attributions",
    "title": "STAT545 A/B: Exploratory Data Analysis (Fall 2025)",
    "section": "üìù Attributions",
    "text": "üìù Attributions\nMany thanks to those who have contributed to the materials for STAT545 over the years. Content has been created by Albina Gibadullina, Vincenzo Coia, Jenny Bryan, Lucy Gao, Grace Tompkins, Katie Burak, Victor Yuan, and other members of the Instructional Team."
  },
  {
    "objectID": "instructor_guides/updating_website.html",
    "href": "instructor_guides/updating_website.html",
    "title": "STAT545 @ UBC",
    "section": "",
    "text": "Website is built using Quarto, and is hosted on GitHub pages through the UBC-STAT Organization.\nI (Grace) rebuilt this website in 2025 to use Quarto and provide a more easily editable and maintainable website for this course.\n\n\nTo edit the website: - Clone the repository to your local machine - Open the R project - Edit the webpages (.qmd files) in the webpages folder - If adding any webpages, add them to the _quarto.yml file\nNOTES: - the _quarto.yml file is white space sensitive. - to hide pages if you‚Äôd prefer to release lectures one-by-one, comment them out in the _quarto.yml file - index.qmd must be named index.qmd and must be on the top level (not in a folder) - if you rename, delete, or move a webpage, you need to go into the docs folder and delete it there. You can just delete everything and re-render. - always render site and save all before pushing to GitHub - right now lectures are named by week since some weeks have two lectures and some don‚Äôt. Due to how I wrote the syllabus I found this made the most sense\n\n\n\n\nin-class exercises are built using a call-out block (warning type with icon = F. Orange, minimal)\ninstructor demos are build using a call-out block (tip type with icon = F. Green, minimal)\nnotes are build using call out blocks (note type, blue)\ntips are built using call out blocks (tip type, green)\ncautions are build using call out blocks (caution type, orange)"
  },
  {
    "objectID": "instructor_guides/updating_website.html#instructions-for-updating-website",
    "href": "instructor_guides/updating_website.html#instructions-for-updating-website",
    "title": "STAT545 @ UBC",
    "section": "",
    "text": "Website is built using Quarto, and is hosted on GitHub pages through the UBC-STAT Organization.\nI (Grace) rebuilt this website in 2025 to use Quarto and provide a more easily editable and maintainable website for this course.\n\n\nTo edit the website: - Clone the repository to your local machine - Open the R project - Edit the webpages (.qmd files) in the webpages folder - If adding any webpages, add them to the _quarto.yml file\nNOTES: - the _quarto.yml file is white space sensitive. - to hide pages if you‚Äôd prefer to release lectures one-by-one, comment them out in the _quarto.yml file - index.qmd must be named index.qmd and must be on the top level (not in a folder) - if you rename, delete, or move a webpage, you need to go into the docs folder and delete it there. You can just delete everything and re-render. - always render site and save all before pushing to GitHub - right now lectures are named by week since some weeks have two lectures and some don‚Äôt. Due to how I wrote the syllabus I found this made the most sense\n\n\n\n\nin-class exercises are built using a call-out block (warning type with icon = F. Orange, minimal)\ninstructor demos are build using a call-out block (tip type with icon = F. Green, minimal)\nnotes are build using call out blocks (note type, blue)\ntips are built using call out blocks (tip type, green)\ncautions are build using call out blocks (caution type, orange)"
  },
  {
    "objectID": "instructor_guides/running_course.html",
    "href": "instructor_guides/running_course.html",
    "title": "Guide to Running STAT545",
    "section": "",
    "text": "Review all lectures, worksheets\nEnsure autograding works using a Test Student (submit in Canvas using student view to generate a test student)\n\n\n\n\n\n\n\nRelease lectures week by week (un-comment each link in the _quarto.yml file) and any related case-studies\nUpdate the ‚Äúthis week at a glance‚Äù section on the index.qmd (home) page\nPost the same announcement ‚Äúthis week at a glance‚Äù on Slack\n\n\n\n\n\nRelease worksheets (un-comment each download link)\nRelease MDA and collaborative project when appropriate (see above)"
  },
  {
    "objectID": "instructor_guides/running_course.html#prior-to-starting-course",
    "href": "instructor_guides/running_course.html#prior-to-starting-course",
    "title": "Guide to Running STAT545",
    "section": "",
    "text": "Review all lectures, worksheets\nEnsure autograding works using a Test Student (submit in Canvas using student view to generate a test student)"
  },
  {
    "objectID": "instructor_guides/running_course.html#posting-content",
    "href": "instructor_guides/running_course.html#posting-content",
    "title": "Guide to Running STAT545",
    "section": "",
    "text": "Release lectures week by week (un-comment each link in the _quarto.yml file) and any related case-studies\nUpdate the ‚Äúthis week at a glance‚Äù section on the index.qmd (home) page\nPost the same announcement ‚Äúthis week at a glance‚Äù on Slack\n\n\n\n\n\nRelease worksheets (un-comment each download link)\nRelease MDA and collaborative project when appropriate (see above)"
  },
  {
    "objectID": "instructor_guides/worksheet_guide.html",
    "href": "instructor_guides/worksheet_guide.html",
    "title": "STAT545 @ UBC",
    "section": "",
    "text": "These instructions assume you have Jupyter/Anaconda installed as per the student instructions\nSummary of Resources:\n\nhttps://ttimbers.github.io/jupyter-nbgrader-r/slides/jupyter-nbgrader-r.html#7\nhttps://github.com/ttimbers/jupyter-nbgrader-r\nhttps://github.com/UBC-STAT/stat-545-instructor/blob/master/instructor-guides/autograding_worksheets.md\n\nPre-requisites:\n\nSet up Jupyer/Anaconda as per the student instructions\nDownload and Install Docker Desktop, if you don‚Äôt already have it (https://www.docker.com/products/docker-desktop/)\nLaunch Docker Desktop and create an account"
  },
  {
    "objectID": "instructor_guides/worksheet_guide.html#worksheets",
    "href": "instructor_guides/worksheet_guide.html#worksheets",
    "title": "STAT545 @ UBC",
    "section": "",
    "text": "These instructions assume you have Jupyter/Anaconda installed as per the student instructions\nSummary of Resources:\n\nhttps://ttimbers.github.io/jupyter-nbgrader-r/slides/jupyter-nbgrader-r.html#7\nhttps://github.com/ttimbers/jupyter-nbgrader-r\nhttps://github.com/UBC-STAT/stat-545-instructor/blob/master/instructor-guides/autograding_worksheets.md\n\nPre-requisites:\n\nSet up Jupyer/Anaconda as per the student instructions\nDownload and Install Docker Desktop, if you don‚Äôt already have it (https://www.docker.com/products/docker-desktop/)\nLaunch Docker Desktop and create an account"
  },
  {
    "objectID": "instructor_guides/worksheet_guide.html#copying-worksheets-from-instructor-repo",
    "href": "instructor_guides/worksheet_guide.html#copying-worksheets-from-instructor-repo",
    "title": "STAT545 @ UBC",
    "section": "Copying Worksheets from Instructor Repo",
    "text": "Copying Worksheets from Instructor Repo\n\nClone the instructor repo to your local machine (mine‚Äôs on desktop as Jupyter cannot access OneDrive?)\ngit clone &lt;https://github.com/UBC-STAT/stat-545-instructor.git&gt; /path/to/destination\nOpen the worksheet (for example, **worksheet_a01.ipynb) in Jupyter notebooks from the worksheets/source folder. These worksheets are written WITH solutions.\nEdit the worksheet and save (more on this below)"
  },
  {
    "objectID": "instructor_guides/worksheet_guide.html#editing-existing-worksheets",
    "href": "instructor_guides/worksheet_guide.html#editing-existing-worksheets",
    "title": "STAT545 @ UBC",
    "section": "Editing Existing Worksheets",
    "text": "Editing Existing Worksheets\n\nEditing text cells\nSome cells are read only. To temporarily enable editing, go to EDIT &gt; EDIT NOTEBOOK METADATA. Go to COMMON TOOLS and you should be able to change cells to ‚ÄúEditable‚Äù, then back to ‚ÄúRead Only‚Äù. At a minimum you should update the version number if making changes. Click the play button to view it normally again.\n\n\nThe Autotest System\nThe autotest system automatically checks student answers in Jupyter Notebooks using tests specified in **autotests.yml. It‚Äôs designed to work with nbgrader to support large-scale grading.\nSolutions are written in the Jupyter Notebook wrapped between:\n### BEGIN SOLUTION\nanswer0.1a ‚Üê your_answer_here\n### END SOLUTION\nThen, in another code chunk in the Jupyter notebook, we perform the autotest.\nKey Command: ### HASHED AUTOTEST\n\nThis special comment is placed at the top of a test code cell to indicate what the autotest should evaluate\nYou can also test multiple answers in one line using semicolons\nAnswers are hashed which makes them less obvious to students\n\nExample: ### HASHED AUTOTEST answer0.1_A; answer0.1_B; answer0.1_C\n\nThe expression can contain any valid R expression which you wish to test\nHere we test that answers_0.1 A through C are equivalent to the solutions\nMultiple conditions are separated by semicolons\n\nExample: ### HASHED AUTOTEST length(answer1.1)\n\ntells autotest to evaluate the length of the student‚Äôs answer rather than the answer itself. In the student notebook, it will compute length(answer1.1) and compare the result to the expected length from the solution notebook.\n\nAutotest does the following:\n\nchecks the type of the response (e.g., string, list, numeric) and runs the corresponding tests defined in the autotest.yml file for that type.\nIt compares the response against the expected value defined in the instructor‚Äôs solution notebook, using multiple stages of validation as specified in the autotest.yml file.\nIf the answer is incorrect, the student will receive an autogenerated error message based on the failed test criteria in the autotest.yml file.\nAutotest runs tests in the order they are defined in the YAML file. This layered approach allows for more detailed checks and provides more specific feedback when a student‚Äôs answer is incorrect.\n\nAll the test rules live in the autotest.yml file.\n\nYou can edit or add to this file\nPredefined test types include: string, numeric, list, dataframe, ggplots\n\nFull example:\n\nSome notes on autograder tests\n\nWhen writing a test that uses¬†sort()¬†on a character vector that contains special characters, the behaviour/ouput will depend on the user‚Äôs locale, which is also OS-dependent. Stripping away special characters with something like¬†gsub(\"[[:punct:]]\", \"\", x)¬†before¬†sort()¬†can address this.\n\n\n\nAssigning Values for Grading\nValues for each question are assigned using {points: X} where X is the value for the question. See below for an example in the instructor version with solutions (worksheets/source/worksheet_a01)"
  },
  {
    "objectID": "instructor_guides/worksheet_guide.html#generate-a-version-with-tests-and-solutions",
    "href": "instructor_guides/worksheet_guide.html#generate-a-version-with-tests-and-solutions",
    "title": "STAT545 @ UBC",
    "section": "Generate a Version with Tests and Solutions",
    "text": "Generate a Version with Tests and Solutions\nThis generates a student facing version including the tests that will be performed, but also includes the answer for easy debugging.\nNavigate to the¬†worksheets¬†folder in the¬†stat-545-instructor¬†repo (using cd command), and run the following code\nnbgrader generate_assignment --source_with_tests --force worksheet_a01\nOpen the folder in stat-545-instructor/worksheets/source_with_tests/ and you will see a new notebook that has answers AND runnable tests. Run all cells to ensure it works properly.\nTips: debug more by checking that you also get fails for wrong answers. You can also submit this to canvas under ‚Äústudent view‚Äù to generate a test submission for your autograder"
  },
  {
    "objectID": "instructor_guides/worksheet_guide.html#creating-student-facing-versions",
    "href": "instructor_guides/worksheet_guide.html#creating-student-facing-versions",
    "title": "STAT545 @ UBC",
    "section": "Creating Student Facing Versions",
    "text": "Creating Student Facing Versions\n\nOpen Powershell (Windows) or Terminal (Mac OS). Navigate to the¬†worksheets¬†folder in the¬†stat-545-instructor¬†repo (i.e, cd Desktop/stat-545-instructor/worksheets), and run the following code in your shell/terminal to ‚Äúrefresh the exchange directory‚Äù:\n# remove existing directory, so we can start fresh for demo purposes\nrm -rf /tmp/exchange\n\n# create the exchange directory, with write permissions for everyone\nmkdir /tmp/exchange\nchmod ugo+rw /tmp/exchange\nAdd the worksheet to database.db file by running:\nnbgrader db assignment add worksheet_aXX\n\nif you get an error that nbgrader is not found, install it first using pip install nbgrader and then rerun the above code.\n\nGenerate the student version of (say) worksheet_05a by running (TIP, you need to be in the directory that contains the file nbgrader_config.py file):\nnbgrader generate_assignment --force worksheet_aXX\nTake a look in the¬†worksheets/release/¬†folder ‚Äì your outputted assignment should be there!\nAdd a new assignment to canvas for this worksheet (you‚Äôll have to click on the ‚ÄúMore Options‚Äù button when you go to create an assignment):\n\nUnder the description write: ‚ÄúPlease upload your Worksheet 5-A file here ‚Äì it should be a .ipynb file named worksheet_aXX‚Äù.\nPoints: use the number of questions they need to get correct in order to get full points.\nChange the ‚Äúsubmission type‚Äù to ‚ÄúFile Uploads‚Äù; then, click ‚ÄúRestrict Upload File Types‚Äù, and enter¬†ipynb\nInput the Due Date\nClick ‚ÄúSave and Publish‚Äù."
  },
  {
    "objectID": "instructor_guides/worksheet_guide.html#autograding-worksheets",
    "href": "instructor_guides/worksheet_guide.html#autograding-worksheets",
    "title": "STAT545 @ UBC",
    "section": "Autograding Worksheets",
    "text": "Autograding Worksheets\nFollow Steps A - E for the autograding workflow. We assume Docker Desktop has already been installed.\nA. Start Docker Container\n\nOpen Docker Desktop and ensure it‚Äôs running (on Mac you will see a whale icon by the Bluetooth button on the top of your screen, and when you click it it should say docker is running)\nOpen a terminal window. Navigate to stat-545-instructor folder (parent directory) (i.e., and run Docker build\ncd Desktop/stat-545-instructor #change to your destination\ndocker build . -t nbgrader -f worksheet_dockerfile/Dockerfile\nGo to the worksheets¬†(i.e., the folder containing the¬†nbgrader_config.py¬†file) and run a Docker container with the following command:\ncd worksheets\n\ndocker run --rm -p 8888:8888 \\\\\n  -v \"${PWD}\":/mnt/nbgrader_root \\\\\n  --name nbgradercontainer \\\\\n  nbgrader:latest\n\nThis will show the link (third one works for me) to use to connect to the Jupyter web interface. You can minimize this Terminal window but¬†DO NOT close it. You do not need to open any links. In another terminal, you can run jupyter server list to see the URLs of running servers with their tokens.\n\nOpen a new terminal window. Attach a terminal to the new container with\ndocker exec -it nbgradercontainer /bin/bash. \nFrom now on, this terminal will be the main point of interaction with nbgrader! We will call this Terminal A. After running the command, you should see (base) jovyan@xxxxxxxxxx:~$\nThe home directory in this Docker container is the same directory as¬†worksheets/\nTo move things ‚Äúinto the Docker container‚Äù, you will move them to the corresponding directories in¬†worksheets/\nWithin the Docker container, you will not be able to access anything outside of¬†worksheets/\nIn Terminal A: type ls -l to view a detailed list of what‚Äôs in your directory\n\nYou might need to create some directories in¬†worksheets/¬†so that they exist in the Docker container if anything is missing\nIf anything is highlighted in red, you can try to remove them and then call mkdir.\n\n\ntotal 4\nlrwxrwxrwx 1 jovyan users   32 Aug 11 19:48 autotests.yml -&gt; /mnt/nbgrader_root/autotests.yml\nlrwxrwxrwx 1 jovyan users   28 Aug 11 19:48 canvas.py -&gt; /mnt/nbgrader_root/canvas.py\nlrwxrwxrwx 1 jovyan users   29 Aug 11 19:48 downloaded -&gt; /mnt/nbgrader_root/downloaded\nlrwxrwxrwx 1 jovyan users   31 Aug 11 19:48 gradebook.db -&gt; /mnt/nbgrader_root/gradebook.db\nlrwxrwxrwx 1 jovyan users   25 Aug 11 19:48 grades -&gt; /mnt/nbgrader_root/grades\nlrwxrwxrwx 1 jovyan users   37 Aug 11 19:48 nbgrader_config.py -&gt; /mnt/nbgrader_root/nbgrader_config.py\nlrwxrwxrwx 1 jovyan users   26 Aug 11 19:48 release -&gt; /mnt/nbgrader_root/release\nlrwxrwxrwx 1 jovyan users   25 Aug 11 19:48 source -&gt; /mnt/nbgrader_root/source\ndrwsrwsr-x 2 jovyan users 4096 Oct 20  2023 work\n\nIf you need to create some directories, you can create these directories in¬†worksheets/, using another separate Terminal window (a.k.a. Terminal B) mkdir grades; mkdir downloaded\nIf you need the autograder to have access to files, edit the Dockerfile in worksheets_dockerfile/ (i.e., it needs the autotest.yml file)\n\nB. Prepare for Submissions\nThis step only needs to be done the first time you grade!\nWe need to import Student IDs from Canvas\n\nExport the gradebook for STAT545 as a CSV file (under Grades in Canvas). Save the unmodifed version in the grading/ folder.\nOpen the CSV and remove all but the ID and Student column.\nRename the ‚ÄúID‚Äù column to ‚Äúid‚Äù and rename the ‚ÄúStudent‚Äù column to ‚Äústudent‚Äù\nDelete the second row. Save as students.csv in worksheets/\n\nBecause you are using save as, there will now be two versions of the Canvas gradebook CSV file\n\nOriginal: DATE_Grades-STAT_545A_101.csv. MOVE THIS TO grading/\nModified: students.csv (should already be in worksheets/\n\n\nRun the following command in Terminal A:\nnbgrader db student import /mnt/nbgrader_root/students.csv\n\nC. Gather Submissions\n\nAfter the deadline, download student submissions from Canvas.\nMove the ZIP file (submissions.zip) into the folder¬†downloaded/{assignment_id}/archive.\n\nYou will need to make these 3 nested folders in¬†worksheets/¬†to be able to access them within the Docker container, for example (in Terminal B):\nWithin the worksheets/ folder, make folders for the following path: downloaded/{assignment_id}/archive manually or by:\n\nmkdir -p downloaded/{assignment_id}/archive && mv ~/Downloads/submissions.zip downloaded/{assignment_id}/archive\nEnsure that the file¬†canvas.py¬†is in the worksheet directory and that the¬†nbgrader_config.py¬†file contains the following lines:\n# Only collect submitted notebooks with valid names  c.ZipCollectApp.strict = True\nWithin the Docker container ¬†(Terminal A) run\n\nnbgrader generate_assignment --force {assignment_id} \nfor example:¬†nbgrader generate_assignment --force worksheet_a02.\n\nIt doesn‚Äôt matter if you‚Äôve run¬†nbgrader generate_assignment¬†in the past to generate the student-facing version of the worksheet‚Äì it must be run¬†again¬†within the Docker container or you will encounter issues.\n\n\nIn Terminal A: collect the submissions:\n\nnbgrader zip_collect --collector=canvas.CanvasPlugin {assignment_id}\nfor example¬†nbgrader zip_collect --collector=canvas.CanvasPlugin worksheet_a02.\n\nadd -- force if file already exists to overwrite it\n\nD. Run the Autograder\n\nTo ensure the assignment is added to nbgrader and the notebook generated, run¬†in Terminal A:\n\nnbgrader db assignment list\nYou should see something like:\nworksheet_a02 (due: None)  # &lt;-- assignment \"worksheet_a02\" is available     - worksheet_a02        # &lt;-- a notebook called \"worksheet_a02\" is made\nIf the assignment is not listed, add it with¬†nbgrader db assignment add {assignment_id}¬†(Terminal A), and then generate the assignment with¬†nbgrader generate_assignment --force {assignment_id}¬†(Terminal A). If you encounter any issues about the notebook already being associated with submissions, delete the submissions within each student ID, and re-gather them using¬†nbgrader zip_collect --collector=canvas.CanvasPlugin {assignment_id}¬†(Terminal A).\n\nRun autograding with (Terminal A):\n\nnbgrader autograde {assignment_id}\n\nExport grades with\n\nnbgrader export\n\nThis creates a file¬†grades.csv¬†with the students‚Äô canvas ID and the points for this one worksheet (although the other worksheets are present as well, they can be ignored).\n\n\nMove this file to the¬†grades¬†directory:\n\nmv grades.csv grades/grades_{assignment_id}.csv\nOtherwise it will be lost when the Docker container is terminated.\n\nIMPORTANT: Make sure there is no whitespace after the .csv name!\nNow you should see the grades_worksheet_axx.csv file in your local grades folder.\n\nE. Publish scores\n\nOpen a new Terminal window (Terminal B). cd to stat-545-instructor/grading/ directory.\nUse the file¬†grading/compile_nbgrader_grades.R¬†to compile the grades from nbgrader to a Canvas-readable CSV format. Navigate to the¬†grading/¬†directory and run the script (Terminal B):\nRscript compile_nbgrader_grades.R {raw_canvas_grades.csv} {assignment_id}\n\nThis script will merge the¬†nbgrader¬†grades and the existing grades from Canvas to the {raw_canvas_grades.csv}, and the output will be canvas.csv in worksheets/grades.\nIf for some reason the csv is not opening properly, check that there is no white space after the .csv exenstion. If problem still persists, open Excel, go to File &gt; Import &gt; import from CSV and find the grades_worksheet_a01.csv file. Import it in cell A1. Save as csv and overwrite the original.\n\n\n\n\nVerify that the scores are correct.\n\nCheck a few random assignments to ensure grading is correct\nWARNING: if you had multiple versions of the worksheet circulating, the autograder will run into issues with cell metadata not matching, etc. These worksheets will be given a score of 0, so make sure that you check that all the 0‚Äôs are¬†actually¬†0‚Äôs and not because of differing worksheet versions.¬†Avoid circulating multiple versions of worksheets, or make sure that students are only submitting the newest version (that corresponds to the instructor version of the worksheet). Let the students know that adding extra cells in their notebook will cause issues with the autograder.\n\nUpload the file¬†worksheets/grades/canvas.csv¬†to the ‚Äúgrades‚Äù page by clicking on ‚ÄúActions‚Äù &gt; ‚ÄúImport‚Äù\n\nTroubleshooting tips\n\nThe autograder grades students in id order, and terminates at the first error.\nCommon fixable errors include duplicating cells (fixable by going into the worksheet in the¬†submitted¬†folder and deleting the cells) and changing chunk types (e.g.¬†from a code chunk to a text chunk)."
  },
  {
    "objectID": "instructor_guides/worksheet_guide.html#pushing-changes-to-github",
    "href": "instructor_guides/worksheet_guide.html#pushing-changes-to-github",
    "title": "STAT545 @ UBC",
    "section": "Pushing Changes to Github",
    "text": "Pushing Changes to Github\n\noptional: create your own branch git checkout -b newbranchname\nadd changes: git add .\ncommit changes: git commit -m ‚Äúedits to worksheet aXX\"\npush: git push origin master or git push origin &lt;newbranchname&gt;"
  }
]